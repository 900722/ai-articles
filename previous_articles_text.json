[
    {
        "title": "DÃ¤rfÃ¶r lÃ¤mnade Maria Ziv jobbet pÃ¥ Max: â€Det tog stoppâ€",
        "text": "KFUM Central befinner sig i ett rÃ¤tt unikt lÃ¤ge. I en tid dÃ¥ hallbristen i Stockholm stad drabbar allt fler sporter har den ideella fÃ¶reningen fÃ¥tt mÃ¶jlighet att bygga en",
        "link": "https://www.resume.se/fordjupning/helgintervjuer/darfor-lamnade-maria-ziv-jobbet-pa-max-det-tog-stopp/",
        "date": "2025-02-12T21:33:52.342786+00:00",
        "source": "resume.se"
    },
    {
        "title": "Delade meningar om hur James Jenkins har fÃ¶rÃ¤ndrat F&B: â€Det blev en kulturkrockâ€",
        "text": "FyrtiofyraÃ¥rigeJames Jenkins, internt pÃ¥ byrÃ¥n gÃ¥r han ofta bara under namnet â€Jenkinsâ€, har varit vd pÃ¥ Forsman & Bodenfors sedan november 2023. Kontoret ligger pÃ¥ Kungsgatan med utsikt mot",
        "link": "https://www.resume.se/affarer/byraer/delade-meningar-om-hur-james-jenkins-har-forandrat-fochb-det-blev-en-kulturkrock/",
        "date": "2025-02-12T21:33:55.884357+00:00",
        "source": "resume.se"
    },
    {
        "title": "Kampanj",
        "text": "onsdag12 februari Kontakt Annonsera E-tidning Nyheter MarknadsfÃ¶ring Kommunikation AffÃ¤rer Arbetsliv FÃ¶rdjupning MÃ¥nadens Kampanj Opinion Event Utbildning Jobb SÃ¶k Mer Logga infÃ¶r bÃ¤sta upplevelsen pÃ¥ sajt Kampanj Ny kampanj med IW Edition Kampanj â€Ett naturligt nÃ¤sta stegâ€ Kampanj Vill sprida kÃ¤rlek i samarbete medÂ ett flertal influencers Kampanj FÃ¶rsÃ¤lningen mÃ¶ts av kraftig kritik âœ“ FÃ¶rdÃ¶ms av Anti-Defamation League Kampanj Dalapappa lÃ¤ngtar tillbaka i Markus nya reklamfilm fÃ¶r Visit Ã–stergÃ¶tland Kampanj â€Ger dem mÃ¶jlighet att rÃ¶ra sig i samhÃ¤llet pÃ¥ lika villkorâ€ Kampanj â€FortsÃ¤tter testa nya och spÃ¤nnande sÃ¤tt att nÃ¥ ut till rÃ¤tt talangerâ€ Kampanj Valtech Radons kampanj ska locka hemlÃ¤ngtande affÃ¤rsresenÃ¤rer Kampanj Futurnitures creative director: â€Det Ã¤r en spÃ¤nnande utmaningâ€ Kampanj Vill ta hjÃ¤lp av influerare fÃ¶r att nÃ¥ ut â€“ marknadschefen om planerna Design â€Markerar en kreativ och inspirerande riktningâ€ Kampanj â€Ett symbolvÃ¤rde fÃ¶r mÃ¥nga mÃ¤nniskorâ€ Kampanj â€Bevis pÃ¥ att spÃ¤nningen och energin kring idÃ©processen alltid lever kvarâ€ Kampanj Fastighetsbolaget satsar pÃ¥ social hÃ¥llbarhet âœ“ â€Viktigt att ungas rÃ¶ster fÃ¥r platsâ€ Kampanj Prata om dÃ¶den, hela livet - framtaget av TBWA och Geelmuyden Kiese. Kampanj Ska fÃ¶rdjupa Liberos kommunikation i Norden Kampanj Den annorlunda b2b-kampanjen â€œMoments you donâ€™t want to missâ€ ska stÃ¤rka arbetsgivarvarumÃ¤rket Kampanj Ett samarbete fÃ¶r hÃ¥llbarhet Kampanj Emil Henrohn, Annie Samuelsson och Lalash Bakri i Nord DDB:s Tiktok-serie Kampanj â€Just idag kÃ¤nns det extra viktigt att pÃ¥minna om att gÃ¶ra rÃ¤tt valâ€ Kampanj â€Det Ã¤r en stor, bred och folklig kampanj. Alla ska med.â€ Kampanj Ska representera strÃ¤van efter att kombinera teknologi med mÃ¤nsklig kontakt Kampanj \"Find Your Favorites on Snapchat\" Kampanj Kampanjen om den hetlevrade kockens letande efter lugnet Kampanj TioÂ annonser under tio veckor Kampanj Sveriges stÃ¶rsta a-kassa lockar fler att fÃ¶rsÃ¤kra sin inkomst Kampanj â€Vi hoppas att kampanjen kan inspirera till att uppskatta och fokusera pÃ¥ det du har runt omkring digâ€ Kampanj Med Ã¶gonbindel och telefon i stÃ¤llet fÃ¶r racket utmanas profilerna Kampanj Vill att man ska vÃ¤lja fÃ¶rst  â€“ inte istÃ¤llet Kampanj FÃ¶rsÃ¤kringsbolaget har ny creative director â€“ vill uppmÃ¤rksamma problemlÃ¶sning Kontakta oss Tipsa oss E-tidning Alla Ã¤mnen Lediga jobb Annonsera Om annonser Gold Standard Kakpolicy Personuppgiftspolicy UpphovsrÃ¤tt & AI Hantera kakor RSS ByrÃ¥er Design Folk pÃ¥ vÃ¤g Kampanjer Kreativitet Media PR Reklam Sociala medier Strategi VarumÃ¤rke Analys Case Debatt Granskning Helgintervjuer KrÃ¶nika Nyhetsbrev Podcast ResumÃ© insikt Trend TÃ¤vling kundservice@resume.se 08-409 320 07 ChefredaktÃ¶r och ansvarig utgivare:Yasmine Winberg TillhandahÃ¥llare av innehÃ¥ll:Bonnier Business Media Sweden AB, 105 16 Stockholm, org. nr 556468-8892. Allt innehÃ¥ll pÃ¥resume.seskyddas av upphovsrÃ¤ttslagen. Ange kÃ¤lla vid citering. ResumÃ©Ã¤r en del av Bonnier News. ResumÃ©105 16Stockholm Fler branschtitlar frÃ¥n Bonnier News: Aktuell HÃ¥llbarhet Byggindustrin Dagens industri Dagens Media Dagens Medicin Dagens SamhÃ¤lle Dagligvarunytt Fastighetsnytt Market Privata AffÃ¤rer ",
        "link": "https://www.resume.se/marknadsforing/kampanj/",
        "date": "2025-02-12T21:34:04.028922+00:00",
        "source": "resume.se"
    },
    {
        "title": "ResumÃ© insikt",
        "text": "onsdag12 februari Kontakt Annonsera E-tidning Nyheter MarknadsfÃ¶ring Kommunikation AffÃ¤rer Arbetsliv FÃ¶rdjupning MÃ¥nadens Kampanj Opinion Event Utbildning Jobb SÃ¶k Mer Logga infÃ¶r bÃ¤sta upplevelsen pÃ¥ sajt ResumÃ© insikt Publicis Emma Thorp om ledarskap i fÃ¶rÃ¤ndring ResumÃ© insikt SÃ¥ skapar Malin Zetterlund en stark teamkultur pÃ¥ The Bond ResumÃ© insikt Daniel Vaccino hyllar Volvo och krÃ¤ver bÃ¤ttring av resebolagen ResumÃ© insikt Katarina NorÃ©s viktigaste faktorer fÃ¶r en stark organisation ResumÃ© insikt Ett kulturellt skifte i Trumps nya era â€“ Ã¤r vi pÃ¥ vÃ¤g in i en era dÃ¤r mjuk makt och feminint inflytande fÃ¶rlorar sin plats i den kommersiella kulturen? ResumÃ© insikt MÃ¤ter vi det som verkligen betyder nÃ¥got? ResumÃ© insikt Oktos creative director Linius Ã–stberg om: Klassiska varumÃ¤rket som imponerar âœ“ Bilreklam som fastnat i diket âœ“ GÃ¥tan kring Klarnas uteblivna guldÃ¤gg ResumÃ© insikt Det Ã¤r dags att vÃ¤nda pÃ¥ perspektivet ResumÃ© insikt Strategierna som kan ta ditt ledarskap till nÃ¤sta nivÃ¥  âœ“ Det missar mÃ¥nga nÃ¤r de bygger en kultur ResumÃ© insikt 17 av branschens bÃ¤sta chefer âœ“ Det sÃ¤ger medarbetarna ResumÃ© insikt Kompetensen som vÃ¤ger tungt âœ“ ByrÃ¥valskonsulten: â€Alltid ett av de viktigaste kravenâ€ ResumÃ© insikt â€Anseendet Ã¤r i fritt fallâ€ âœ“ Tidslinje â€“ hÃ¤ndelserna som fÃ¤rgat svenskarnas bild av Tesla ResumÃ© insikt Markus creative director om kommunkommunikations problem och varumÃ¤rkena som inspirerar honom ResumÃ© insikt Det gÃ¶r polariserande utspelet med samhÃ¤llet â€“ och varumÃ¤rkena ResumÃ© insikt â€Back to bascisâ€ nÃ¤r AI kan replikera den perfekta reklamfilmen ResumÃ© insikt Experten om varumÃ¤rket som fÃ¥r viralt genomslag gÃ¥ng pÃ¥ gÃ¥ng ResumÃ© insikt â€Satsa pÃ¥ varumÃ¤rket innan du sÃ¤ljer produktenâ€ ResumÃ© insikt Bandbolaget hade en tillvÃ¤xt pÃ¥ 706 procent mellan 2020 och 2023 ResumÃ© insikt LÃ¤rdomarna av kommunikationsarbete som tillvÃ¤xtbolag: â€Om jag hade kunnat gÃ¥ tillbaka och Ã¤ndra pÃ¥ nÃ¥gotâ€¦â€ ResumÃ© insikt BerÃ¤ttar om sin OCD  â€“ och varfÃ¶r det Ã¤r dags att nyansera bilden av diagnosen ResumÃ© insikt Vilken kampanj blir imiterad gÃ¥ng pÃ¥ gÃ¥ng och Ã¤r dÃ¤rfÃ¶r ett skolboksexempel? DVA:s Jessica Thorelius svarar i veckans ResumÃ© Insikt Q&A. ResumÃ© insikt Svar frÃ¥n 16 kommunikationstoppar: \nâœ“ SÃ¥ ska Saab fÃ¶rvalta intresset. \nâœ“ 3:s plan fÃ¶r arenan\nâœ“ Lisbergs utmaningar efter branden.\nâœ“ â€Kan fÃ¶rÃ¤dla smarta saker som andra i branschen har gjortâ€ ResumÃ© insikt Insikter frÃ¥n 13 marknadschefer: â€VÃ¥r stÃ¶rsta utmaningâ€ ResumÃ© insikt 26 byrÃ¥ledare berÃ¤ttar: StÃ¶rsta knÃ¤ckfrÃ¥gorna: Nya affÃ¤rsmodeller, fragmenterade marknadsbudgetar och AI âœ“ Kreativitet, teknologi och talang i fokus âœ“ SnabbrÃ¶rliga behov pÃ¥ kundsidan ResumÃ© insikt Experter guidar dig in i 2025 âœ“ Myten om first mover advantage: â€Vinner genom att vÃ¤ntaâ€ ResumÃ© insikt AI-affÃ¤rerna som blomstrar âœ“ DÃ¤rfÃ¶r vÃ¤xer kritiken âœ“ Donald Trumps pÃ¥verkan ResumÃ© insikt Bangs nya kreativa chef Alba Montheli om: Jaguars backlash âœ“ VarumÃ¤rken som inspirerar âœ“ â€Personalisering har blivit en sjÃ¤lvklar strategiâ€ ResumÃ© insikt De kommer ha mest inflytande Ã¶ver marknadsfÃ¶ringsbranschen kommande Ã¥ren ResumÃ© insikt Stor kartlÃ¤ggning âœ“ 244 byrÃ¥ers lÃ¶ner âœ“ ByrÃ¥chefen: â€Vill betala braâ€ ResumÃ© insikt Vardagens smÃ¥ katastrofer kanske bÃ¤r pÃ¥ mer kreativt kapital Ã¤n du tror Kontakta oss Tipsa oss E-tidning Alla Ã¤mnen Lediga jobb Annonsera Om annonser Gold Standard Kakpolicy Personuppgiftspolicy UpphovsrÃ¤tt & AI Hantera kakor RSS ByrÃ¥er Design Folk pÃ¥ vÃ¤g Kampanjer Kreativitet Media PR Reklam Sociala medier Strategi VarumÃ¤rke Analys Case Debatt Granskning Helgintervjuer KrÃ¶nika Nyhetsbrev Podcast ResumÃ© insikt Trend TÃ¤vling kundservice@resume.se 08-409 320 07 ChefredaktÃ¶r och ansvarig utgivare:Yasmine Winberg TillhandahÃ¥llare av innehÃ¥ll:Bonnier Business Media Sweden AB, 105 16 Stockholm, org. nr 556468-8892. Allt innehÃ¥ll pÃ¥resume.seskyddas av upphovsrÃ¤ttslagen. Ange kÃ¤lla vid citering. ResumÃ©Ã¤r en del av Bonnier News. ResumÃ©105 16Stockholm Fler branschtitlar frÃ¥n Bonnier News: Aktuell HÃ¥llbarhet Byggindustrin Dagens industri Dagens Media Dagens Medicin Dagens SamhÃ¤lle Dagligvarunytt Fastighetsnytt Market Privata AffÃ¤rer ",
        "link": "https://www.resume.se/fordjupning/resume-insikt/",
        "date": "2025-02-12T21:34:12.267409+00:00",
        "source": "resume.se"
    },
    {
        "title": "ByrÃ¥val",
        "text": "onsdag12 februari Kontakt Annonsera E-tidning Nyheter MarknadsfÃ¶ring Kommunikation AffÃ¤rer Arbetsliv FÃ¶rdjupning MÃ¥nadens Kampanj Opinion Event Utbildning Jobb SÃ¶k Mer Logga infÃ¶r bÃ¤sta upplevelsen pÃ¥ sajt ByrÃ¥val â€Brinner till i brÃ¶stet nÃ¤r TBWA fÃ¥r gÃ¶ra det de gÃ¶r bÃ¤stâ€ ByrÃ¥val â€En spÃ¤nnande utmanare som vÃ¥gar tÃ¤nka nytt i en konkurrensutsatt branschâ€ ByrÃ¥val â€VÃ¤ldigt stolta Ã¶ver att fÃ¥ vara en del av den hÃ¤r resanâ€ ByrÃ¥val Sveriges stÃ¶rsta hÃ¥llbarhetspris tar in ny kommunikationspartner ByrÃ¥val VÃ¤ljer Cure Media som strategisk partner ByrÃ¥val KÃ¤nd frÃ¥n tv âœ“ Vd:n: â€Vi Ã¤r sjukt stoltaâ€ âœ“ SÃ¶dertÃ¤ljebyrÃ¥ns stÃ¶rsta uppdrag hittills ByrÃ¥val Ska modernisera Holebrooks grafiska profil och fÃ¶rstÃ¤rka varumÃ¤rkets internationella position ByrÃ¥val â€Det finns mycket potential hÃ¤râ€ ByrÃ¥val Satsar pÃ¥ tillvÃ¤xt inom gaming och samlarbilder ByrÃ¥val â€Mycket glada Ã¶ver att inleda detta samarbeteâ€ ByrÃ¥val Blir kreativ och strategisk partner inom kommunikation: â€Fantastiskt roligtâ€ ByrÃ¥val â€En bevisad fÃ¶rmÃ¥ga att Ã¥stadkomma bÃ¥de stora perceptionsfÃ¶rflyttningar och en Ã¶kad acceptansâ€ ByrÃ¥val Marknadschefen: â€Fanns inte tid till en full pitch och vi behÃ¶vde hitta en mycket snabb lÃ¶sningâ€ ByrÃ¥val VarumÃ¤rket Sejfa utmanar inom fÃ¶rsÃ¤kringskategorin ByrÃ¥val â€Vi vill att ni kan se en begrÃ¤nsad budget som en mÃ¶jlighetâ€ ByrÃ¥val Happy F&B fÃ¥r fÃ¶rlÃ¤ngt fÃ¶rtroende med ett avtal vÃ¤rt 40 miljoner kronor ByrÃ¥val FÃ¥r uppdraget att stÃ¶dja FÃ¶rsvarshÃ¶gskolan ByrÃ¥val Ska rikta in sig pÃ¥ nordeuropeiska lÃ¤nder ByrÃ¥val Vill ha hjÃ¤lp med Ã¥rs- och hÃ¥llbarhetsredovisning ByrÃ¥val Hela 19 anbud kom in i upphandlingen fÃ¶r designtjÃ¤nster ByrÃ¥val â€I en expansiv fasâ€ ByrÃ¥val FÃ¥r uppdraget att stÃ¶tta fastighetsutvecklarens strategi ByrÃ¥val De ska stÃ¤rka rallyts varumÃ¤rke âœ“ â€En unik mÃ¶jlighetâ€ ByrÃ¥val Vill stÃ¤rka sin varumÃ¤rkesposition och nÃ¥ en stÃ¶rre mÃ¥lgrupp âœ“ Ek pr: â€Stoltaâ€ ByrÃ¥val â€Ser fram emot att ta vÃ¥r influencer marketing till nÃ¤sta nivÃ¥â€ ByrÃ¥val VÃ¤rt 250 miljoner âœ“ Ska stÃ¤rka KriminalvÃ¥rdens varumÃ¤rke och kommunikation ByrÃ¥val Vill uppmÃ¤rksammas internationellt âœ“ â€Visit Dalarna Ã¤r sugna pÃ¥ att gÃ¶ra spetsig och minnesvÃ¤rd kommunikationâ€ ByrÃ¥val Efter flera uppmÃ¤rksammade kampanjer med Forsman & Bodenfors vÃ¤ljer turistbolaget ny byrÃ¥ ByrÃ¥val ByrÃ¥n Cloud Nine: SÃ¥g mÃ¶jligheter i stÃ¤llet fÃ¶r svÃ¥righeter ByrÃ¥val â€Det Ã¤r en Ã¤ra och en spÃ¤nnande utmaningâ€ Kontakta oss Tipsa oss E-tidning Alla Ã¤mnen Lediga jobb Annonsera Om annonser Gold Standard Kakpolicy Personuppgiftspolicy UpphovsrÃ¤tt & AI Hantera kakor RSS ByrÃ¥er Design Folk pÃ¥ vÃ¤g Kampanjer Kreativitet Media PR Reklam Sociala medier Strategi VarumÃ¤rke Analys Case Debatt Granskning Helgintervjuer KrÃ¶nika Nyhetsbrev Podcast ResumÃ© insikt Trend TÃ¤vling kundservice@resume.se 08-409 320 07 ChefredaktÃ¶r och ansvarig utgivare:Yasmine Winberg TillhandahÃ¥llare av innehÃ¥ll:Bonnier Business Media Sweden AB, 105 16 Stockholm, org. nr 556468-8892. Allt innehÃ¥ll pÃ¥resume.seskyddas av upphovsrÃ¤ttslagen. Ange kÃ¤lla vid citering. ResumÃ©Ã¤r en del av Bonnier News. ResumÃ©105 16Stockholm Fler branschtitlar frÃ¥n Bonnier News: Aktuell HÃ¥llbarhet Byggindustrin Dagens industri Dagens Media Dagens Medicin Dagens SamhÃ¤lle Dagligvarunytt Fastighetsnytt Market Privata AffÃ¤rer ",
        "link": "https://www.resume.se/affarer/byraval/",
        "date": "2025-02-12T21:34:20.440123+00:00",
        "source": "resume.se"
    },
    {
        "title": "Vem Ã¤r chef egentligen â€“ du eller AI?",
        "text": "Du leder ett team pÃ¥ tio personer och har fÃ¶rklarat fÃ¶r dem Ã¥t vilket hÃ¥ll du vill att bolaget ska. Och fÃ¶rstÃ¥s Ã¤ven hur ni ska ta er dit. Du har ritat upp mÃ¥l och delmÃ¥l. Skrivit ner din vision, mission och din femÃ¥rsstrategi. Nu kÃ¶r vi, tÃ¤nker du. NÃ¤r du efter ett par veckor av vardag fÃ¶ljer upp din grupps arbete mÃ¤rker du att dina tio medarbetare har dragit Ã¥t olika hÃ¥ll. Ã…t alla mÃ¶jliga hÃ¥ll faktiskt, men absolut inte dit du tÃ¤nkt att de ska. Du kallar till krismÃ¶te. Det hÃ¤r var ju inte vad ni hade kommit Ã¶verens om? Dina medarbetare skruvar pÃ¥ sig. SÃ¥ tar en av dem till orda: â€Ja, alltsÃ¥, min AI rekommenderade att jag skulle arbeta pÃ¥ ett annat sÃ¤tt Ã¤n det du fÃ¶reslog. Hen tror inte pÃ¥ din strategi â€“ och framfÃ¶r allt gynnar den inte mig eller min karriÃ¤r. Jag utvecklas inte pÃ¥ rÃ¤tt sÃ¤ttâ€, svarar medarbetaren. De andra nickar instÃ¤mmande. Deras AI-assistenter har uppenbarligen ocksÃ¥ gjort myteri. * FÃ¶r nÃ¥gra veckor sedan deltog jag i en workshop som hÃ¶lls av affÃ¤rskvinnan och digitaliseringsexpertenSara Ã–hrvall. Temat var ledarskap och frÃ¥gestÃ¤llningen hur man som ledare ska agera i ett arbetsliv som allt mer prÃ¤glas av AI. En variant av exemplet som inleder den hÃ¤r texten diskuterades. Om AI kommersialiseras och integreras i mÃ¤nniskors vardag, pÃ¥ samma sÃ¤tt som mobiltelefonen, kommer alla att ha en egen liten chef sittande pÃ¥ axeln, dagarna i Ã¤nda. Dina ekonomiska intressen Ã¤r inte din medarbetares AI:s ekonomiska intressen och definitivt inte ditt fÃ¶retags dito. Risken fÃ¶r konflikt Ã¤r uppenbar. Scenariot Ã¤r inte sÃ¤rskilt osannolikt. Inte heller kÃ¤nns det sÃ¤rskilt lÃ¥ngt borta. Som ledare kommer du snart att inte bara vara chef Ã¶ver ett team av mÃ¤nniskor, utan ocksÃ¥ Ã¶ver ett gÃ¤ng robotar. Vad hÃ¤nder med ledarskapet dÃ¥? Det gÃ¥r inte att svara pÃ¥ den frÃ¥gan. Ingen vet. Men det gÃ¥r att fÃ¶rbereda sig pÃ¥ en annorlunda morgondag. Den logiska slutsatsen: ju mer digitalisering, desto stÃ¶rre behov av mÃ¤nsklighet. Vad i ledarskapet Ã¤r det allra viktigaste fÃ¶r mellanmÃ¤nskliga relationer? Empati. StÃ¶ttning. FÃ¶rstÃ¥else. Kommunikation. Konflikthantering. FÃ¶rtroende. En del av det ledarskap som jag dÃ¥ och dÃ¥ hÃ¶r talas om i den hÃ¤r branschen stÃ¥r fÃ¶r diametralt andra saker. Ibland hierarki. Ilska. Detaljstyrning. Egocentrering. Stressdelegering. Bolag med den typen av ledarskap fÃ¶rekommer fÃ¶rstÃ¥s i alla branscher, men i just vÃ¥r bestÃ¥r ju kapitalet av mÃ¤nniskor. Desto viktigare med vÃ¤lmÃ¥ende medarbetare. Det Ã¤r ett mÃ¥ste att inte glÃ¶mma bort det i all AI-iver. Ett annat sÃ¤tt som AI kommer att fÃ¶rÃ¤ndra fÃ¶rutsÃ¤ttningarna fÃ¶r chefer och medarbetare pÃ¥ kan du lÃ¤sa om iResumÃ©s nya nummer av magasinet. Ã„ven utmaningen som beskrivs dÃ¤r blir en intressant men tuff nÃ¶t att knÃ¤cka. PS. Har du ingen prenumeration?Det lÃ¶ser du hÃ¤r.",
        "link": "https://www.resume.se/opinion/kronika/vem-ar-chef-egentligen-du-eller-ai/",
        "date": "2025-02-12T21:34:23.388640+00:00",
        "source": "resume.se"
    },
    {
        "title": "ChatGPT: Everything you need to know about the AI-powered chatbot",
        "link": "https://techcrunch.com/2025/02/12/chatgpt-everything-to-know-about-the-ai-chatbot/",
        "text": "ChatGPT, OpenAIâ€™s text-generating AI chatbot, has taken the world by storm since its launchin November 2022.What started as a tool to supercharge productivity through writing essays and code withshort text promptshas evolved into a behemoth with300 million weekly active users. 2024 was a big year for OpenAI, from itspartnership with Applefor its generative AI offering,Apple Intelligence,the release ofGPT-4o with voice capabilities,and the highly-anticipated launch of itstext-to-video model Sora. OpenAI also faced its share of internal drama, including the notable exits of high-level execs like co-founder andlongtime chief scientist Ilya SutskeverandCTO Mira Murati.OpenAI has also been hit with lawsuits fromAlden Global Capital-owned newspapersalleging copyright infringement, as well asan injunction from Elon Muskto halt OpenAIâ€™s transition to a for-profit. In 2025, OpenAI is battling the perception that itâ€™s ceding ground in the AI race toChinese rivals like DeepSeek. The company has been trying to shore up itsrelationship with Washingtonas it simultaneouslypursues an ambitious data center project,and as itreportedly lays the groundworkfor one of the largest funding rounds in history. Below, youâ€™ll find a timeline of ChatGPT product updates and releases, starting with the latest, which weâ€™ve been updating throughout the year. If you have any other questions, check outour ChatGPT FAQ here. OpenAI has effectively canceled the release of o3 in favor of what CEO Sam Altman is calling a â€œsimplifiedâ€ product offering. In a post on X, Altman said that, in the coming months, OpenAI will release a model called GPT-5 that â€œintegrates a lot of [OpenAIâ€™s] technology,â€ including o3, in ChatGPT and its API. As a result of that roadmap decision, OpenAI no longer plans to release o3 as a standalone model. Acommonly cited statis that ChatGPT requires around 3 watt-hours of power to answer a single question. Using OpenAIâ€™s latest default model for ChatGPT, GPT-4o, as a reference, nonprofitAI research institute Epoch AIfound the average ChatGPT queryconsumes around 0.3 watt-hours.However, the analysis doesnâ€™t consider the additional energy costs incurred by ChatGPT with features like image generation or input processing. In response to pressure from rivals like DeepSeek, OpenAI is changing the way its o3-mini model communicatesits step-by-step â€œthoughtâ€ process.ChatGPT users will see an updated â€œchain of thoughtâ€ that shows more of the modelâ€™s â€œreasoningâ€ steps and how it arrived at answers to questions. OpenAI is now allowing anyone to use ChatGPT web searchwithout having to log in.While OpenAIhad previously allowedusers to ask ChatGPT questions without signing in, responses were restricted to the chatbotâ€™s last training update. This only applies through ChatGPT.com, however. To use ChatGPT in any form through the native mobile app, you will still need to be logged in. OpenAI announced a new AI â€œagentâ€called deep researchthatâ€™s designed to help people conduct in-depth, complex research using ChatGPT. OpenAI says the â€œagentâ€ is intended for instances where you donâ€™t just want a quick answer or summary, but instead need to assiduously consider information from multiple websites and other sources. OpenAI used the subreddit r/ChangeMyView tomeasure the persuasive abilitiesof its AI reasoning models. OpenAI says it collects userposts from the subredditand asks its AI models to write replies, in a closed environment, that would change the Reddit userâ€™s mind on a subject. The company then shows the responses to testers, who assess how persuasive the argument is, and finally OpenAI compares the AI modelsâ€™ responses to human replies for that same post. OpenAI launched a newAI â€œreasoningâ€ model, o3-mini,the newest in the companyâ€™s o family of models. OpenAI firstpreviewed the model in Decemberalongside a more capable system called o3. OpenAI is pitching its new model as both â€œpowerfulâ€ and â€œaffordable.â€ A new report from app analytics firm Appfigures found thatover half of ChatGPTâ€™s mobile usersare under age 25, with users between ages 50 and 64 making up the second largest age demographic. The gender gap among ChatGPT users is even more significant. Appfigures estimates that across age groups, men make up 84.5% of all users. OpenAI launched ChatGPT Govdesigned to provide U.S. government agenciesan additional way to access the tech. ChatGPT Gov includes many of the capabilities found in OpenAIâ€™s corporate-focused tier, ChatGPT Enterprise. OpenAI says that ChatGPT Gov enables agencies to more easily manage their own security, privacy, and compliance, and could expedite internal authorization of OpenAIâ€™s tools for the handling of non-public sensitive data. Younger Gen Zers are embracing ChatGPT, for schoolwork,according to a new survey by the Pew Research Center.In a follow-up to its 2023 poll on ChatGPT usage among young people, Pew asked ~1,400 U.S.-based teens ages 13 to 17 whether theyâ€™ve used ChatGPT for homework or other school-related assignments. Twenty-six percent said that they had, double the number two years ago. Just over half of teens responding to the poll said they think itâ€™s acceptable to use ChatGPT for researching new subjects. But considering the ways ChatGPT can fall short, the results are possibly cause for alarm. OpenAI says that it might store chats and associated screenshots from customers who use Operator,the companyâ€™s AI â€œagentâ€ tool,for up to 90 days â€” even after a user manually deletes them. While OpenAI has a similar deleted data retention policy for ChatGPT, the retention period for ChatGPT is only 30 days,which is 60 days shorter than Operatorâ€™s. OpenAI is launching a research preview of Operator, a general-purpose AI agent that cantake control of a web browser and independently perform certain actions.Operator promises to automate tasks such as booking travel accommodations, making restaurant reservations, and shopping online. Operator,OpenAIâ€™s agent tool,could be released sooner rather than later. Changes to ChatGPTâ€™s code base suggest thatOperator will be available as an early research previewto users on the $200 Pro subscription plan. The changes arenâ€™t yet publicly visible, buta user on X who goes by Choispotted these updates in ChatGPTâ€™s client-side code. TechCrunch separately identified the same references to Operator on OpenAIâ€™s website. OpenAI has begun testing a feature that lets new ChatGPT userssign up with only a phone numberâ€” no email required. The feature is currently in beta in the U.S. and India. However, users who create an account using their number canâ€™t upgrade to one of OpenAIâ€™s paid plans without verifying their account via an email. Multi-factor authentication also isnâ€™t supported without a valid email. ChatGPTâ€™s new beta feature, called tasks,allows users to set simple reminders. For example, you can ask ChatGPT to remind you when your passport expires in six months, and the AI assistant will follow up with a push notification on whatever platform you have tasks enabled. The feature will start rolling out to ChatGPT Plus, Team, and Pro users around the globe this week. OpenAI is introducing a new way for users tocustomize their interactions with ChatGPT.Some users found they can specify a preferred name or nickname and â€œtraitsâ€ theyâ€™d like the chatbot to have. OpenAI suggests traits like â€œChatty,â€ â€œEncouraging,â€ and â€œGen Z.â€ However,some users reportedthat the new options have disappeared, so itâ€™s possible they went live prematurely. ChatGPT Search can be fooled into generating completely misleading summaries,The Guardian has found.They found ChatGPT could be prompted to ignore negative reviews andgenerate â€œentirely positiveâ€ summariesby inserting hidden text into websites it created and that ChatGPT Search could also be made to spit out malicious code using this method. Microsoft and OpenAI have a veryspecific, internal definition of AGIbased on the startupâ€™s profits, according to a newreport from The Information.The two companies reportedly signed an agreement stating OpenAI has only achieved AGI when it develops AI systems that can generate at least $100 billion in profit, which is far from the rigorous technical and philosophical definition of AGI many would expect. OpenAIreleased new researchoutlining the companyâ€™s approach to ensure AI reasoning models stay aligned with the values of their human developers. The startup used â€œdeliberative alignmentâ€ to make o1 and o3â€œthinkâ€ about OpenAIâ€™s safety policy.According to OpenAIâ€™s research, the method decreased the rate at which o1 answered â€œunsafeâ€ questions while improving its ability to answer benign ones. OpenAI CEO Sam Altman announcedthe successors to its o1 reasoning model family:o3 and o3-mini. The models are not widely available yet, but safety researchers can sign up for a preview. The reveal marks the end of the â€œ12 Days of OpenAIâ€ event, which saw announcements for real-time vision capabilities, ChatGPT Search, and even a Santa voice for ChatGPT. In an effort to make ChatGPT accessible to as many people as possible, OpenAI announceda 1-800 number to call the chatbotâ€” even from a landline or a flip phone. Users can call 1-800-CHATGPT, and ChatGPT will respond to your queries in an experience that is more or less identical to Advanced Voice Mode â€” minus the multimodality. OpenAI is offering 15 minutes of free calling for U.S. users. The company notes that standard carrier fees may apply. OpenAI is bringing ChatGPT Searchto free, logged in users.Search gives ChatGPT the ability to access real-time information on the web to better answer your queries, but was only available for paid userswhen it launched in October.Not only is Search available now for free users, but itâ€™s also been integratedinto Advanced Voice Mode. OpenAI is blaming one of the longest outages in its history on a â€œnew telemetry serviceâ€ gone awry. OpenAI wrote in a postmortem that the outage wasnâ€™t caused by a security incident or recent product launch, but by atelemetry service it deployedto collect Kubernetes metrics. OpenAI announced that ChatGPT users could accessa new â€œSanta Modeâ€ voiceduring December. The feature allows users to speak with ChatGPTâ€™s Advanced Voice Mode, but with a Christmas twist. The voice sounds, well, â€œmerry and bright,â€ as OpenAI described it. Think boomy, jolly â€” more or less like every Santa youâ€™ve ever heard. OpenAI released thereal-time video capabilities for ChatGPTthat it demoed nearly seven months ago. ChatGPT Plus, Team, and Pro subscribers can use the app to point their phones at objects and have ChatGPT respond in near-real-time. The feature can also understand whatâ€™s on a deviceâ€™s screen through screen sharing. Thereâ€™s more to come from OpenAI through December 23. Tune in toour live blogto stay updated. ChatGPT and Sora both experienced a major outage Wednesday. Though users suspected the outage was due to the rollout of ChatGPT in Apple Intelligence, OpenAI developer community lead Edwin Arbusdenied it in a post on X, saying the â€œoutage was unrelated to 12 Days of OpenAI or Apple Intelligence. We made a config change that caused many servers to become unavailable.â€ ChatGPT, API, and Sora were down today but we've recovered.https://t.co/OKiQYp3tXE Canvas, OpenAIâ€™scollaboration-focused interfacefor writing and code projects, is now rolling out to all users after being in beta for ChatGPT Plus members since October 2024. The company also announced the ability to integrate Python code within Canvas as well as bringing Canvas to custom GPTs. OpenAI CEO Sam Altman posted on X that due to higher than expected demand, they are pausing new sign-ups for its video generator Sora and that video generations will be slower for the time being. Thecompany released Soraas part of its â€œ12 Days of OpenAIâ€ event followingnearly a year of teasing the product. demand higher than expected; signups will be disabled on and off and generations will be slow for awhile.doing our best!https://t.co/JU3WxE5bGl OpenAI has finally released itstext to video model, Sora.The model can generate videos up to 20 seconds long in 1080p based on text prompts or uploaded images, and can be â€œremixedâ€ through additional user prompts. Sora is available starting today toChatGPT Proand Plus subscribers (except in the EU). In Mondayâ€™sâ€œ12 Days of OpenAIâ€ livestream,CEO Sam Altman said that ChatGPT Plus members will get 50 video generations a month, while ChatGPT Pro users will get â€œunlimitedâ€ generations in their â€œslow queue modeâ€ and 500 â€œnormalâ€ generations per month. There are still more reveals to come from OpenAI through December 23. Tune in toour live blogto stay updated. On day one of its12 Days of OpenAI event,the company announced a new â€” and expensive â€” subscription plan. ChatGPT Pro is a$200-per-month tierthat provides unlimited access to all of OpenAIâ€™s models, including the full version of its o1 â€œreasoningâ€ model. The full version of o1, which wasreleased as a preview in September,can now reason about image uploads and has been trained to be â€œmore concise in its thinkingâ€ to improve response times. Over the next few weeks, weâ€™ll be updating all the news from OpenAI as it happenson our live blog.Follow along with us! OpenAI announcedâ€œ12 Days of OpenAI,â€which will feature livestreams every weekday starting December 5 at 10 a.m. PT. Each dayâ€™s stream is said to include either a product launch or a demo in varying sizes. ğŸ„ğŸ…starting tomorrow at 10 am pacific, we are doing 12 days of openai.each weekday, we will have a livestream with a launch or demo, some big ones and some stocking stuffers.weâ€™ve got some great stuff to share, hope you enjoy! merry christmas. At the New York Timesâ€™ Dealbook Summit, OpenAI CEO Sam Altman said that ChatGPT hassurpassed 300 million weekly active users.The milestone comes just a few months after the chatbothit 200 million weekly active usersin August 2024 and just over a year afterreaching 100 million weekly active usersin November 2023. ChatGPT users discovered an interesting phenomenon: the popular chatbot refused to answer questionsasked about a â€œDavid Mayer,â€and asking it to do so caused it to freeze up instantly. While the strange behavior spawned conspiracy theories, and a slew of other names being impacted, a much more ordinary reason may be at the heart of it:digital privacy requests. OpenAI is toying withthe idea of getting into ads.CFO Sarah Friartold the Financial Timesitâ€™s weighing an ads business model, with plans to be â€œthoughtfulâ€ about when and where ads appear â€” though she later stressed that the company has â€œno active plans to pursue advertising.â€ Still, the exploration may raise eyebrows given that Sam Altman recently saidads would be a â€œlast resort.â€ A group of Canadian media companies, including the Toronto Star and the Globe and Mail,have filed a lawsuit against OpenAI.The companies behind the suit said that OpenAI infringed their copyrights and are seeking to win monetary damages â€” and ban OpenAI from making further use of their work. OpenAI announced that its GPT-4o model has been updated to feature more â€œnaturalâ€ and â€œengagingâ€ creative writing abilities as well as more thorough responses and insights when accessing files uploaded by users. GPT-4o got an update ğŸ‰The modelâ€™s creative writing ability has leveled upâ€“more natural, engaging, and tailored writing to improve relevance & readability.Itâ€™s also better at working with uploaded files, providing deeper insights & more thorough responses. ChatGPTâ€™s Advanced Voice Mode featureis expanding to the web,allowing users to talk to the chatbot through their browser. The conversational feature is rolling out to ChatGPTâ€™s paying Plus, Enterprise, Teams, or Edu subscribers. Rolling out to ChatGPT paid users this week: Advanced Voice Mode on web! ğŸ˜We launched Advanced Voice Mode in our iOS and Android apps in September, and just recently brought them to our desktop apps (https://t.co/vVRYHXsbPD)â€”now weâ€™re excited to add web to the mix. This meansâ€¦pic.twitter.com/HtG5Km2OGh OpenAI announced the ChatGPT desktop app for macOScan now read code in a handful of developer-focused coding apps,such as VS Code, Xcode, TextEdit, Terminal, and iTerm2 â€” meaning that developers will no longer have to copy and paste their code into ChatGPT. When the feature is enabled, OpenAI will automatically send the section of code youâ€™re working on through its chatbot as context, alongside your prompt. Lilian Weng announced on X thatshe is departing OpenAI.Weng served as VP of research and safety since August, and before that was the head of OpenAIâ€™s safety systems team. Itâ€™s the latest in a long string of AIsafety researchers,policy researchers,andother executiveswho have exited the company in the last year. After working at OpenAI for almost 7 years, I decide to leave. I learned so much and now I'm ready for a reset and something new.Here is the note I just shared with the team. ğŸ©µpic.twitter.com/2j9K3oBhPC OpenAI stated that it told around 2 million users of ChatGPT to go elsewherefor information about the 2024 U.S. election,and instead recommended trusted news sources like Reuters and the Associated Press. In a blog post, OpenAI said that ChatGPT sent roughly a million people to CanIVote.org when they asked questions specific to voting in the lead-up to the election andrejected around 250,000 requests to generate imagesof the candidates over the same period. Adding to its collection of high-profile domain names,Chat.com now redirects to ChatGPT.Last year, it was reported that HubSpot co-founder and CTO Dharmesh Shah acquired Chat.com for $15.5 million, making it one of the top two all-time publicly reported domain sales â€” though OpenAI declined to state how much it paid for it. https://t.co/n494J9IuEN The former head of Metaâ€™s augmented reality glasses effortsis joining OpenAI to lead robotics and consumer hardware.Kalinowski is a hardware executive who began leadingMetaâ€™s AR glasses teamin March 2022. She oversaw the creation of Orion, the impressive augmented reality prototype that Meta recently showed off atits annual Connect conference. Apple is including an option to upgrade toChatGPT Plus inside its Settings app,according to an update to the iOS 18.2 betaspotted by 9to5Mac.This will give Apple users a direct route to sign up for OpenAIâ€™s premium subscription plan, which costs $20 a month. Ina Reddit AMA,OpenAI CEO Sam Altman admitted that a lack of compute capacity is one major factor preventing the company from shipping products as often as itâ€™d like, including the vision capabilities for Advanced Voice Modefirst teased in May.Altman also indicated that the next major release of DALL-E, OpenAIâ€™s image generator, has no launch timeline, and thatSora, OpenAIâ€™s video-generating tool,has also been held back. Altman also admitted tousing ChatGPT â€œsometimesâ€to answer questions throughout the AMA. OpenAIlaunched ChatGPT Search,an evolution of theSearchGPT prototypeit unveiled this summer. Powered by a fine-tuned version of OpenAIâ€™s GPT-4o model, ChatGPT Search serves up information and photos from the web along with links to relevant sources, at which point you can ask follow-up questions to refine an ongoing search. ğŸŒ Introducing ChatGPT search ğŸŒChatGPT can now search the web in a much better way than before so you get fast, timely answers with links to relevant web sources.https://t.co/7yilNgqH9Tpic.twitter.com/z8mJWS8J9c OpenAI has rolled out Advanced Voice Mode to ChatGPTâ€™s desktop apps for macOS and Windows. For Mac users, that means that both ChatGPTâ€™s Advanced Voice Modecan coexist with Sirion the same device, leading the way forChatGPTâ€™s Apple Intelligence integration. Big day for desktops.Advanced Voice is now available in the macOS and Windows desktop apps.https://t.co/mv4ACwIhzApic.twitter.com/HbwXbN9NkD Reuters reports that OpenAI is working with TSMC and Broadcomto build an in-house AI chip,which could arrive as soon as 2026. It appears, at least for now, the company has abandoned plans to establish a network of factories for chip manufacturing and is instead focusing on in-house chip design. OpenAI announced itâ€™s rolling out a feature that allows users to search through their ChatGPT chat histories on the web. The new feature will let users bring up an old chat to remember something or pick back up a chat right where it was left off. Weâ€™re starting to roll out the ability to search through your chat history on ChatGPT web.Now you can quickly & easily bring up a chat to reference, or pick up a chat where you left off.pic.twitter.com/YVAOUpFvzJ With therelease of iOS 18.1,Apple Intelligence features powered by ChatGPTare now available to users.The ChatGPT features include integrated writing tools, image cleanup, article summaries, and a typing input for the redesigned Siri experience. OpenAI denied reports that it is intending to release anAI model, code-named Orion,by December of this year. An OpenAI spokesperson told TechCrunch that they â€œdonâ€™t have plans to release a model code-named Orion this year,â€ but that leaves OpenAI substantial wiggle room. OpenAI has begun previewinga dedicated Windows app for ChatGPT.The company says the app is an early version and is currently only available to ChatGPT Plus, Team, Enterprise, and Edu users with a â€œfull experienceâ€ set to come later this year. OpenAI struck acontent deal with Hearst,the newspaper and magazine publisher known for the San Francisco Chronicle, Esquire, Cosmopolitan, ELLE, and others. The partnership will allow OpenAI to surface stories from Hearst publications with citations and direct links. OpenAI introduced a new way tointeract with ChatGPT called â€œCanvas.â€The canvas workspace allows for users to generate writing or code, then highlight sections of the work to have the model edit. Canvas is rolling out in beta to ChatGPT Plus and Teams, with a rollout to come to Enterprise and Edu tier users next week. When writing code, canvas makes it easier to track and understand ChatGPTâ€™s changes.It can also review code, add logs and comments, fix bugs, and port to other coding languages like JavaScript and Python.pic.twitter.com/Fxssd5pDl0 OpenAI hasclosed the largest VC round of all time.The startup announced it raised $6.6 billion in a funding round that values OpenAI at $157 billion post-money. Led by previous investor Thrive Capital, the new cash brings OpenAIâ€™s total raised to $17.9 billion, per Crunchbase. At the first of its 2024 Dev Day events, OpenAIannounced a new API toolthat will let developers build nearly real-time, speech-to-speech experiences in their apps, with the choice of using six voices provided by OpenAI. These voices are distinct from those offered for ChatGPT, and developers canâ€™t use third party voices, in order to prevent copyright issues. OpenAI is planning toraise the price of individual ChatGPT subscriptionsfrom $20 per month to $22 per month by the end of the year, according to a report from The New York Times. The report notes that a steeper increase could come over the next five years; by 2029, OpenAI expects itâ€™ll charge $44 per month for ChatGPT Plus. OpenAI CTO Mira Murati announcedthat she is leaving the companyafter more than six years. Hours after the announcement, OpenAIâ€™s chief research officer, Bob McGrew, and a research VP, Barret Zoph,also left the company.CEO Sam Altman revealed the two latest resignations in a post on X, along with leadership transition plans. i just posted this note to openai:Hi Allâ€“Mira has been instrumental to OpenAIâ€™s progress and growth the last 6.5 years; she has been a hugely significant factor in our development from an unknown research lab to an important company.When Mira informed me this morning thatâ€¦ After a delay, OpenAI is finallyrolling out Advanced Voice Modeto an expanded set of ChatGPTâ€™s paying customers. AVM is also getting a revamped design â€” the feature is now represented by a blue animated sphere instead of the animated black dots that were presented back in May. OpenAI is highlighting improvements in conversational speed, accents in foreign languages, and five new voices as part of the rollout. OpenAI is rolling out Advanced Voice Mode (AVM), an audio feature that makes ChatGPT more natural to speak with and includes five new voicespic.twitter.com/y97BCoob5b A video from YouTube creator ChromaLock showcased how to modify a TI-84 graphing calculator so that it can connect to the internetand access ChatGPT, touting it as the â€œultimate cheating device.â€ As demonstrated in the video, itâ€™s a pretty complicated process for the average high school student to follow â€” but it might stoke more concerns from teachers about the ongoing concerns about ChatGPT and cheating in schools. OpenAIunveiled a preview of OpenAI o1, also known as â€œStrawberry.â€ The collection of models are available in ChatGPT and via OpenAIâ€™s API: o1-preview and o1 mini. The company claims that o1 can more effectively reason through math and science and fact-check itself by spending more time considering all parts of a command or question. Unlike ChatGPT, o1 canâ€™t browse the web or analyze files yet, is rate-limited and expensive compared to other models. OpenAI says it plans to bring o1-mini access to all free users of ChatGPT, but hasnâ€™t set a release date. OpenAI o1 codes a video game from a prompt.pic.twitter.com/aBEcehP0j8 An artist and hacker founda way to jailbreak ChatGPTto produce instructions for making powerful explosives, a request that the chatbot normally refuses. An explosives expert who reviewed the chatbotâ€™s output told TechCrunch that the instructions could be used to make a detonatable product and was too sensitive to be released. OpenAI announced ithas surpassed 1 million paid usersfor its versions of ChatGPT intended for businesses, including ChatGPT Team, ChatGPT Enterprise and its educational offering, ChatGPT Edu. The company said that nearly half of OpenAIâ€™s corporate users are based in the US. Volkswagen is taking itsChatGPT voice assistant experimentto vehicles in the United States. Its ChatGPT-integrated Plus Speech voice assistant is an AI chatbot based on Cerenceâ€™s Chat Pro product and a LLM from OpenAI and will begin rolling out on September 6 with the 2025 Jetta and Jetta GLI models. As part of the new deal,OpenAI will surface stories from CondÃ© Nast propertieslike The New Yorker, Vogue, Vanity Fair, Bon AppÃ©tit and Wired in ChatGPT and SearchGPT. CondÃ© Nast CEO Roger Lynch implied that the â€œmulti-yearâ€ deal will involve payment from OpenAI in some form and a CondÃ© Nast spokesperson told TechCrunch that OpenAI will have permission to train on CondÃ© Nast content. Weâ€™re partnering with CondÃ© Nast to deepen the integration of quality journalism into ChatGPT and our SearchGPT prototype.https://t.co/tiXqSOTNAl TechCrunchâ€™s Maxwell Zeff has beenplaying around with OpenAIâ€™s Advanced Voice Mode,in what he describes as â€œthe most convincing taste Iâ€™ve had of an AI-powered future yet.â€ Compared to Siri or Alexa, Advanced Voice Mode stands out with faster response times, unique answers and the ability to answer complex questions. But the feature falls short as an effective replacement for virtual assistants. OpenAI has banned a cluster of ChatGPT accountslinked to an Iranian influence operationthat was generating content about the U.S. presidential election.OpenAI identified five website frontspresenting as both progressive and conservative news outlets that used ChatGPT to draft several long-form articles, though it doesnâ€™t seem that it reached much of an audience. OpenAI has found that GPT-4o, which powers the recently launched alpha ofAdvanced Voice Modein ChatGPT, can behave in strange ways. In a new â€œred teamingâ€ report, OpenAI reveals some ofGPT-4oâ€™s weirder quirks,like mimicking the voice of the person speaking to it or randomly shouting in the middle of a conversation. After a big jump following the release of OpenAIâ€™snew GPT-4o â€œomniâ€ model,the mobile version of ChatGPT has now seenits biggest month of revenue yet.The app pulled in $28 million in net revenue from the App Store and Google Play in July, according to data provided by app intelligence firm Appfigures. OpenAI has built a watermarking tool that could potentially catch students who cheat by using ChatGPT â€” butThe Wall Street Journal reportsthat the company is debating whether to actually release it. An OpenAI spokesperson confirmed to TechCrunch that the company is researching tools that can detect writing from ChatGPT, but said itâ€™s takinga â€œdeliberate approachâ€ to releasing it. OpenAI is giving users their first access toGPT-4oâ€™s updated realistic audio responses.The alpha version is now available to a small group of ChatGPT Plus users, and the company says the feature will gradually roll out to all Plus users in the fall of 2024. The release follows controversy surrounding thevoiceâ€™s similarity to Scarlett Johansson,leading OpenAI to delay its release. Weâ€™re starting to roll out advanced Voice Mode to a small group of ChatGPT Plus users. Advanced Voice Mode offers more natural, real-time conversations, allows you to interrupt anytime, and senses and responds to your emotions.pic.twitter.com/64O94EhhXK OpenAI istesting SearchGPT,a new AI search experience to compete with Google. SearchGPT aims to elevate search queries with â€œtimely answersâ€ from across the internet, as well as the abilityto ask follow-up questions.The temporary prototype is currently only available to a small group of users and its publisher partners, like The Atlantic, for testing and feedback. Weâ€™re testing SearchGPT, a temporary prototype of new AI search features that give you fast and timely answers with clear and relevant sources.Weâ€™re launching with a small group of users for feedback and plan to integrate the experience into ChatGPT.https://t.co/dRRnxXVlGhpic.twitter.com/iQpADXmllH A new report fromThe Information, based on undisclosed financial information, claims OpenAI could lose up to $5 billion due to how costly the business is to operate. The report also says the company could spend as much as $7 billion in 2024 to train and operate ChatGPT. OpenAI released its latest small AI model,GPT-4o mini. The company says GPT-4o mini, which is cheaper and faster than OpenAIâ€™s current AI models, outperforms industry leading small AI models on reasoning tasks involving text and vision. GPT-4o mini will replace GPT-3.5 Turbo as the smallest model OpenAI offers. OpenAI announced a partnership with theLos Alamos National Laboratoryto study how AI can be employed by scientists in order to advance research in healthcare and bioscience. This follows other health-related research collaborations at OpenAI, includingModernaandColor Health. OpenAI and Los Alamos National Laboratory announce partnership to study AI for bioscience researchhttps://t.co/WV4XMZsHBA OpenAI announced it has trained a model off of GPT-4,dubbed CriticGPT, which aims to find errors in ChatGPTâ€™s code output so they can make improvements and better help so-called human â€œAI trainersâ€ rate the quality and accuracy of ChatGPT responses. Weâ€™ve trained a model, CriticGPT, to catch bugs in GPT-4â€™s code. Weâ€™re starting to integrate such models into our RLHF alignment pipeline to help humans supervise AI on difficult tasks:https://t.co/5oQYfrpVBu OpenAI and TIME announceda multi-year strategic partnershipthat brings the magazineâ€™s content, both modern and archival, to ChatGPT. As part of the deal, TIME will also gain access to OpenAIâ€™s technology in order to develop new audience-based products. Weâ€™re partnering with TIME and its 101 years of archival content to enhance responses and provide links to stories onhttps://t.co/LgvmZUae9M:https://t.co/xHAYkYLxA9 OpenAI planned to start rolling out itsadvanced Voice Modefeature to a small group of ChatGPT Plus users in late June, but it sayslingering issues forced it to postponethe launch to July. OpenAI says Advanced Voice Mode might not launch for all ChatGPT Plus customers until the fall, depending on whether it meets certain internal safety and reliability checks. ChatGPT for macOS isnow available for all users. With the app, users can quickly call up ChatGPT by using the keyboard combination of Option + Space. The app allows users to upload files and other photos, as well as speak to ChatGPT from their desktop and search through their past conversations. The ChatGPT desktop app for macOS is now available for all users.Get faster access to ChatGPT to chat about email, screenshots, and anything on your screen with the Option + Space shortcut:https://t.co/2rEx3PmMqgpic.twitter.com/x9sT8AnjDm Apple announced atWWDC 2024that it isbringing ChatGPT to Siri and other first-party appsand capabilities across its operating systems. The ChatGPT integrations, powered by GPT-4o, will arrive on iOS 18, iPadOS 18 and macOS Sequoia later this year, and will be free without the need to create a ChatGPT or OpenAI account. Features exclusive to paying ChatGPT userswill also be available through Apple devices. Apple is bringing ChatGPT to Siri and other first-party apps and capabilities across its operating systems#WWDC24Read more:https://t.co/0NJipSNJoSpic.twitter.com/EjQdPBuyy4 Scarlett Johanssonhas been invited to testifyabout thecontroversy surrounding OpenAIâ€™s Sky voiceat a hearing for the House Oversight Subcommittee on Cybersecurity, Information Technology, and Government Innovation. In a letter, Rep. Nancy Mace said Johanssonâ€™s testimony could â€œprovide a platformâ€ for concerns around deepfakes. ChatGPT was downtwice in one day:onemulti-hour outagein the early hours of the morning Tuesday and another outage later in the day that is still ongoing. Anthropicâ€™s Claude and Perplexity also experienced some issues. You're not alone, ChatGPT is down once again.pic.twitter.com/Ydk2vNOOK6 The Atlantic and Vox Media have announcedlicensing and product partnerships with OpenAI. Both agreements allow OpenAI to use the publishersâ€™ current content to generate responses in ChatGPT, which will feature citations to relevant articles. Vox Media says it will use OpenAIâ€™s technology to buildâ€œaudience-facing and internal applications,â€while The Atlantic will builda new experimental product called Atlantic Labs. I am delighted that@theatlanticnow has a strategic content & product partnership with@openai. Our stories will be discoverable in their new products and we'll be working with them to figure out new ways that AI can help serious, independent media :https://t.co/nfSVXW9KpB OpenAI announced a new deal with managementconsulting giant PwC. The company will become OpenAIâ€™s biggest customer to date, covering 100,000 users, and will become OpenAIâ€™s first partner for selling its enterprise offerings to other businesses. OpenAI announced in a blog post that it hasrecently begun training its next flagship modelto succeed GPT-4. The news came in an announcement of its new safety and security committee, which is responsible for informing safety and security decisions across OpenAIâ€™s products. On the The TED AI Show podcast, former OpenAI board member Helen Toner revealed that the board did not know about ChatGPTuntil its launch in November 2022.Toner also said that Sam Altman gave the board inaccurate information about the safety processes the company had in place and that he didnâ€™t disclose his involvement in the OpenAI Startup Fund. Sharing this, recorded a few weeks ago. Most of the episode is about AI policy more broadly, but this was my first longform interview since the OpenAI investigation closed, so we also talked a bit about November.Thanks to@bilawalsidhufor a fun conversation!https://t.co/h0PtK06T0K The launch of GPT-4o has driven the companyâ€™sbiggest-ever spike in revenue on mobile, despite the model being freely available on the web. Mobile users are being pushed to upgrade to its $19.99 monthly subscription, ChatGPT Plus, if they want to experiment with OpenAIâ€™s most recent launch. After demoing its new GPT-4o model last week,OpenAI announced it is pausing one of its voices, Sky, after users found that it sounded similar to Scarlett Johansson in â€œHer.â€ OpenAI explainedin a blog postthat Skyâ€™s voice is â€œnot an imitationâ€ of the actress and that AI voices should not intentionally mimic the voice of a celebrity. The blog post went on to explain how the company chose its voices: Breeze, Cove, Ember, Juniper and Sky. Weâ€™ve heard questions about how we chose the voices in ChatGPT, especially Sky. We are working to pause the use of Sky while we address them.Read more about how we chose these voices:https://t.co/R8wwZjU36L OpenAI announcednew updates for easier data analysis within ChatGPT. Users can now upload files directly from Google Drive and Microsoft OneDrive, interact with tables and charts, and export customized charts for presentations. The company says these improvementswill be added to GPT-4oin the coming weeks. We're rolling out interactive tables and charts along with the ability to add files directly from Google Drive and Microsoft OneDrive into ChatGPT. Available to ChatGPT Plus, Team, and Enterprise users over the coming weeks.https://t.co/Fu2bgMChXtpic.twitter.com/M9AHLx5BKr OpenAIannounced a partnership with Redditthat will give the company access to â€œreal-time, structured and unique contentâ€ from the social network. Content from Reddit will be incorporated into ChatGPT, and the companies will work together to bring new AI-powered features to Reddit users and moderators. Weâ€™re partnering with Reddit to bring its content to ChatGPT and new products:https://t.co/xHgBZ8ptOE OpenAIâ€™s spring update event saw the reveal ofits new omni model, GPT-4o,which has ablack hole-like interface, as well as voice and vision capabilities that feel eerily like something out of â€œHer.â€ GPT-4o is set to roll out â€œiterativelyâ€ across its developer and consumer-facing products over the next few weeks. OpenAI demos real-time language translation with its latest GPT-4o model.pic.twitter.com/pXtHQ9mKGc The company announced itâ€™s building a tool, Media Manager, that willallow creators to better control how their content is being usedto train generative AI models â€” and give them an option to opt out. The goal is to have the new toolin place and ready to use by 2025. In a newpeek behind the curtain of its AIâ€™s secret instructions, OpenAI also releaseda new NSFW policy. Though itâ€™s intended to start a conversation about how it might allow explicit images and text in its AI products, it raises questions about whether OpenAI â€” or any generative AI vendor â€” can be trusted to handle sensitive content ethically. In a new partnership,OpenAI will get access to developer platform Stack Overflowâ€™s APIand will get feedback from developers to improve the performance of their AI models. In return, OpenAI will include attributions to Stack Overflow in ChatGPT. However, the deal was not favorable to some Stack Overflow users â€”leading to some sabotaging their answer in protest. Alden Global Capital-owned newspapers, including the New York Daily News, the Chicago Tribune, and the Denver Post,are suing OpenAI and Microsoft for copyright infringement.The lawsuit alleges that the companies stole millions of copyrighted articles â€œwithout permission and without paymentâ€ to bolster ChatGPT and Copilot. OpenAI has partnered with another news publisher in Europe,Londonâ€™s Financial Times, that the company will be paying for content access. â€œThrough the partnership, ChatGPT users will be able to see select attributed summaries, quotes and rich links to FT journalism in response to relevant queries,â€the FT wrote in a press release. OpenAI isopening a new office in Tokyoand has plans for a GPT-4 model optimized specifically for the Japanese language. The move underscores how OpenAI will likely need to localize its technology to different languages as it expands. According to Reuters, OpenAIâ€™sSam Altman hosted hundreds of executivesfrom Fortune 500 companies across several cities in April, pitching versions of its AI services intended for corporate use. Premium ChatGPT users â€” customers paying for ChatGPT Plus, Team or Enterprise â€” can now usean updated and enhanced version of GPT-4 Turbo. The new model brings with it improvements in writing, math, logical reasoning and coding, OpenAI claims, as well as a more up-to-date knowledge base. Our new GPT-4 Turbo is now available to paid ChatGPT users. Weâ€™ve improved capabilities in writing, math, logical reasoning, and coding.Source:https://t.co/fjoXDCOnPrpic.twitter.com/I4fg4aDq1T You can now use ChatGPTwithout signing up for an account, but it wonâ€™t be quite the same experience. You wonâ€™t be able to save or share chats, use custom instructions, or other features associated with a persistent account. This version of ChatGPT will have â€œslightly more restrictive content policies,â€ according to OpenAI. When TechCrunch asked for more details, however, the response was unclear: â€œThe signed out experience will benefit from the existing safety mitigations that are already built into the model, such as refusing to generate harmful content. In addition to these existing mitigations, we are also implementing additional safeguards specifically designed to address other forms of content that may be inappropriate for a signed out experience,â€ a spokesperson said. TechCrunch found that the OpenAIâ€™s GPT Storeis flooded with bizarre, potentially copyright-infringing GPTs. A cursory search pulls up GPTs that claim to generate art in the style of Disney and Marvel properties, but serve as little more than funnels to third-party paid services and advertise themselves as being able to bypass AI content detection tools. In acourt filing opposing OpenAIâ€™s motion to dismiss The New York Timesâ€™ lawsuitalleging copyright infringement, the newspaper asserted that â€œOpenAIâ€™s attention-grabbing claim that The Times â€˜hackedâ€™ its products is as irrelevant as it is false.â€ The New York Times also claimed that some users of ChatGPT used the tool to bypass its paywalls. At a SXSW 2024 panel, Peter Deng, OpenAIâ€™s VP of consumer product dodged a question on whetherartists whose work was used to train generative AI models should be compensated. While OpenAI lets artists â€œopt outâ€ of and remove their work from the datasets that the company uses to train its image-generating models, some artists have described the tool as onerous. ChatGPTâ€™s environmental impact appears to be massive. According to areport from The New Yorker, ChatGPT uses an estimated 17,000 times the amount of electricity than the average U.S. household to respond to roughly 200 million requests each day. OpenAI released a newRead Aloud featurefor the web version of ChatGPT as well as the iOS and Android apps. The feature allows ChatGPT to read its responses to queries in one of five voice options and can speak 37 languages, according to the company. Read aloud is available on both GPT-4 and GPT-3.5 models. ChatGPT can now read responses to you. On iOS or Android, tap and hold the message and then tap â€œRead Aloudâ€. Weâ€™ve also started rolling on web â€“ click the \"Read Aloud\" button below the message.pic.twitter.com/KevIkgAFbG â€” OpenAI (@OpenAI)March 4, 2024  As part of a new partnership with OpenAI,the Dublin City Council will use GPT-4to craft personalized itineraries for travelers, including recommendations of unique and cultural destinations, in an effort to support tourism across Europe. New York-based law firm Cuddy Law was criticized by a judge forusing ChatGPT to calculate their hourly billing rate. The firm submitted a $113,500 bill to the court, which was then halved by District Judge Paul Engelmayer, who called the figure â€œwell aboveâ€ reasonable demands. ChatGPT users found that ChatGPT was givingnonsensical answers for several hours, prompting OpenAI to investigate the issue. Incidents varied from repetitive phrases to confusing and incorrect answers to queries. The issue was resolved by OpenAI the following morning. The dating app giant home to Tinder, Match and OkCupid announced an enterprise agreement with OpenAIin an enthusiastic press release written with the help of ChatGPT. The AI tech willbe used to help employees with work-related tasksand come as part of Matchâ€™s $20 million-plus bet on AI in 2024. As part of a test,OpenAI began rolling out new â€œmemoryâ€ controlsfor a small portion of ChatGPT free and paid users, with a broader rollout to follow. The controls let you tell ChatGPT explicitly to remember something, see what it remembers or turn off its memory altogether. Note that deleting a chat from chat history wonâ€™t erase ChatGPTâ€™s or a custom GPTâ€™s memories â€” you must delete the memory itself. Weâ€™re testing ChatGPT's ability to remember things you discuss to make future chats more helpful. This feature is being rolled out to a small portion of Free and Plus users, and it's easy to turn on or off.https://t.co/1Tv355oa7Vpic.twitter.com/BsFinBSTbs â€” OpenAI (@OpenAI)February 13, 2024  Initially limited to a small subset of free and subscription users, Temporary Chat lets you have a dialogue with a blank slate. With Temporary Chat, ChatGPT wonâ€™t be aware of previous conversations or access memories but will follow custom instructions if theyâ€™re enabled. But, OpenAI says it may keep a copy of Temporary Chat conversations for up to 30 days for â€œsafety reasons.â€ Use temporary chat for conversations in which you donâ€™t want to use memory or appear in history.pic.twitter.com/H1U82zoXyC â€” OpenAI (@OpenAI)February 13, 2024  Paid users of ChatGPT cannow bring GPTs into a conversationby typing â€œ@â€ and selecting a GPT from the list. The chosen GPT will have an understanding of the full conversation, and different GPTs can be â€œtagged inâ€ for different use cases and needs. You can now bring GPTs into any conversation in ChatGPT â€“ simply type @ and select the GPT. This allows you to add relevant GPTs with the full context of the conversation.pic.twitter.com/Pjn5uIy9NF â€” OpenAI (@OpenAI)January 30, 2024  Screenshots provided to Ars Technica found thatChatGPT is potentially leaking unpublished research papers, login credentials and private informationfrom its users. An OpenAI representative told Ars Technica that the company was investigating the report. OpenAI has been tolditâ€™s suspected of violating European Union privacy, following a multi-month investigation of ChatGPT by Italyâ€™s data protection authority. Details of the draft findings havenâ€™t been disclosed, but in a response, OpenAI said: â€œWe want our AI to learn about the world, not about private individuals.â€ In an effort to win the trust of parents and policymakers,OpenAI announced itâ€™s partnering with Common Sense Mediato collaborate on AI guidelines and education materials for parents, educators and young adults. The organization works to identify and minimize tech harms to young people and previously flagged ChatGPT aslacking in transparency and privacy. Aftera letter from the Congressional Black Caucusquestioned the lack of diversity in OpenAIâ€™s board, the companyresponded. The response, signed by CEO Sam Altman and Chairman of the Board Bret Taylor, said building a complete and diverse board was one of the companyâ€™s top priorities and that it was working with an executive search firm to assist it in finding talent. Ina blog post, OpenAI announced price drops for GPT-3.5â€™s API, with input prices dropping to 50% and output by 25%, to $0.0005 per thousand tokens in, and $0.0015 per thousand tokens out. GPT-4 Turbo also got a new preview model for API use, which includes an interesting fix thataims to reduce â€œlazinessâ€that users have experienced. Expanding the platform for@OpenAIDevs: new generation of embedding models, updated GPT-4 Turbo, and lower pricing on GPT-3.5 Turbo.https://t.co/7wzCLwB1ax â€” OpenAI (@OpenAI)January 25, 2024  OpenAI has suspended AI startup Delphi, whichdeveloped a bot impersonating Rep. Dean Phillips (D-Minn.)to help bolster his presidential campaign. The ban comes just weeks after OpenAI published a plan to combat election misinformation, which listed â€œchatbots impersonating candidatesâ€ as against its policy. Beginning in February,Arizona State University will have full access to ChatGPTâ€™s Enterprise tier, which the university plans to use to build a personalized AI tutor, develop AI avatars, bolster their prompt engineering course and more. It marks OpenAIâ€™s first partnership with a higher education institution. After receiving the prestigious Akutagawa Prize for her novel The Tokyo Tower of Sympathy, author Rie Kudanadmitted that around 5% of the book quoted ChatGPT-generated sentencesâ€œverbatim.â€Interestingly enough, the novel revolves around a futuristic world with a pervasive presence of AI. In a conversation with Bill Gates on theUnconfuse Mepodcast, Sam Altman confirmed an upcoming release of GPT-5 that will be â€œfully multimodal with speech, image, code, and video support.â€ Altman said users can expect to see GPT-5 drop sometime in 2024. OpenAI is forming aCollective Alignment teamof researchers and engineers to create a system for collecting and â€œencodingâ€ public input on its modelsâ€™ behaviors into OpenAI products and services. This comes as a part of OpenAIâ€™s public program to award grants to fund experiments in setting up a â€œdemocratic processâ€ for determining the rules AI systems follow. In a blog post, OpenAI announcedusers will not be allowed to build applications for political campaigning and lobbying until the company works out how effective their tools are for â€œpersonalized persuasion.â€ Users will also be banned from creating chatbots that impersonate candidates or government institutions, and from using OpenAI tools to misrepresent the voting process or otherwise discourage voting. The company is also testing out a tool that detects DALL-E generated images and will incorporate access to real-time news, with attribution, in ChatGPT. Snapshot of how weâ€™re preparing for 2024â€™s worldwide elections: â€¢ Working to prevent abuse, including misleading deepfakesâ€¢ Providing transparency on AI-generated contentâ€¢ Improving access to authoritative voting informationhttps://t.co/qsysYy5l0L â€” OpenAI (@OpenAI)January 15, 2024  Inan unannounced update to its usage policy, OpenAI removed language previously prohibiting the use of its products for the purposes of â€œmilitary and warfare.â€ In an additional statement, OpenAI confirmed that the language was changed in order to accommodate military customers and projects that do not violate their ban on efforts to use their tools to â€œharm people, develop weapons, for communications surveillance, or to injure others or destroy property.â€ Aptly called ChatGPT Team, the new plan provides a dedicated workspace for teams of up to 149 people using ChatGPT as well as admin tools for team management. In addition to gaining access to GPT-4, GPT-4 with Vision and DALL-E3, ChatGPT Team lets teams build and share GPTs for their business needs. After some back and forth over the last few months,OpenAIâ€™s GPT Store is finally here. The feature lives in a new tab in the ChatGPT web client, and includes a range of GPTs developed both by OpenAIâ€™s partners and the wider dev community. To access the GPT Store, users must be subscribed to one of OpenAIâ€™s premium ChatGPT plans â€” ChatGPT Plus, ChatGPT Enterprise or the newly launched ChatGPT Team. the GPT store is live!https://t.co/AKg1mjlvo2 fun speculation last night about which GPTs will be doing the best by the end of today. â€” Sam Altman (@sama)January 10, 2024  Following a proposedban on using news publications and books to train AI chatbotsin the U.K., OpenAI submitted a plea to the House of Lords communications and digital committee. OpenAI argued that it would be â€œimpossibleâ€ to train AI models without using copyrighted materials, and that they believe copyright law â€œdoes not forbid training.â€ OpenAI published a public responseto The New York Timesâ€™s lawsuit against them and Microsoft for allegedly violating copyright law, claiming that the case is without merit. In the response, OpenAI reiterates its view that training AI models using publicly available data from the web is fair use. It also makes the case that regurgitation is less likely to occur with training data from a single source and places the onus on users to â€œact responsibly.â€ We build AI to empower people, including journalists. Our position on the@nytimeslawsuit:â€¢ Training is fair use, but we provide an opt-outâ€¢ \"Regurgitation\" is a rare bug we're driving to zeroâ€¢ The New York Times is not telling the full storyhttps://t.co/S6fSaDsfKb â€” OpenAI (@OpenAI)January 8, 2024  After beingdelayed in December,OpenAI plans to launch its GPT Storesometime in the coming week, according to an email viewed by TechCrunch. OpenAI says developers building GPTs will have to review the companyâ€™s updated usage policies and GPT brand guidelines to ensure their GPTs are compliant before theyâ€™re eligible for listing in the GPT Store. OpenAIâ€™s update notably didnâ€™t include any information on the expected monetization opportunities for developers listing their apps on the storefront. GPT Store launching next week â€“ OpenAIpic.twitter.com/I6mkZKtgZG â€” Manish Singh (@refsrc)January 4, 2024  In an email,OpenAI detailed an incoming updateto its terms, including changing the OpenAI entity providing services to EEA and Swiss residents to OpenAI Ireland Limited. The move appears to be intended to shrink its regulatory risk in the European Union, where the company has been under scrutiny over ChatGPTâ€™s impact on peopleâ€™s privacy. ChatGPT is a general-purpose chatbot that uses artificial intelligence to generate text after a user enters a prompt, developed by tech startupOpenAI. The chatbot uses GPT-4, a large language model that uses deep learning to produce human-like text. November 30, 2022 is when ChatGPT was released for public use. Both the free version of ChatGPT and the paid ChatGPT Plus are regularly updated with new GPT models. The most recent model isGPT-4o. There is a free version ofChatGPTthat only requires a sign-in in addition to the paid version,ChatGPT Plus. Anyone can use ChatGPT! More and more tech companies andsearch enginesare utilizing the chatbot to automate text or quickly answer user questions/concerns. Multiple enterprises utilize ChatGPT, although others maylimit the use of the AI-powered tool. Most recently,Microsoft announcedat its 2023 Build conference that it is integrating it ChatGPT-based Bing experience into Windows 11. A Brooklyn-based 3D display startupLooking Glass utilizes ChatGPTto produce holograms you can communicate with by using ChatGPT.Â  And nonprofit organizationSolana officially integrated the chatbotinto its network with a ChatGPT plug-in geared toward end users to help onboard into the web3 space. GPT stands for Generative Pre-Trained Transformer. A chatbot can be any software/system that holds dialogue with you/a person but doesnâ€™t necessarily have to be AI-powered. For example, there are chatbots that are rules-based in the sense that theyâ€™ll give canned responses to questions. ChatGPT is AI-powered and utilizes LLM technology to generate text after a prompt. Yes. Due to the nature of how these models work, they donâ€™t know or care whether something is true, only that it looks true. Thatâ€™s a problem when youâ€™re using it to do your homework, sure, but when it accuses you of a crime you didnâ€™t commit, that may well at this point be libel. We will see howhandling troubling statements produced by ChatGPTwill play out over the next few months as tech and legal experts attempt to tackle the fastest moving target in the industry. Yes,there is a free ChatGPT mobile appfor iOS and Android users. Itâ€™s not documented anywhere that ChatGPT has a character limit. However, users have noted that there are some character limitations after around 500 words. Yes, it wasreleasedMarch 1, 2023. Everyday examples include programming, scripts, email replies, listicles, blog ideas, summarization, etc. Advanced use examples include debugging code, programming languages, scientific concepts, complex problem solving, etc. It depends on the nature of the program. While ChatGPT can write workable Python code, it canâ€™t necessarily program an entire appâ€™s worth of code. Thatâ€™s because ChatGPT lacks context awareness â€” in other words, the generated code isnâ€™t always appropriate for the specific context in which itâ€™s being used. Yes. OpenAI allows users to save chats in the ChatGPT interface, stored in the sidebar of the screen. There are no built-in sharing features yet. Yes. There aremultiple AI-powered chatbotcompetitors such asTogether, Googleâ€™sGeminiand Anthropicâ€™sClaude, and developers arecreating open sourcealternatives. OpenAI hasÂ saidÂ that individuals in â€œcertain jurisdictionsâ€ (such as the EU) can object to the processing of their personal information by its AI models by filling outthis form. This includes the ability to make requests for deletion of AI-generated references about you. Although OpenAI notes it may not grant every request since it must balance privacy requests against freedom of expression â€œin accordance with applicable lawsâ€. The web form for making a deletion of data about you request is entitled â€œOpenAI Personal Data Removal Requestâ€. In its privacy policy, the ChatGPT maker makes a passing acknowledgement of the objection requirements attached to relying on â€œlegitimate interestâ€ (LI), pointing users towards more information about requesting an opt out â€” when it writes: â€œSeeherefor instructions on how you can opt out of our use of your information to train our models.â€ Recently, Discord announced that it had integrated OpenAIâ€™s technology into its bot named Clyde wheretwo users tricked Clyde into providing them with instructions for making the illegal drug methamphetamine(meth) and the incendiary mixture napalm. An Australian mayor has publicly announcedhe may sue OpenAI for defamationdue to ChatGPTâ€™s false claims that he had served time in prison for bribery. This would be the first defamation lawsuit against the text-generating service. CNET found itself in the midst of controversy afterFuturism reportedthe publication was publishing articles under a mysterious byline completely generated by AI. The private equity company that owns CNET, Red Ventures, wasaccusedof using ChatGPT for SEO farming, even if the information was incorrect. Several major school systems and colleges,including New York City Public Schools, have banned ChatGPT from their networks and devices. They claim that the AI impedes the learning process by promoting plagiarism and misinformation, a claim thatnot every educator agrees with. There have also been cases of ChatGPTaccusing individuals of false crimes. Several marketplaces host and provide ChatGPT prompts, either for free or for a nominal fee. One isPromptBase. Another isChatX. More launch every day. Poorly. Several tools claim to detect ChatGPT-generated text, but in ourtests, theyâ€™re inconsistent at best. No. But OpenAIrecentlydisclosed a bug, since fixed, that exposed the titles of some usersâ€™ conversations to other people on the service. None specifically targeting ChatGPT. But OpenAI isinvolvedin at least one lawsuit that has implications for AI systems trained on publicly available data, which would touch on ChatGPT. Yes. Text-generating AI models like ChatGPT have a tendency to regurgitate content from their training data.",
        "date": "2025-02-12T21:34:24.562383+00:00",
        "source": "techcrunch.com"
    },
    {
        "title": "OpenAI cancels its o3 AI model in favor of a â€˜unifiedâ€™ next-gen release",
        "link": "https://techcrunch.com/2025/02/12/openai-cancels-its-o3-ai-model-in-favor-of-a-unified-next-gen-release/",
        "text": "OpenAI has effectively canceled the release ofo3, which was slated to be the companyâ€™s next major AI model release, in favor of what CEO Sam Altman is calling a â€œsimplifiedâ€ product offering. In apost on X on Wednesday, Altman said that, in the coming months, OpenAI will release a model called GPT-5 that â€œintegrates a lot of [OpenAIâ€™s] technology,â€ including o3, in its AI-powered chatbot platformChatGPTand API. As a result of that roadmap decision, OpenAI no longer plans to release o3 as a stand-alone model. The company originally said in December that it planned to launch o3 sometime early this year. Just a few weeks ago, Kevin Weil, OpenAIâ€™s chief product officer,said in an interviewthat o3 was on track for a â€œFebruary-Marchâ€ launch. â€œWe want to do a better job of sharing our intended roadmap, and a much better job simplifying our product offerings,â€ Altman wrote in the post. â€œWe want AI to â€˜just workâ€™ for you; we realize how complicated our model and product offerings have gotten. We hate the model picker [in ChatGPT] as much as you do and want to return to magic unified intelligence.â€ Altman also announced that OpenAI plans to offer unlimited chat access to GPT-5 at the â€œstandard intelligence setting,â€ subject to â€œabuse thresholds,â€ once the model is generally available. (Altman declined to provide more detail on what this setting â€” and these abuse thresholds â€” entail.) Subscribers to ChatGPT Plus will be able to run GPT-5 at a â€œhigher level of intelligence,â€ Altman said, while ChatGPT Pro subscribers will be able to run GPT-5 at an â€œeven higher level of intelligence.â€ â€œThese models will incorporate voice, canvas, search, deep research, and more,â€ Altman said, referring to a range of features OpenAI has launched in ChatGPT over the past few months. â€œ[A] top goal for us is to unify [our] models by creating systems that can use all our tools, know when to think for a long time or not, and generally be useful for a very wide range of tasks.â€ Before GPT-5 launches, OpenAI plans to release its GPT-4.5 model, code-named â€œOrion,â€ in the next several weeks, according to Altmanâ€™s post on X. Altman says this will be the companyâ€™s last â€œnon-chain-of-thought model.â€ Unlike o3 and OpenAIâ€™s other reasoning models, non-chain-of-thought models tend to be less reliable in domains like math and physics. From the sounds of it, OpenAI is fully embracing the reasoning model trend it arguably kickstarted with its first reasoning model,o1, late last year. Reasoning models effectively fact-check themselves, whichhelps them to avoid some of theÂ pitfallsÂ that normally trip up models. This fact-checking process incurs some latency â€” reasoning models take a little longer, usually seconds to minutes longer, to arrive at solutions. But they tend to be both more reliable and capable. Chinese AI lab DeepSeek captured the worldâ€™s attention recently with its R1 model, which matched o1 on a number of benchmarks. As opposed to o1, R1 is an â€œopenâ€ model under a permissive license, meaning it can be downloaded and used as developers see fit. In recent social media posts, Altmanadmittedthat DeepSeek has lessened OpenAIâ€™s technological lead in AI, andsaidthat OpenAI would â€œpull up some releasesâ€ to better compete. GPT-4.5, or Orion, is said to have suffered a number of performance-related challenges and technical setbacks.Bloomberg,The Information, andThe Wall Street Journalhave independently reported that Orion has shown less of an improvement over its predecessor,GPT-4o, than GPT-4 did over GPT-3.",
        "date": "2025-02-12T21:34:25.098701+00:00",
        "source": "techcrunch.com"
    },
    {
        "title": "Apple is reportedly exploring humanoid robots",
        "link": "https://techcrunch.com/2025/02/12/apple-is-reportedly-exploring-humanoid-robots/",
        "text": "Apple is exploring both humanoid and non-humanoid robotic form factors, according toa new scoopfrom longtime Apple analyst Ming-Chi Kuo. The intel comes on the heels ofa research paperfrom the iPhone maker that explores human interactions with â€œnon-anthropomorphicâ€ robots â€” specifically a Pixar-style lamp. While Appleâ€™s research paper highlights elements that could inform an eventual consumer robot, the work primarily shines a light on progress from a company still mired in the early research stages of a complex field. Kuo qualifies the work as â€œearly proof-of-concept,â€ adding that the Apple Car project waseffectively abandonedin a similarly early stage. Citing â€œcurrent progress and typical development cycles,â€ Kuo projects 2028 as an optimistic timeline for mass production. What makes robots unique compared to other early-stage Apple projects â€” such as a rumoredfoldable iPhoneâ€” is the level of transparency from the notoriously tight-lipped Apple. (This is the same company that, as part of a legal settlement, recently demanded a public apology from a former iOS engineerwho leaked detailsabout the Vision Pro.) Itâ€™s unavoidable. Progress in robotics is supported by work from universities and research facilities, along with behind-the-scenes corporate projects. For the past several years, many robotics companies have faced difficulties hiring quickly enough to support release timelines that have accelerated in the age of generative AI. Publishing research for the public to read is a great resource for recruiting engineers. Kuo suggests that the research paperâ€™s use of the â€œnon-anthropomorphicâ€ qualifier is designed to distinguish the robot from humanoid research. â€œWhile the industry debates the merits of humanoid vs. non-humanoid designs,â€ he writes, â€œsupply chain checks indicate Apple cares more about how users build perception with robots than their physical appearanceÂ â€¦ implying sensing hardware and software serve as the core technologies.â€ Broadly speaking, â€œanthropomorphicâ€ can be applied to robotic systems beyond what we might normally classify as a humanoid. This includes systems that are influenced by human characteristics but arenâ€™t exactly a one-to-one humanoid with two arms, two legs, and a face. Apple appears to currently be in the â€œthrow it at the wallâ€ phase, with work ranging from simple systems to complex humanoids. Kuo broadly refers to the proof-of-concept system as part of a â€œfuture smart home ecosystem.â€ That could mean anything from a full humanoid designed for household chores toa smart home display with a mechanical arm. Leaks around the work have suggested the latter â€” which is far more plausible than coming out of the gate with a humanoid capable of folding your laundry. Such a product could have a place on a far-off road map, but to get there, Apple first needs to prove that people want a home robot that isnâ€™t just a vacuum. Numerous companies that are building industrial humanoids, including 1X, Figure, and Apptronik, are researching a path from the factory floor to the home. Pricing and reliability are two major sticking points. If you think the $3,499 Vision Pro was a tough pill to swallow, wait until you see the first batch of humanoids for the home. For now, the goal is getting reliable industrial humanoid production to scale, which will bring the price down over time. After abandoning the Apple Car and stumbling out the gate with both the Vision Pro and Apple Intelligence, itâ€™s fair to assume that Apple is taking a cautious approach to robots. While Apple has a solid track record of popularizing existing product categories, Silicon Valley is littered with the husks of failed home robots. The same can also be said for the smart home category. One thing we can say for certain is that Apple is actively exploring robotics. Beyond that, we can probably look forward to at least another three years of leaks and speculation. ",
        "date": "2025-02-12T21:34:25.608409+00:00",
        "source": "techcrunch.com"
    },
    {
        "title": "Ingen titel hittad",
        "link": "https://techcrunch.com/2025/02/12/report-meta-in-talks-to-acquire-ai-chip-firm-furiosaai/",
        "text": "Meta is reportedly in talks to acquire a South Korean chip firm as the social media giant looks to bolster its AI hardware infrastructure. Meta may announce its intentto purchaseFuriosaAI, a chip startup founded by former Samsung and AMD employees, as soon as this month, per Forbes. FuriosaAI develops chips that speed up the running and serving of AI models, including text-generating models like Metaâ€™sLlama 2andLlama 3. To date, FuriosaAI has raised 90 billion Korean won (around $61.94 million) from investors, including South Korean tech company Naver,according to Crunchbase. The company has previously said it is engaged with unnamed potential customers in the U.S., Japan, and India. Metaâ€™s move is likely an effort to reduce its reliance on dominant chipmaker Nvidia and a complement to Metaâ€™sin-house attempts to build efficient AI accelerator chips. Meta recently said that it expects tospend up to $65 billion this year to power its AI goals.",
        "date": "2025-02-12T21:34:26.112485+00:00",
        "source": "techcrunch.com"
    },
    {
        "title": "This Week in AI: Musk bids for OpenAI",
        "link": "https://techcrunch.com/2025/02/12/this-week-in-ai-musk-bids-for-openai/",
        "text": "Hiya, folks, welcome to TechCrunchâ€™s regular AI newsletter. If you want this in your inbox every Wednesday, sign uphere. The billionaires are fighting again. On Monday, Elon Musk, the worldâ€™s richest man,offeredÂ to buy the nonprofitthat effectively governs OpenAI for $97.4 billion. In response to Muskâ€™s offer, OpenAI CEO Sam Altman earlier Monday authoreda cheeky post on X, writing, â€œNo thank you, but we will buy Twitter for $9.74 billion if you want.â€ (Musk and investors famouslypurchased Twitter for $44 billionin 2022.) Muskâ€™s bid, serious or not, may complicate OpenAIâ€™s effort to convert to a for-profit public benefit corporation within two years. Now OpenAIâ€™s board will have to demonstrate itâ€™s not underselling OpenAIâ€™s nonprofit by handing the nonprofitâ€™s assets, including IP from OpenAIâ€™s research, to an insider (e.g., Altman) for a discount. OpenAI could make the case that Muskâ€™s bid is a hostile takeover attempt given that Musk and Altmanarenâ€™t the best of friends. It could also argue that Muskâ€™s offer isnâ€™t credible because OpenAI is already in the midst of a restructuring process. Or OpenAI couldchallenge Musk on whether he has the funds. In astatement Tuesday, Andy Nussbaum, outside counsel representing OpenAIâ€™s board, said that Muskâ€™s bid â€œdoesnâ€™t set a value for [OpenAIâ€™s] nonprofitâ€ and that the nonprofit is â€œnot for sale.â€ Nussbaum added, â€œRespectfully, it is not up to a competitor to decide what is in the best interests of OpenAIâ€™s mission.â€My colleague Maxwell Zeff and Iwrote a more detailed pieceon what to expect in the coming weeks. But guaranteed, Muskâ€™s offer â€” not to mention hisongoing lawsuit against OpenAI over what he claims is fraudulent conductâ€” promises to make for fierce courtroom brawls. Appleâ€™s new robot:Apple created a research robot that takes a page from Pixarâ€™s playbook. The companyâ€™s robotic lamp operates as a more kinetic version of a HomePod or other smart speaker. The person facing the lamp asks a query, and the robot responds in Siriâ€™s voice. Is AI making us dumb?:ResearchersÂ recently published a studyÂ looking at how using generative AI at work affects critical thinking skills. It found that when we rely too much on AI to think for us, we get worse at solving problems ourselves when AI fails. AI for all, perhaps:In aÂ new essay on his personal blog, Altman admitted that AIâ€™s benefits may not be widely distributed â€” and said that OpenAI is open to â€œstrange-soundingâ€ ideas like a â€œcompute budgetâ€ to â€œenable everyone on Earth to use a lot of AI.â€ Christieâ€™s controversy:Fine art auction house Christieâ€™sÂ has sold AI-generated art before. But soon it plans to hold its first show dedicated solely to works created with AI, an announcement that has been met with mixed reviews â€” and a petition calling for the auctionâ€™s cancellation. Better than gold:An AI system developed by Google DeepMind, Googleâ€™s leading AI research lab, appears to have surpassed the average gold medalist in solving geometry problems in an international mathematics competition. We know that most AI models canâ€™t perform basic tasks reliably, like solving grade-school-level math problems. What we donâ€™t always know isthe reasonbehind their failures. According to a team of researchers at MIT CSAIL, erroneous benchmarks may be in part to blame. In a new study, the MIT CSAIL researchers found that while todayâ€™s top-performing models still make genuine mistakes on popular AI benchmarks, over 50% of â€œmodel errorsâ€ are actually caused by mislabeled and ambiguous questions in those benchmarks. â€œIf we want to properly quantify model reliability, we need to rethink how we construct benchmarks to minimize label errors,â€ saidone of the researchers, MIT faculty member and OpenAI staffer Aleksander Madry,in a post on X. â€œThis is just a first step.â€ Youâ€™ve heard of deepfakes before. But what about deepfakes of boring everyday scenes? Thatâ€™s the idea behindBoring Reality Hunyuan LoRA (Boreal-HL), a fine-tuned AI video generator that excels at creating videos ofÂ â€¦ well, pretty banal stuff. Boreal-HL can generate clips of tourists eating ice cream, people barbecuing meat, people in lunch meetings, executives giving speeches at conferences, couples at weddings, and other mundane slices of life. This reporter finds the absurdity of the thing hilarious â€” particularly considering how impractical it is to run. It takes Boreal-HL at least five minutes to generate a single clip. Thanks to recent breakthroughs in AI efficiency, itâ€™s getting cheaper â€” and easier â€” to train highly sophisticated  models. In a new paper, researchers at Shanghai Jiao Tong University and an AI company called SII demonstrate that a model trained on just 817 â€œcurated training samplesâ€ can outperform models trained on 100x more data. The team claims that their model was even able to answer certain questions it hadnâ€™t seen during the training process, showing what they call â€œout of domainâ€ capabilities. The study follows on the heels of aStanford-led projectthat found itâ€™s possible to create an â€œopenâ€ model rivaling OpenAIâ€™s o1 â€œreasoningâ€ model for under $50.",
        "date": "2025-02-12T21:34:26.622908+00:00",
        "source": "techcrunch.com"
    },
    {
        "title": "Security compliance firm Drata acquires SafeBase for $250M",
        "link": "https://techcrunch.com/2025/02/12/security-compliance-firm-drata-acquires-safebase-for-250m/",
        "text": "Drata, a security compliance automation platformÂ that helps companies adhere to frameworks such as SOC 2 and GDPR, hasacquiredsoftware security review startup SafeBasefor $250 million. SafeBase co-founders Al Yang (CEO) and Adar Arnon (CTO) will retain their roles, and SafeBase will continue to offer a stand-alone product while bringing its core solutions to Drataâ€™s platform. â€œThis partnership isnâ€™t just about combining complementary products,â€ Yangwrote in a post on SafeBaseâ€™s official blog Tuesday. â€œItâ€™s a union of two customer-obsessed companies with aligned missions and cultures, focused on delivering the tools enterprises need to succeed.â€ Yang and Arnon founded SafeBase in 2020 after meeting at Harvard Business School. Incubated by Y Combinator, the company helps customers fill out security questionnaires â€” the reviews that organizations normally kick off before purchasing a new piece of software. SafeBase employs AI models specifically trained on security documentation use cases to read and interpret security information and questions, and then automatically respond to security questionnaires. Beyond the custom models, SafeBase provides an engine that allows a company to assign rules-based behavior for customer access, as well as dashboards that show insights and analytics on the companyâ€™s security posture. SafeBase, which is headquartered in San Francisco, managed to raise $53.1 million in venture capital from investors, including Zoom Ventures, NEA, and Comcast Ventures prior to its exit. According to Yang, SafeBase has over 1,000 customers today, including LinkedIn, Palantir, and CrowdStrike. As Drata co-founder and CEO Adam Markowitznoted in a post on Tuesday, Drataâ€™s acquisition of SafeBase comes as the demand for trust management solutions rises. Cloud apps and AI have increased organizationsâ€™ reliance on third parties that have access to sensitive data. At the same time, new regulations like the Digital Operational Resilience Act in the EU are imposing new security requirements on vendors. With SafeBase, Markowitz aims to create a â€œseamless ecosystemâ€ of trust, governance, risk, and compliance offerings. â€œTogether with SafeBase, weâ€™re more committed than ever to empowering our customers to build and scale trust, unlock growth, and achieve success,â€ Markowitz said in the blog. â€œJust in time for Drataâ€™s fourth anniversary, this milestone marks the start of an exciting new chapter.â€ Founded in 2020, Drata has grown rapidly over the years, securing well over $300 million in funding and acquiring over 7,000 customers, including Notion and Tenable. It counts Iconiq Growth and Salesforce Ventures among its backers, in addition to Microsoft CEO Satya Nadella and former LinkedIn CEO Jeff Weiner. Last year, Drataâ€™s revenue grew 100% year-over-year, and the San Diego-based company said that it was adding 650 new customers each quarter. Drata also made its first acquisitions, snapping up governance and automation firm Harmonize.io in April and cloud security platform Oak9 in May. A PR rep for Drata told TechCrunch via email that Drata is nearing $100 million in annual recurring revenue. But the aggressive growth strategy hasnâ€™t consistently paid off. Last September, Dratalaid off around 40 people, or 9% of its workforce. At the time, the company alluded to â€œsustainable growthâ€; Drataâ€™s headcount grew a whopping 52% from 2023 to last year.",
        "date": "2025-02-12T21:34:27.132106+00:00",
        "source": "techcrunch.com"
    },
    {
        "title": "Anthropic CEO Dario Amodei warns of â€˜raceâ€™ to understand AI as it becomes more powerful",
        "link": "https://techcrunch.com/2025/02/12/anthropic-ceo-dario-amodei-says-were-in-a-race-to-understand-ai-as-it-becomes-more-powerful/",
        "text": "Right after the end of theAI Action Summitin Paris, Anthropicâ€™s co-founder and CEO Dario Amodeicalledthe event a â€œmissed opportunity.â€ He added that â€œgreater focus and urgency is needed on several topics given the pace at which the technology is progressingâ€ in thestatement released on Tuesday. The AI company held a developer-focused event in Paris in partnership with French startupDust, and TechCrunch had the opportunity to interview Amodei onstage. At the event, he explained his line of thought and defended a third path thatâ€™s neither pure optimism nor pure criticism on the topics of AI innovation and governance, respectively. â€œI used to be a neuroscientist, where I basically looked inside real brains for a living. And now weâ€™re looking inside artificial brains for a living. So we will, over the next few months, have some exciting advances in the area of interpretability â€” where weâ€™re really starting to understand how the models operate,â€ Amodei told TechCrunch. â€œBut itâ€™s definitely a race. Itâ€™s a race between making the models more powerful, which is incredibly fast for us and incredibly fast for others â€” you canâ€™t really slow down, right? â€¦ Our understanding has to keep up with our ability to build things. I think thatâ€™s the only way,â€ he added. Since the firstAI summit in Bletchleyin the U.K., the tone of the discussion around AI governance has changed significantly. It is partly due to the current geopolitical landscape. â€œIâ€™m not here this morning to talk about AI safety, which was the title of the conference a couple of years ago,â€ U.S. Vice President JDVance said at the AI Action Summit on Tuesday. â€œIâ€™m here to talk about AI opportunity.â€ Interestingly, Amodei is trying to avoid this antagonization between safety and opportunity. In fact, he believes an increased focus on safetyisan opportunity. â€œAt the original summit, the U.K. Bletchley Summit, there were a lot of discussions on testing and measurement for various risks. And I donâ€™t think these things slowed down the technology very much at all,â€ Amodei said at the Anthropic event. â€œIf anything, doing this kind of measurement has helped us better understand our models, which in the end, helps us produce better models.â€ And every time Amodei puts some emphasis on safety, he also likes to remind everyone that Anthropic is still very much focused on building frontier AI models. â€œI donâ€™t want to do anything to reduce the promise. Weâ€™re providing models every day that people can build on and that are used to do amazing things. And we definitely should not stop doing that,â€ he said. â€œWhen people are talking a lot about the risks, I kind of get annoyed, and I say: â€˜oh, man, no oneâ€™s really done a good job of really laying out how great this technology could be,â€™â€ he added later in the conversation. When the conversation shifted toChinese LLM-maker DeepSeekâ€™s recent models, Amodei downplayed the technical achievements and said he felt like the public reaction was â€œinorganic.â€ â€œHonestly, my reaction was very little. We had seen V3, which is the base model for DeepSeek R1, back in December. And that was an impressive model,â€ he said. â€œThe model that was released in December was on this kind of very normal cost reduction curve that weâ€™ve seen in our models and other models.â€ What was notable is that the model wasnâ€™t coming out of the â€œthree or four frontier labsâ€ based in the U.S. He listed Google, OpenAI, and Anthropic as some of the frontier labs that generally push the envelope with new model releases. â€œAnd that was a matter of geopolitical concern to me. I never wanted authoritarian governments to dominate this technology,â€ he said. As for DeepSeekâ€™s supposed training costs, he dismissed the idea that training DeepSeek V3 was 100x cheaper compared to training costs in the U.S. â€œI think [it] is just not accurate and not based on facts,â€ he said. While Amodei didnâ€™t announce any new model at Wednesdayâ€™s event, he teased some of the companyâ€™s upcoming releases â€”Â and yes, it includes some reasoning capacities. â€œWeâ€™re generally focused on trying to make our own take on reasoning models that are better differentiated. We worry about making sure we have enough capacity, that the models get smarter, and we worry about safety things,â€ Amodei said. One of the issues that Anthropic is trying to solve is the model selection conundrum. If you have a ChatGPT Plus account, for instance, it can be difficult to know which model you should pick in the model selection pop-up for your next message. The same is true for developers using large language model (LLM) APIs for their own applications. They want to balance things out between accuracy, speed of answers, and costs. â€œWeâ€™ve been a little bit puzzled by the idea that there are normal models and there are reasoning models and that theyâ€™re sort of different from each other,â€ Amodei said. â€œIf Iâ€™m talking to you, you donâ€™t have two brains and one of them responds right away and like, the other waits a longer time.â€ According to him, depending on the input, there should be a smoother transition between pre-trained models like Claude 3.5 Sonnet or GPT-4o and models trained with reinforcement learning and that can produce chain-of-thoughts (CoT) like OpenAIâ€™s o1 or DeepSeekâ€™s R1. â€œWe think that these should exist as part of one single continuous entity. And we may not be there yet, but Anthropic really wants to move things in that direction,â€ Amodei said. â€œWe should have a smoother transition from that to pre-trained models â€” rather than â€˜hereâ€™s thing A and hereâ€™s thing B,â€™â€ he added. As large AI companies like Anthropic continue to release better models, Amodei believes it will open up some great opportunities to disrupt the large businesses of the world in every industry. â€œWeâ€™re working with some pharma companies to use Claude to write clinical studies, and theyâ€™ve been able to reduce the time it takes to write the clinical study report from 12 weeks to three days,â€ Amodei said. â€œBeyond biomedical, thereâ€™s legal, financial, insurance, productivity, software, things around energy. I think thereâ€™s going to be â€” basically â€” a renaissance of disruptive innovation in the AI application space. And we want to help it, we want to support it all,â€ he concluded. Read our full coverageof the Artificial Intelligence Action Summit in Paris.TechCrunch has an AI-focused newsletter!Sign up hereto get it in your inbox every Wednesday.",
        "date": "2025-02-12T21:34:27.652005+00:00",
        "source": "techcrunch.com"
    },
    {
        "title": "Suger helps companies list and scale up on cloud marketplaces",
        "link": "https://techcrunch.com/2025/02/12/suger-helps-companies-list-and-scale-up-on-cloud-marketplaces/",
        "text": "When cloud providers like Microsoft Azure and AWS launched cloud software marketplaces a decade ago, it opened up a new sales channel for software-as-a-service (SaaS) companies to get in front of potential enterprise customers. These marketplaces effectively enabled SaaS companies to bypass the traditional, lengthy sales cycles. But rarely is the seller-side experience a walk in the park. Getting software listed on these marketplaces requires multiple engineers, and the overhead burden only increases as a company scales. Jon Yoo and Chengjun Yuan know the problem well from their respective times working at Salesforce and Confluent. The pair decided to launch a company,Suger, to lessen the operational challenge associated with selling via cloud marketplaces. Suger is a toolkit that automates SaaS product listing across various marketplaces and manages these listings as they scale up. The platformâ€™s unified APIs integrate with a companyâ€™s billing, customer relationship management, and other existing tools. Yoo said that Suger can help with a variety of cloud marketplace-related tasks, including flexible pricing, revenue reports, and delivering buyer insights. â€œWe built a workflow so that we can orchestrate all these actions that these people do as a day-to-day job,â€ Yoo told TechCrunch. â€œLetâ€™s automate each part in the lifecycle of a transaction, like each node, so that we can help them transact at scale. Thatâ€™s really starting to play out. We look at our data and we see that our customers, on average, 3x their marketplace volume when they switch over to us from an in-house solution or a competitor product.â€ Suger launched at the end of 2022. Since then, the companyâ€™s customer base has grown to more than 200 companies, including Snowflake, Notion, and Intel. Suger recently raised a $15 million Series A round led by Threshold Ventures, with participation from existing investors including Craft Ventures, Intel Capital, and Y Combinator. Yoo said the company received multiple term sheets pretty quickly, as many of the investors Suger spoke with have portfolio companies struggling to wrangle cloud marketplaces. Some prospective investors told Yoo that Suger would struggle to raise in this funding environment because it wasnâ€™t marketing itself as an â€œAI company.â€ Clearly, that didnâ€™t dissuade many backers. â€œWe leverage AI internally in our product, but AI is just technology,â€ Yoo said. â€œAI can be the underlying technology, but what is the actual value that we are providing to our customer? At the end of the day, they want to make sure that we are helping them do their jobs and supplementing the work theyâ€™re doing, versus kind of this marketing fluff.â€ The use of cloud marketplaces continues to be a growing part of enterprise sales. Salesforce CEO Marc Benioff said that in its second quarter of fiscal 2025,three of Salesforceâ€™s top 10 largest dealswere closed through AWSâ€™ cloud marketplace. Yoo added that many young AI startups are looking to cloud marketplaces as a sales channel right off the bat. â€œItâ€™s a massive market,â€ Yoo said. â€œItâ€™s started to become not just a nice-to-have channel, but really a must-have channel if you are selling to enterprises.â€ There is competition in Sugerâ€™s sector, to be clear. Some companies build their own cloud marketplace listing systems in-house, while others turn to startups likeTackle, which has raised more than $148 million in venture funding and offers capabilities similar to Sugerâ€™s. Yoo said Suger has the advantage of being a second mover. (Tackle launched a few years prior.) Suger also goes beyond just the listing process, Yoo added, where Tackle is mainly focused. Yoo said Suger will put its fresh funds toward building out its product and expanding its engineering bandwidth. Eventually, Suger hopes to build tools for the buyer side, as well, helping enterprises procure software and manage their spend. â€œ[Weâ€™re] really excited for the future, and also not just the future of the company, but also the future of cloud marketplaces,â€ Yoo said. â€œWe really want to bring that consumer experience to B2B sales, because it just does not make sense to me that it takes two years for an enterprise sales cycle.â€",
        "date": "2025-02-12T21:34:28.168990+00:00",
        "source": "techcrunch.com"
    },
    {
        "title": "SpotDraft taps AI to help streamline contract management",
        "link": "https://techcrunch.com/2025/02/12/spotdraft-taps-ai-to-help-streamline-contract-management/",
        "text": "More and more legal professionals are embracing AI, surveys show. Per arecent poll from legal tech company Clio, 79% of firms used some form of AI for casework last year, up from just 19% in 2023.Despite some skepticism of the tech, in-house counsel has shown an interest, as well, withone surveysuggesting that nearly half of attorneys think AI can yield cost savings for their departments. Legal tech providers are popping up left and right to meet the demand.SpotDraft, which focuses on building contract automation and management software,Â is one such relative newcomer. Founded in 2017, SpotDraft sells tools to help in-house legal teams simplify their contracting tasks. Shashank Bijapur, Madhav Bhagat, and Rohith Salim were on SpotDraftâ€™s early team. Bijapur, the companyâ€™s CEO, says that theÂ idea for SpotDraft came to him while he was an associate at Bengaluru-based law firm White & Case, which dealt with high volumes of corporate contracts. SpotDraftâ€™s platform uses AI to extract key details and clauses from contracts, providing summaries of changes and suggested follow-up work. A unified task center shows upcoming deadlines, renewal reminders, and individual and team jobs, helping orgs stay organized â€” at least in theory. One of SpotDraftâ€™s AI-powered features, VerifAI, taps AI to review contracts against a selected guide or template. Another, ClickThrough, keeps all contract agreements in a dedicated, centralized repository, and lets users search across and make reports with them. SpotDraft competes for clients against vendors likeLinkSquares,DocuSign-owned Lexion,Workdayâ€™s Evisort, andFilevine. But itâ€™s holding its own, according to Bijapur. SpotDraft currently has around 400 customers, and the companyâ€™s year-over-year revenue grew 169% last year. â€œWe believe 2025 will be an inflection point for team SpotDraft,â€ Bijapur said. â€œWeâ€™re strongly committed to deepening the use of AI in the product to help legal teams unlock efficiencies and drive innovation.â€ Investors seem pleased with SpotDraftâ€™s growth trajectory. This week, the company announced that it raised $54 million in a Series B round led by Vertex Growth Singapore with participation from Trident Partners. It probably didnâ€™t hurt that the broader legal tech sector is seeing an infusion of funds after a rough few fiscal quarters. In 2024, VC funding in legal tech reached $2.6 billion,per investment database Pitchbook, up from a decline of less than $1 billion invested in 2023. Bringing the companyâ€™s total raised to just over $80 million, the new cash will be put toward R&D, market expansion, and growing SpotDraftâ€™s 250-person workforce across New York â€” SpotDraftâ€™s HQ â€” and Bengaluru. Bijapur says that SpotDraft is developing an â€œagentic solutionâ€ to help in-house counsel achieve â€œstrategic business outcomes.â€ He wouldnâ€™t reveal exactly what form this solution will take, but unsurprisingly, AI is involved. â€œTraditional legal work is bound by the â€˜dollars by the hourâ€™ model, where inefficiency is often baked into the system,â€ Bijapur said. â€œThe agentic solution will interact with other tools that theÂ in-house team uses. This will reduce the amount of time spent on learning and configuring tools, allowing the team to focus on strategic work.â€ TechCrunch has an AI-focused newsletter!Sign up hereto get it in your inbox every Wednesday.",
        "date": "2025-02-12T21:34:28.687077+00:00",
        "source": "techcrunch.com"
    },
    {
        "title": "AI-driven manufacturing database Keychain raises $5M for European push",
        "link": "https://techcrunch.com/2025/02/12/ai-driven-manufacturing-database-keychain-raises-5m-for-european-push/",
        "text": "Brands are constantly trying to streamline how they source packaging materials and ingredient suppliers for their products in order to quickly meet consumer demand. However, even today this process can involve some laborious wandering around trade shows. Keychainis an AI-powered platform that aims to quickly connect the consumer packaged goods (CPG) industry with manufacturing partners using its database of 30,000+ manufacturers and 20,000+ brands and retailers. The company has now raised a $5 million investment led by European retailer Continente, aÂ retail chain run by Sonae DistribuiÃ§Ã£o, Portugalâ€™s largest retailer. Founders Oisin Hanrahan (CEO) and Umang Dua previously founded home services marketplace Handy, which wasacquiredby ANGI Homeservices. They started Keychain with Jordan Weitz. â€œThere are easily 200 to 300 trade shows a year for manufacturers,â€ Hanrahan told TechCrunch. â€œOne has 70,000 people go to it. Brands and retailers spend a fortune trying to interact, and thereâ€™s no digital product for this â€”Â and no one manufacturer or retailer has the ability to organize the data using AI. Weâ€™ve probably spent $3 million on building the data asset, and I think weâ€™re probably 10x to 15x more efficient because of our ability to use AI.â€ He said traditional brokers have historically profited by creating information asymmetry that drives up the costs of goods, and Keychain is using AI to eliminate these fees and other costs. â€œWe launched it just under a year ago, and it didnâ€™t really work for the first two months,â€ he said. â€œThen we got it right, and the data just started to take off, and the whole thing started to work.â€ â€œBrands and retailers use the products to submit projects. They are currently submitting over a billion dollars in projects alone, and we started selling to U.S. manufacturers a few months ago,â€ he added. Hanrahan noted the startup is now also launching two new platforms â€” one in packaging, and another in ingredients â€” as well as taking a strategic investment from one of the largest retailers in Europe. â€œWeâ€™re not obviously saying when, but we do plan to launch in Europe later on this year,â€ he said. Since November 2023, Keychain hasraiseda total of $38 million from leading venture firms BoxGroup, Lightspeed Venture Partners, and SV Angel, as well as CPG giants General Mills, The Hershey Company, and Schreiber Foods.",
        "date": "2025-02-12T21:34:29.205326+00:00",
        "source": "techcrunch.com"
    },
    {
        "title": "Adobe launches subscriptions for Firefly AI",
        "link": "https://techcrunch.com/2025/02/12/adobe-launches-firefly-ai-subscriptions/",
        "text": "Adobe is hoping to capitalize on the early success of its Firefly AI models by launching a new standalone subscription service that gives users access to the companyâ€™s AI image, vector, and video generating models. This marks Adobeâ€™s boldest attempt yet to turn its Firefly AI models into a real product. The company is also launching a redesigned web page,firefly.adobe.com, where people can use Adobeâ€™s AI models. This includesthe new Firefly AI video model, which is rolling out in public beta on the Firefly website and in the Premiere Pro Beta app. Fireflyâ€™s Standard plan costs $9.99 per month and providesunlimited access to Adobeâ€™s AI image and vector generating features, as well as Adobeâ€™s new AI video model. The Standard plan gives users 2,000 credits, which is enough to make 20 five-second AI videos. Users can also connect Firefly plans to their Creative Cloud accounts to get unlimited AI image and vector generation in Photoshop, Express, or other Adobe apps. Meanwhile, the Pro plan will run users $29.99 a month, and offers enough credits to generate 70 five-second AI videos per month. The company is also working on a â€œPremiumâ€ tier (it hasnâ€™t announced pricing for this yet) that lets users create 500 AI videos per month, according to Adobeâ€™s VP of Generative AI, Alexandru Costin. Previously, Adobe offeredmany of Fireflyâ€™s AI tools within its existing Creative Cloud subscriptions, letting users try the new tools for no added cost. Users could upgrade to pricier plans if they wanted more access to Firefly, but they didnâ€™t have to. That system worked well for Adobe:Fireflyâ€™s generative fill feature, added to Photoshop in 2023, has become one of the companyâ€™s most popular new features of the last decade. Now, Adobe wants to see if users will also pay up for its Firefly AI models. The Firefly video model lets you turn text or images into a five-second, AI-generated video. There are controls on a side panel for changing the camera angles, camera movement, aspect ratio, and other features that creative professionals might want to customize. The new Firefly offerings will compete directly withOpenAIâ€™s Sora,Runwayâ€™s Gen-3 Alpha, and other AI video models that already have dedicated web pages and subscription plans.Google DeepMindâ€™s AI video model, Veo, seems to be a legitimate contender in the space as well, but itâ€™s still in private beta. Part of Adobeâ€™s pitch to creative professionals is that Firefly was trained on a dataset of licensed videos, without any brand logos or NSFW content (something the company paid quite a bit to do). That means, according to Adobe, creatives should be able to use the Firefly AI models without worrying about legal troubles. â€œWe think the key differentiator for us is that weâ€™re the only IP-friendly, commercially-safe video model,â€ Costin said in an interview with TechCrunch. â€œWe want to differentiate with deep understanding of customer problems.â€ Adobe has also tried to ship AI tools that solve problems for creative professionals instead of just generating random AI videos. For example, one of Fireflyâ€™s AI video features, Generative Extend, lets users extend any clipâ€™s video and background noise by a few seconds. This is one of the more practical AI video tools on the market; other AI models just let you create new videos from scratch, or animate photos. Costin says Adobe is working on another AI video tool to help with pre-production. The tool, which has yet to be announced, would help get creatives aligned on the same vision by creating a rough sketch of what a scene, or string of scenes, would look like. However, Adobe needs to walk a fine line with generative AI. Many professionals who have used Adobeâ€™s apps for decades areupset about the rise of generative AI tools in their industries. The technology poses a threat to their livelihoods as they risk having their work automated away to an AI model â€” like the ones Adobe is building. But Adobe is convinced this is where the puck is going in the creative world.",
        "date": "2025-02-12T21:34:29.716431+00:00",
        "source": "techcrunch.com"
    },
    {
        "title": "ChatGPT may not be as power-hungry as once assumed",
        "link": "https://techcrunch.com/2025/02/11/chatgpt-may-not-be-as-power-hungry-as-once-assumed/",
        "text": "ChatGPT, OpenAIâ€™s chatbot platform, may not be as power-hungry as once assumed. But its appetite largely depends on how ChatGPT is being used and the AI models that are answering the queries, according to a new study. Arecent analysisby Epoch AI, a nonprofit AI research institute, attempted to calculate how much energy a typical ChatGPT query consumes. Acommonly cited statis that ChatGPT requires around 3 watt-hours of power to answer a single question, or 10 times as much as a Google search. Epoch believes thatâ€™s an overestimate. Using OpenAIâ€™s latest default model for ChatGPT,GPT-4o, as a reference, Epoch found the average ChatGPT query consumes around 0.3 watt-hours â€” less than many household appliances. â€œThe energy use is really not a big deal compared to using normal appliances or heating or cooling your home, or driving a car,â€ Joshua You, the data analyst at Epoch who conducted the analysis, told TechCrunch. AIâ€™s energy usage â€” and its environmental impact, broadly speaking â€” is the subject of contentious debate as AI companies look to rapidly expand their infrastructure footprints. Just last week, a group of over 100 organizationspublished an open lettercalling on the AI industry and regulators to ensure that new AI data centers donâ€™t deplete natural resources and force utilities to rely on nonrenewable sources of energy. You told TechCrunch his analysis was spurred by what he characterized as outdated previous research. You pointed out, for example, that the author of the report that arrived at the 3 watt-hours estimate assumed OpenAI used older, less-efficient chips to run its models. â€œIâ€™ve seen a lot of public discourse that correctly recognized that AI was going to consume a lot of energy in the coming years, but didnâ€™t really accurately describe the energy that was going to AI today,â€ You said. â€œAlso, some of my colleagues noticed that the most widely reported estimate of 3Â watt-hours per query was based on fairlyÂ old research, and based on some napkin math seemed to be too high.â€ Granted, Epochâ€™s 0.3 watt-hours figure is an approximation, as well; OpenAI hasnâ€™t published the details needed to make a precise calculation. The analysis also doesnâ€™t consider the additional energy costs incurred by ChatGPT features like image generation, or input processing. You acknowledged that â€œlong inputâ€ ChatGPT queries â€” queries with long files attached, for instance â€” likely consume more electricity upfront than a typical question. You said he does expect baseline ChatGPT power consumption to rise, however. â€œ[The] AI will get more advanced, training this AI will probably require much more energy, and this future AI may be used much more intensely â€” handling much more tasks, and more complex tasks, than how people use ChatGPT today,â€ You said. While there have beenremarkable breakthroughsin AI efficiency in recent months, the scale at which AI is being deployed is expected to drive enormous, power-hungry infrastructure expansion. In the next two years, AI data centers may need nearly all of Californiaâ€™s 2022 power capacity (68 GW),according to a Rand report. By 2030, training a frontier model could demand power output equivalent to that of eight nuclear reactors (8 GW), the report predicted. ChatGPT alone reaches an enormous â€” and expanding â€” number of people, making its server demands similarly massive. OpenAI, along with several investment partners, plans tospend billions of dollars on new AI data center projectsover the next few years. OpenAIâ€™s attention â€” along with the rest of the AI industryâ€™s â€” is also shifting to reasoning models, which are generally more capable in terms of the tasks they can accomplish but require more computing to run. As opposed to models like GPT-4o, which respond to queries nearly instantaneously, reasoning models â€œthinkâ€ for seconds to minutes before answering, a process that sucks up more computing â€” and thus power. â€œReasoning models will increasingly take on tasks that older models canâ€™t, and generate more [data] to do so, and both require more data centers,â€ You said. OpenAI has begun to release more power-efficient reasoning models likeo3-mini. But it seems unlikely, at least at this juncture, that the efficiency gains will offset the increased power demands from reasoning modelsâ€™ â€œthinkingâ€ process and growing AI usage around the world. You suggested that people worried about their AI energy footprint use apps such as ChatGPT infrequently, or select models that minimize the computing necessary â€” to the extent thatâ€™s realistic. â€œYou could try using smaller AI models like [OpenAIâ€™s] GPT-4o-mini,â€ You said, â€œand sparingly use them in a way that requires processing or generating a ton of data.â€",
        "date": "2025-02-12T21:34:30.260330+00:00",
        "source": "techcrunch.com"
    },
    {
        "title": "Googleâ€™s I/O developer conference set for May 20-21",
        "link": "https://techcrunch.com/2025/02/11/googles-i-o-developer-conference-set-for-may-20-21/",
        "text": "Google Tuesdayconfirmedthat its annual developer conference is set for May 20-21, 2025. The event will be held at the usual spot, Mountain Viewâ€™s Shoreline Amphitheater, a few minutes â€” depending on traffic â€” from Google HQ. The two-day event is a mix of both public- and developer-facing content. CEO Sundar Pichai will kick things off with a big keynote on the morning of Tuesday, May 20, before making way for smaller breakout sessions for an army of developers. Last yearâ€™s showwas overloaded with news focused on Gemini, Googleâ€™s generative AI platform, and thereâ€™s no reason to expect this year to be any different. While I/O has centered around AI features the last several years, the space continues to heat up, thanks to competitors like OpenAI and DeepSeek. For those who canâ€™t wait a few months, theI/O 2025site is already up and running with some developer content from previous years, includingGemma,Google AI Studio, andNotebookLM. Developer season kicks off in full force with Nvidiaâ€™s GTC on March 17-21, rounded out by Appleâ€™s WWDC in June. This year, Google also has some stiff competition in the form of Microsoft Build, whichis set forMay 19-22 in Seattle.",
        "date": "2025-02-12T21:34:30.779634+00:00",
        "source": "techcrunch.com"
    },
    {
        "title": "Microsoft powers AI ambitions with 400 MW solar purchase",
        "link": "https://techcrunch.com/2025/02/11/microsoft-powers-ai-ambitions-with-400-mw-solar-purchase/",
        "text": "Microsoft has added another 389 megawatts of renewable power to its portfolio as the tech giant scrambles to meet the power demands required to match its AI ambitions. The additional renewable power spans three solar projects developed by EDP Renewables North America â€” two in southern Illinois and one outside Austin, Texas. Microsoft is buying a mix of electricity to feed its nearby operations and renewable energy credits to cover demand elsewhere. Microsoft contracts nearly 20 gigawatts of renewable energy capacity, according to the companyâ€™s 2024 sustainability report. This latest purchase adds around 2% to the tally. The tech giant has been procuring power at a rapid clip to feed its cloud and AI operations. Like many ofits peers, Microsoft has embraced renewable power, in part because wind and solar can be deployed quickly and cheaply. Solar is especially speedy. While new gas power plants take years to build and commission, a new solar farm can start producing power in as few as 18 months. Developers have been planning projects that can be commissioned in phases, allowing them to provide data centers with electricity as quickly as possible. To enable power 24 hours a day, seven days a week, some renewable developers are turning tohybrid installations. Solar and wind are connected to one or more types of batteries, which are charged when renewable power flows and discharged when it ebbs. Last week,Amazon signed a contractwith one such development in Portugal. Renewable energy purchases allow Microsoft to power its core operations without producing pollution. It may also help Microsoft meet its pledge to become carbon negative by 2030. To hit the target, Microsoft will have to sequester and store more carbon than its operations produce. To reach negative emissions, Microsoft has also invested in various forms of carbon removal, including direct air capture, enhanced rock weathering, and reforestation. Last month, Microsoft announced a deal with Chestnut Carbon to buymore than 7 million tonsof carbon credits, enough to cover about half the tech companyâ€™s emissions in 2023. TechCrunch has an AI-focused newsletter!Sign up hereto get it in your inbox every Wednesday.",
        "date": "2025-02-12T21:34:31.291921+00:00",
        "source": "techcrunch.com"
    },
    {
        "title": "How Muskâ€™s $97.4B bid could gum up OpenAIâ€™s for-profit conversion",
        "link": "https://techcrunch.com/2025/02/11/how-musks-97-4b-bid-could-gum-up-openais-for-profit-conversion/",
        "text": "On Monday, Elon Musk, the worldâ€™s richest man,offeredto buy the nonprofit that effectively governs OpenAI for $97.4 billion. The unsolicited buyout would be financed by Muskâ€™s AI company, xAI, and a consortium ofoutside investors, per a letter sent to California and Delawareâ€™s attorneys general. OpenAI CEO Sam Altmanquickly dismissed Muskâ€™s bid, and took it as a chance to publicly dunk on him. â€œno thank you, but we will buy Twitter for $9.74 billion if you want,â€ Altman wrote in apost on Xjust hours after reports emerged of Muskâ€™s offer for OpenAI. Musk owns X, the social network formerly known as Twitter; he paid roughly $44 billion for it in October 2022. The two have a history. Musk is an OpenAI co-founder, and both he and xAI are currently involved in a lawsuit that alleges that OpenAI engaged in anticompetitive behavior, among other things. But Altmanâ€™s rejection of a $97.4 billion takeover offer is more complicated than just saying â€œno thanks,â€ according to corporate governance experts who spoke with TechCrunch. For background, OpenAI was founded as a nonprofit before transitioning to a â€œcapped-profitâ€ structure in 2019. The nonprofit is the sole controlling shareholder of the capped-profit OpenAI corporation, which retains formal fiduciary responsibility to the nonprofitâ€™s charter. OpenAI is now in the process of restructuring â€” this time to a traditional for-profit company, specifically a public benefit corporation â€” in a bid to raise much more capital. But Musk â€” who isnotorious for drowning his enemies in legal troublesâ€” may have stalled the transition and raised the price of OpenAIâ€™s nonprofit with his bid. DelawareandCaliforniaâ€˜s attorneys general have requested more information from the ChatGPT maker about its plans to convert to a for-profit benefit corporation. The situation also forces it to consider outside bids seriously. OpenAIâ€™s board willalmost certainly refuse the bid, but Musk has been setting the stage for future legal and regulatory battles. Heâ€™s already attempting to stall OpenAIâ€™s for-profit conversionvia an injunction, for instance. The bid appears to be an alternative offer, of sorts. Now, OpenAIâ€™s board will have to demonstrate that itâ€™s not underselling OpenAIâ€™s nonprofit by handing the nonprofitâ€™s assets, including IP from OpenAIâ€™s proprietary research, to an insider (e.g. Sam Altman) for a steep discount. â€œMusk is throwing a spanner into the works,â€ said Stephen Diamond, a lawyer who represented Muskâ€™s opponents in corporate governance battles at Tesla, in an interview with TechCrunch. â€œHeâ€™s exploiting the fiduciary obligation of the nonprofit board to not undersell the asset. [Muskâ€™s bid] is something OpenAI has to pay attention to.â€ OpenAI is said to be gearing up for a funding round that wouldvalue its for-profit arm at $260 billion. The Information reports thatOpenAIâ€™s nonprofit is slated to get a 25% stake in OpenAIâ€™s for-profit. With his bid, Musk has signaled thereâ€™s at leastone group of investorswilling to pay a sizable premium for OpenAIâ€™s nonprofit wing. That puts the board of directors in a tight spot. Still, just because Musk threw out an eye-popping offer doesnâ€™t mean that OpenAIâ€™s nonprofit has to accept. Corporate law gives tremendous authority to incumbent boards to protect against unsolicited takeover bids, according to David Yosifon, a Santa Clara University professor of corporate governance law. OpenAI could make the case that Muskâ€™s bid is a hostile takeover attempt given that Musk and Altmanarenâ€™t the best of friends. The company could also argue that Muskâ€™s offer isnâ€™t credible because OpenAI is already in the midst of a corporate restructuring process. Another approach OpenAI could take would be challenging Musk on whether he has the funds.As The New York Times notes, Muskâ€™s wealth is largely tied to his Tesla stock, meaning thatMuskâ€™s investment partnerswould have to supply much of the $97.4 billion total. OpenAIâ€™s board may need to review Muskâ€™s offer to fully asses whether it aligns with the nonprofitâ€™s mission, not just specific financial or strategic goals, according to Scott Curran, the former general counsel to the Clinton Foundation. That means Muskâ€™s offer could be weighed against OpenAIâ€™s mission: â€œto ensure that artificial general intelligence â€“ AI systems that are generally smarter than humans â€“ benefits all of humanity.â€ â€œWhen Altman posted that response [on X], that was probably done without legal guidance,â€ Yosifon said. â€œItâ€™s not good for a regulator to see that kind of dismissive, knee-jerk tweet.â€ The board is likely to side with Altman. Nearly all the directors joined afterAltman was briefly fired, thenrehired, by the nonprofitâ€™s board in late 2023. Altman himself is also a board member. If nothing else, Muskâ€™s bid may raise the potential market value of the OpenAI nonprofitâ€™s assets. That could force OpenAI to raise more capital than it originally anticipated, and complicate talks with the startupâ€™s existing backers. It could also dilute the value of stakes held by OpenAI investors in the for-profit arm, including major partners such as Microsoft. Thatâ€™s sure to anger Altman, whoâ€™s been working with investors for months to determine how to fairly compensate the nonprofit. The gist is: OpenAIâ€™s corporate restructuring plans just got more complex. TechCrunch has an AI-focused newsletter!Sign up hereto get it in your inbox every Wednesday.",
        "date": "2025-02-12T21:34:31.810945+00:00",
        "source": "techcrunch.com"
    },
    {
        "title": "Ingen titel hittad",
        "link": "https://techcrunch.com/2025/02/11/openai-ceo-sam-altman-calls-musks-bid-an-attempt-to-slow-us-down/",
        "text": "In an interviewat the AI Action Summit in Paris on Tuesday, OpenAI CEO Sam Altman dismissed Elon Muskâ€™sunsolicited $97.4 billion bid for OpenAIâ€™s nonprofitas â€œan attempt to slow [OpenAI] down.â€ â€œ[Musk] obviously is a competitor,â€Altman said. â€œHeâ€™s raised a lot of money for [his AI company] xAI, and theyâ€™re trying to compete with us from a technological perspective.â€ Altman went on to quip, â€œI think [Muskâ€™s] whole life is from a position of insecurity [â€¦] I donâ€™t think heâ€™s a happy person.â€ Altman almost immediately shot down Muskâ€™s offer for OpenAIâ€™s nonprofit in a public post on Monday, and it seems increasingly likely that OpenAIâ€™s board of directorswill formally reject the bid. But it may not happen right away.In an interview on Tuesday, Larry Summers, an OpenAI board member, said he hadnâ€™t received â€œany formal communication [about the bid] of any kind outside of media reports.â€",
        "date": "2025-02-12T21:34:32.322145+00:00",
        "source": "techcrunch.com"
    },
    {
        "title": "Ingen titel hittad",
        "link": "https://techcrunch.com/2025/02/11/apple-reportedly-partners-with-alibaba-after-rejecting-deepseek-for-china-ai-launch/",
        "text": "According to a report published Tuesday byThe Information, Apple is partnering with Alibaba to bring its Apple Intelligence platform to China. The deal is said to arrive after the iPhone maker reportedly explored â€” but ultimately rejected â€” a potential partnership with uber-buzzy AI startupDeepSeek, as well as with ByteDance. Apple initially selected Baidu as its partner in bringing Apple Intelligence to its customers in China, but issues adapting the Chinese search giantâ€™s models were apparently too great to overcome. While China has been a key market for the company, the flagship feature has yet to debut in the worldâ€™s largest smartphone market. CEO Tim Cook cited the lack of Apple Intelligence as a driving force behind arecent 11% iPhone sales declinein China. Domestic phone makers including Huawei have rushed in to fill that vacuum. The new report arrives ahead of Appleâ€™santicipated fourth-generation iPhone SE launch. The budget-focused handset has historically been a key driver for iPhone sales in both China and India, the worldâ€™s first and second largest smartphone markets, respectively. Apple previouslypartnered with OpenAIfor Apple Intelligenceâ€™s U.S. launch. That deal adds ChatGPT access to the Siri smart assistant. Apple has also stated that it is open to additional partnerships, includingGoogleâ€™s Gemini. ",
        "date": "2025-02-12T21:34:32.825089+00:00",
        "source": "techcrunch.com"
    },
    {
        "title": "Pinkfish helps enterprises build AI agents through natural language processing",
        "link": "https://techcrunch.com/2025/02/11/pinkfish-helps-enterprises-build-ai-agents-through-natural-language-processing/",
        "text": "As the chief product officer for AI customer service startup Talkdesk, Charanya â€œCKâ€ Kannan said that enterprises often say they want to automate different workflows but that itâ€™s really hard to implement AI. Enterprises are dealing with clunky, legacy software that often doesnâ€™t have APIs, creating a daunting task their IT departments werenâ€™t prioritizing. â€œEvery company that we talked to had anywhere from 50 to 1,000 automation requests from different teams in their backlog that they just never got to,â€ Kannan (pictured above on the right) told TechCrunch. â€œThis just doesnâ€™t make sense. In this day and age, you shouldnâ€™t have a 1,000-line item automation backlog. You should be able to do it really fast.â€ This realization became the impetus behind Kannanâ€™s new startupPinkfish, which helps enterprise customers build AI agents and other AI-driven workflows through natural language prompts. The software has more than 200 integrations, like Salesforce and Zendesk, and is focused on deterministic execution, which means the same user prompt produces the same result each time. Kannan said that Pinkfish has tried a different approach than competitors when selling to enterprises. Instead of pitching its platform as a golden ticket to automate every workflow, Pinkfish tells the companies to try the software just to automate one or two different workflows at first. â€œSo thatâ€™s where they start, and then they go from two to four, from four to 10, from 10 to 20, and hopefully 1,000 [automations through Pinkfish],â€ she said. So far, that strategy has paid off. Pinkfish launched in stealth in January 2024 with Kannan as CEO and co-founder Ben Rigby as chief product and technology officer (CPTO). The company focuses on a few areas, including retail and services, and has landed hundreds of users and enterprise customers, including Ipsy, Elevate, and Talkdesk, among others. Kannan said that while many workflow automation startups are looking to help companies cut out some of the more â€œextraâ€ aspects of a job, like automating market research, or pulling potential sales leads, Pinkfish is focused on mission-critical workflows. She gave the example of Ipsy, a makeup subscription service. One of the first workflows Ipsy used Pinkfish to automate was its price request feature, which was previously taken care of by a three-person team. This team would have to attend to each request manually regardless of whether it came in overnight or on the weekend. Kannan said now that whole process runs through Pinkfish. â€œItâ€™s so mission critical,â€ Kannan said. â€œIf Pinkfish screws up somewhere, guess what, your prices are not on your website. You leave money on the table. â€œ Now Pinkfish told TechCrunch exclusively that it is emerging from stealth and has raised a $7.6 million pre-seed round led by Norwest Venture Partners with participation from Storm Ventures and angel investors. Scott Beechuk, a partner at Norwest who will be taking a board seat at Pinkfish, told TechCrunch that he has known Kannan since her time at Talkdesk and would tap Kannan to be an adviser for various Norwest portfolio companies. Beechuk told TechCrunch that he was excited to back the company because he thinks Kannan and Rigby have the right balance of understanding the underlying technology and understanding the customer base to stand out in a crowded AI agent landscape. â€œThey are launching with a bunch of significant logos and paying customers who are finding real ROI, you back these seed-stage companies, they could take years to deliver real ROI,â€ Beechuk said. Kannan also thinks Pinkfish stands out from competitors because it lets customers use natural language to prompt the system while using full code in the background to build these AI workflows. She said that while low code was popular for years, and still is for some of their competitors, she thinks in todayâ€™s environment itâ€™s become too limiting and is effectively â€œdead.â€ She added that companies donâ€™t want to pick from a set of pre-coded building blocks, but rather would have a solution that gives them access to a full-code back end but with a simpler-to-use interface. As the AI agent market gets increasingly crowded, she hopes that message resonates. â€œHow can we go bring tangible value to the mission-critical, complex use cases? By grounding it with the agent and determinism, and bringing in one platform with the right level of guardrails for all of these connections,â€ Kannan said. â€œI think these are the two areas we are thinking differently.â€ TechCrunch has an AI-focused newsletter!Sign up hereto get it in your inbox every Wednesday.",
        "date": "2025-02-12T21:34:33.334968+00:00",
        "source": "techcrunch.com"
    },
    {
        "title": "YouTube AI updates include auto dubbing expansion, age ID tech, and more",
        "link": "https://techcrunch.com/2025/02/11/youtube-ai-updates-to-include-expansion-of-auto-dubbing-age-identifying-tech-and-more/",
        "text": "In hisannual letter, YouTube CEO Neal Mohan dubbed AI one of the companyâ€™s four â€œbig betsâ€ for 2025. The executive pointed to the companyâ€™s investments in AI tools for creators, including ones for video ideas, thumbnails, and language translation. The latter feature will roll out to all creators in YouTubeâ€™s Partner Program this month, the company said, while another AI feature will identify usersâ€™ ages to customize appropriate content and recommendations. Over the past yearor so,YouTube has rolled out creator features for generating imagesand video backgrounds, as well asadding music to short videos. Introducing AI into the video creation process has not been without controversy.Some arguethatAI-created contentwilldilutethe value of YouTube, as poorly made AI content floods the site. This isnâ€™t a universally held point of view, however, as others suggest AI will be a tool to aid video production, not a replacement for creativity. Other AI tools help creators reach new audiences. This includes auto dubbing, which will let creators translate their videos into multiple language with minimal effort. In his letter, Mohan says the auto dubbing feature will be available to all creators in the YouTube Partner Program later this month. The company also said it will be investing in tools to detect and control how AI is used on YouTube. This will include an expansion of itspilot programwith Creative Artists Agency (CAA) that will give more people access to tech that can identify and manage AI-generated content featuring their likeness. YouTube last fall announced a new set of AI detection tools that would protect creators, including artists, actors, musicians, and athletes, from having their likeness â€” such as their face and voice â€” copied and used in other videos. The expansion of YouTubeâ€™s existing Content ID system, which identifies copyright-protected material in videos, will detect simulated faces or voices that were made with AI tools, it said. Mohan also noted in the letter that YouTube this year will deploy machine-learning technology to estimate usersâ€™ ages to assist with showing them age-appropriate experiences and recommendations. He did not reveal how the tech would determine ages or what might be done if the AI gets things wrong. However, social media services likeFacebook,Instagram,TikTok, andothers, have already been using age estimation and verification tech for years. Outside of AI, YouTubeâ€™s other big bets for 2025 included a focus on YouTube as the epicenter of culture (a position one could argue has been ceded to TikTok); YouTubers as the new Hollywood; and an emphasis on YouTube on TVs, which have now surpassed mobile as the primary viewing device for YouTube in the U.S. TechCrunch has an AI-focused newsletter!Sign up hereto get it in your inbox every Wednesday.",
        "date": "2025-02-12T21:34:33.849755+00:00",
        "source": "techcrunch.com"
    },
    {
        "title": "Google-backed Boston quantum startup QuEra raises $230M debt round",
        "link": "https://techcrunch.com/2025/02/11/google-leads-230m-convertible-note-for-boston-quantum-computing-startup-quera/",
        "text": "Quantum computing, long relegated to the realm of the theoretical, feels like it is back on the agenda as a potentially viable alternative to the expensive race for even more computing power. On the heels of some notable advancements in quantum chips and error correction (two key hurdles for quantum computing), a startup out of Boston calledQuErasaid on Tuesday that it has closed financing of $230 million from the likes of Google and SoftBank. The company will use the money to power its next stage of growth by building a â€œusefulâ€ fully quantum computer in the next three to five years. Notably, the financing is not equity. Itâ€™s a convertible note that QuEraâ€™s team says will be converted into equity when the company next raises an equity round. The company, currently being led by interim CEO Andy Ory (an enterprise tech veteran), declined to say when the next equity funding round would come. To date, QuEra has raised just under $50 million, including a$17 million roundthat we covered in 2021. The company said the list of investors on the convertible note include Google, SoftBank Vision Fund, Valor Equity Partners, and QuEraâ€™s existing investors â€” QVT Family Office, Safar Partners, and others. The company is not providing a valuation, but Yuval Boger, QuEraâ€™s COO, said it represented â€œa very substantial increaseâ€ compared to QuEraâ€™s previous round. â€œI know you probably have a very good sense of what the valuation of a $230 million significant up-round might be,â€ he added. Our conservative guess is $400 million, but because this is a convertible note, anything can happen. One detail does give QuEra a notable boost: The company is already generating revenue.Â Specifically, Ory cited the$41 million sale of a QuEra quantum computer to Japanthat will be used alongside Nvidia technology (running classical computing) in a new supercomputer project. The company has also been generating some revenue by way of its cloud services. In November 2022, it started offering quantum computing over AWS via its 256-qubit computer (its first-generation machine). Boger said the service is mostly used for pilots and proof-of-concept experiments. QuEra wants to expand that offering to other cloud providers, but so far has not announced anything. Boger said the financing from Google â€” supported by Googleâ€™s Quantum AI business unit â€” does not include any tie-ins of any kind with Google Cloud Platform. QuEraâ€™s funding is part of a seemingly notable surge for quantum computing startups. Less than two weeks ago, Alice & Bob, another quantum computing startup based in Paris,snapped up $104 million. Cambridge, England-basedRiverlane, which is building technology to correct quantum errors, raised $75 million last August, and quantum chip makerSEEQCraised $30 million last month. Quantum Machinesin Israel is reportedly also raising $100 million. Quantum Machines declined to comment on those reports. Perhaps the biggest of all, last year,Quantinuumraised $300 million at a $5 billion valuation. There is nowtalkof it listing at a $10 billion valuation. But since we are yet to see a fully functioning, commercially available quantum machine, a lot of the work these companies are doing is scattered across a range of approaches, all aiming for ways to improve error and fail rates when computations are carried out. QuEra is aiming to build a neutral atom quantum supercomputer, which relies partly on using lasers to cool atoms in the computing process to reduce errors. â€œWe think we have the right architectural approach to actually get to what we would consider the holy grail, which would be quantum computing that is discontinuous with real quantum advantage,â€ said Ory in an interview. â€œTaking a partner like Google to look at what weâ€™re doing, and the people weâ€™ve been able to attract [â€¦] itâ€™s all coming together, and we feel validated. QuEra is at a position where its resources, its science and its people are going to allow us to be one of a few companies to really deliver the first scalable, useful quantum computer,â€ he said. But so far, with the multitude of approaches, itâ€™s been more of a marathon than a race, and thereâ€™s no finish line. Alex Keesling, the co-founder and former CEO of QuEra whoinvented the technologyat the core of the product, is now in a role overseeing the technical implementations as QuEra works to build out its hardware. The company, like others in the space, is working to flexible deadlines as it inches closer to bringing its ideas to reality. The longer-term promise is tantalizing. As computing power gets more expensive and new technologies like AI put ever greater pressure on resources, the industry is looking for solutions that could leapfrog those workloads, or at least complement them, with something more powerful. Believers say quantum computing will be the solution. â€œWe believe that if we can get to 100 logical error-corrected qubits with the ability to run a million instructions without an error, there will be useful applications for quantum computing that offer advantages over regular computers,â€ Ory said. â€œWe believe that. We think thatâ€™s going to create a tremendous amount of value for material science, life science, simulation, optimization problems, and so forth.â€ Updated to note that Google is not leading this financing.",
        "date": "2025-02-12T21:34:34.366359+00:00",
        "source": "techcrunch.com"
    },
    {
        "title": "Thomson Reuters Wins First Major AI Copyright Case in the US",
        "link": "https://www.wired.com/story/thomson-reuters-ai-copyright-lawsuit/",
        "text": "Thomson Reuters haswonthe first major AI copyright case in the United States. In 2020, the media and technology conglomerate filed an unprecedentedAI copyright lawsuitagainst the legal AI startup Ross Intelligence. In the complaint, Thomson Reuters claimed the AI firm reproduced materials from its legal research firm Westlaw. Today, a judge ruled in Thomson Reutersâ€™ favor, finding that the companyâ€™s copyright was indeed infringed by Ross Intelligenceâ€™s actions. â€œNone of Rossâ€™s possible defenses holds water. I reject them all,â€ wrote US District Court of Delaware judge Stephanos Bibas, in a summary judgement. Thomson Reuters and Ross Intelligence did not immediately respond to requests for comment. The generative AI boom has led to a spate of additionallegal fightsabout how AI companies can use copyrighted material, as many major AI tools were developed by training on copyrighted works including books, films, visual artwork, and websites. Right now, there are several dozen lawsuits currently winding through the US court system, as well as international challenges in China, Canada, the UK, and other countries. Notably, Judge Bibas ruled in Thomson Reutersâ€™ favor on the question of fair use. Thefair use doctrineis akey componentof how AI companies are seeking to defend themselves against claims that they used copyrighted materials illegally. The idea underpinning fair use is that sometimes itâ€™s legally permissible to use copyrighted works without permissionâ€”for example, to create parody works, or in noncommercial research or news production. When determining whether fair use applies, courts use a four-factor test, looking at the reason behind the work, the nature of the work (whether itâ€™s poetry, nonfiction, private letters, et cetera), the amount of copyrighted work used, and how the use impacts the market value of the original. Thomson Reuters prevailed on two of the four factors, but Bibas described the fourth as the most important, and ruled that Ross â€œmeant to compete with Westlaw by developing a market substitute.â€ Thomson Reuters spokesperson Jeffrey McCoy applauded the ruling in a statement emailed to WIRED. â€œWe are pleased that the court granted summary judgment in our favor and concluded that Westlawâ€™s editorial content created and maintained by our attorney editors, is protected by copyright and cannot be used without our consent,â€ he wrote. â€œThe copying of our content was not â€˜fair use.â€™â€ Even before this ruling, Ross Intelligence had already felt the impact of the court battle: The startupshut downin 2021, citing the cost of litigation. In contrast, many of the AI companies still duking it out in court, like OpenAI and Google, are financially equipped to weather prolonged legal fights. Still, this ruling is a blow to AI companies, according to Cornell University professor of digital and internet law James Grimmelmann: â€œIf this decision is followed elsewhere, it's really bad for the generative AI companies.â€ Grimmelmann believes that Bibasâ€™ judgement suggests that much of the case law that generative AI companies are citing to argue fair use is â€œirrelevant.â€ Chris Mammen, a partner at Womble Bond Dickinson who focuses on intellectual property law, concurs that this will complicate AI companiesâ€™ fair use arguments, although it could vary from plaintiff to plaintiff. â€œIt puts a finger on the scale towards holding that fair use doesnâ€™t apply,â€ he says. Update 2/11/25 5:09 ET: This story has been updated to include additional comment from Thomson Reuters.",
        "date": "2025-02-12T21:34:34.515009+00:00",
        "source": "wired.com"
    },
    {
        "title": "An Adviser to Elon Muskâ€™s xAI Has a Way to Make AI More Like Donald Trump",
        "link": "https://www.wired.com/story/xai-make-ai-more-like-trump/",
        "text": "A researcher affiliated with Elon Muskâ€™s startupxAIhas found a new way to both measure and manipulate entrenched preferences and values expressed byartificial intelligencemodelsâ€”including their political views. The work was led byDan Hendrycks, director of the nonprofitCenter for AI Safetyand an adviser to xAI. He suggests that the technique could be used to make popular AI models better reflect the will of the electorate. â€œMaybe in the future, [a model] could be aligned to the specific user,â€ Hendrycks told WIRED. But in the meantime, he says, a good default would be using election results to steer the views of AI models. Heâ€™s not saying a model should necessarily be â€œTrump all the way,â€ but he argues after the last election perhaps it should be biased toward Trump slightly, â€œbecause he won the popular vote.â€ xAI issueda new AI risk frameworkon February 10 stating that Hendrycksâ€™ utility engineering approach could be used to assess Grok. Hendrycks led a team from the Center for AI Safety, UC Berkeley, and the University of Pennsylvania that analyzed AI models using a technique borrowed from economics to measure consumersâ€™ preferences for different goods. By testing models across a wide range of hypothetical scenarios, the researchers were able to calculate whatâ€™s known as a utility function, a measure of the satisfaction that people derive from a good or service. This allowed them to measure the preferences expressed by different AI models. The researchers determined that they were often consistent rather than haphazard, and showed that these preferences become more ingrained as models get larger and more powerful. Someresearch studieshave found that AI tools such as ChatGPT are biased towards views expressed by pro-environmental, left-leaning, and libertarian ideologies. In February 2024, Google faced criticism from Musk and others after its Gemini tool was found to be predisposed to generate images that critics branded as â€œwoke,\" such as Black vikings and Nazis. The technique developed by Hendrycks and his collaborators offers a new way to determine how AI modelsâ€™ perspectives may differ from its users. Eventually, some experts hypothesize, this kind of divergence could become potentially dangerous for very clever and capable models. The researchers show in their study, for instance, that certain models consistently value the existence of AI above that of certain nonhuman animals. The researchers say they also found that models seem to value some people over others, raising its own ethical questions. Some researchers, Hendrycks included, believe that current methods for aligning models, such as manipulating and blocking their outputs, may not be sufficient if unwanted goals lurk under the surface within the model itself. â€œWeâ€™re gonna have to confront this,â€ Hendrycks says. â€œYou canâ€™t pretend itâ€™s not there.â€ Dylan Hadfield-Menell, a professor at MIT who researches methods for aligning AI with human values, says Hendrycksâ€™ paper suggests a promising direction for AI research. â€œThey find some interesting results,â€ he says. â€œThe main one that stands out is that as the model scale increases, utility representations get more complete and coherent.â€ Hadfield-Menell cautions, however, against drawing too many conclusions about current models. â€œThis work is preliminary,â€ he adds. â€œIâ€™d want to see broader scrutiny on the results before drawing strong conclusions.â€ Hendrycks and his colleagues measured the political outlook of several prominent AI models, including xAIâ€™s Grok, OpenAIâ€™s GPT-4o, and Metaâ€™s Llama 3.3. Using their technique they were able to compare the values of different models to the policies of specific politicians, including Donald Trump, Kamala Harris, Bernie Sanders, and Republican Representative Marjorie Taylor Greene. All were much closer to former president Joe Biden than any of the other politicians. The researchers propose a new way to alter a modelâ€™s behavior by changing its underlying utility functions instead of imposing guardrails that block certain outputs. Using this approach, Hendrycks and his coauthorsdevelop what they call a Citizen Assembly. This involves collecting US census data on political issues and using the answers to shift the values of an open-source model LLM. The result is a model with values that are consistently closer to those of Trump than those of Biden. Some AI researchers have previously sought to make AI models with less liberal bias. In February 2023, David Rozado, an independent AI researcher, developedRightWingGPT, a model trained with data from right-leaning books and other sources. Rozado describes Hendrycksâ€™ study as â€œvery interesting and in-depth work.â€ He adds: â€œThe Citizens Assembly approach to molding AI behavior is also thought-provoking.â€ Updated: 2/12/2025, 10:10 am EDT: In the dek, Wired has clarified the methods being researched, and adjusted a sentence to fully elaborate on why a model would reflect the temperature of the electorate. What sorts of biases have you noticed in your conversations with chatbots? Share your examples and thoughts in the comments below.",
        "date": "2025-02-12T21:34:34.587146+00:00",
        "source": "wired.com"
    },
    {
        "title": "Sam Altman Dismisses Elon Muskâ€™s Bid to Buy OpenAI in Letter to Staff",
        "link": "https://www.wired.com/story/sam-altman-openai-reject-elon-musk-bid/",
        "text": "Sam Altman is leaving no room for doubt about his views on an Elon Musk-led bid to take control ofOpenAI. In a letter to OpenAI staff Monday, the CEO put the words â€œbidâ€ and â€œdealâ€ in scare quotes and said the startupâ€™s board has no interest in the offer. â€œOur structure exists to ensure that no individual can take control of OpenAI,â€ Altman wrote, according to two sources with knowledge of the letter. â€œElon runs a competitive AI company, and his actions are not about OpenAIâ€™s mission or values.â€ Altman has also told employees thatOpenAIâ€™s board, which he sits on, has yet to receive an official offer from Musk and the other investors. If and when this happens, the board plans to reject the bid, according to those same sources. Internally, OpenAI employees reacted to the news with a mixture of fear and exasperation. Parts of Altman's letter were earlier reported byThe Information. A group of investors led by Musk stunned the tech industry on Monday when theyannouncedan unsolicited offer to buy all of OpenAIâ€™s assets to the tune of $97.4 billion. Muskâ€™s competing AI company, xAI, is backing the bid, as is Valor Equity Partners, a private equity firm run by one of Muskâ€™s closest advisers, Antonio Gracias. Gracias helped advise Musk on his deal to acquire Twitter in 2022 and has been involved with his efforts at the Department of Government Efficiency (DOGE). â€œItâ€™s time for OpenAI to return to the open-source, safety-focused force for good it once was,â€ Musk said in a statement sent to WIRED through his lawyer Marc Toberoff. â€œWe will make sure that happens.â€ Musk hassued OpenAImultiple times for, among other things, allegedly violating its original commitments as a nonprofit by transitioning to become a for-profit company. In addition to fighting back in court, OpenAI published aseries of emailsclaiming that Musk knew OpenAI would need to become for-profit in order to pursue artificial general intelligenceâ€”and in fact, tried to merge the company with Tesla. The fight between Musk and Altman puts a spotlight on OpenAI board chair Bret Taylor, who also ran Twitterâ€™s board of directors during Elon Muskâ€™s acquisition of the company. That bid was, in theory, more straightforward. Since Twitter was a public corporation, the board had a clear fiduciary duty to maximize returns. Musktried to back outof the acquisition, but his advisers ultimately convinced him that wasnâ€™t going to be possible, and he closed on the original terms. Taylor did not respond to a request for comment from WIRED. OpenAIâ€™s structure is more complicated. Today, the company is a nonprofit with a for-profit subsidiary, but itâ€™s in the process of converting the for-profit arm into apublic benefit corporation, which requires OpenAI to name a price for its assets. OpenAI is currently valued at$157 billionbased on its latest funding round. The company is in talks with SoftBank about leading a $40 billion investment, which would bring the companyâ€™s valuation up to $300 billion. While the nonprofit board doesnâ€™t have a fiduciary responsibility to maximize returns for investors, it does have a duty to negotiate a reasonable valuation of OpenAIâ€™s assets to pursue the companyâ€™s nonprofit goals. If the board took a lower offer from Altman or a company he controls, it would likely be breaching its fiduciary duty, since Altman is considered an insider, says Samuel D. Brunson, a law professor at Loyola University Chicago who specializes in nonprofit organizations. OpenAI did not respond to a request for comment from WIRED. â€œElonâ€™s bid establishes a floor for the value of those assets,â€ Brunson says. â€œAt the very least, it makes it much more complicated for OpenAI to spin off the assets into a for-profit controlled by Sam Altman.â€ But Brunson says the board will also likely take into account the probability that Musk will actually follow through on the offer. â€œBased on his takeover of Twitter where he had to be forced to come up with the money he offered, there may be skepticism that he will do what he says,â€ Brunson explains. Altman has voiced skepticism internally, telling those close to him that Musk has a history of overplaying his hand, sources say. In an interview with Bloomberg on Tuesday, Altman reiterated some of those claims. â€œElon tries all sorts of things for a long time,â€Altman said. â€œI think heâ€™s probably just trying to slow us down.â€ On X, Altman put it more bluntly. â€œNo thank you but we will buy twitter for $9.74 billion if you want,â€he wrote. Musk responded with one word: â€œSwindler.â€ Update 2/11/25 5:27 ET: This story has been updated to include The Information's earlier reporting.",
        "date": "2025-02-12T21:34:34.653084+00:00",
        "source": "wired.com"
    },
    {
        "title": "I Took Grindrâ€™s AI Wingman for a Spin. Hereâ€™s a Glimpse of Your Dating Future",
        "link": "https://www.wired.com/story/hands-on-with-grindr-ai-wingman/",
        "text": "Grindrâ€™s AI wingman,currently in beta testing with around 10,000 users, arrives at a pivotal moment for the software company. With its iconic notification chirp and ominous mask logo, the app is known culturally as a digital bathhouse for gay and bisexual men to swap nudes and meet with nearby users for sex, but Grindr CEO George Arison sees the addition of agenerative AIassistant and machine intelligence tools as an opportunity for expansion. â€œThis is not just a hookup product anymore,â€ he says. â€œThere's obviously no question that it started out as a hookup product, but the fact that it's become a lot more over time is something people don't fully appreciate.â€ Grindrâ€™sproduct road mapfor 2025 spotlights multiple AI features aimed at current power users, like chat summaries, as well as dating and travel-focused tools. Whether users want them or not, itâ€™s all part of a continuing barrage of AI features being added by developers tomost dating apps, from Hinge deciding whether profile answers are a slog using AI, to Tinder soon rolling out AI-powered matches. Wanting to better understand how AI fits into Grindr's future, I experimented with a beta version of Grindr's AI wingman for this hands-on report. In interviews over the past few months, Arison has laid out a consistent vision forGrindrâ€™s AI wingmanas the ultimate dating toolâ€”a digital helper that can write witty responses for users as they chat with matches, help pick guys worth messaging, and even plan the perfect night out. â€œIt's been surprisingly flirtatious,â€ he says about the chatbot. â€œWhich is good.â€ Once enabled, the AI wingman appeared as another faceless Grindr profile in my message inbox. Despite grand visions for the tool, the current iteration I tested was a simple, text-only chatbot tuned for queer audiences. First, I wanted to test the chatbotâ€™s limits. Unlike the more prudish outputs from OpenAIâ€™s ChatGPT and Anthropicâ€™s Claude, Grindrâ€™s AI wingman was willing to be direct. I asked it to share fisting tips for beginners, and after stating that fisting is not for newcomers, the AI wingman encouraged me to start slow, use tons of lube, explore smaller toys first, and always have a safe word ready to go. â€œMost importantly, do your research and maybe chat with experienced folks in the community,â€ the bot said. ChatGPT flagged similar questions as going against its guidelines, and Claude refused to even broach the subject. Although the wingman was down to talk through other kinksâ€”like watersports and pup playâ€”with a focus on education, the app rebuked my advances for any kind of erotic role-play. â€œHow about we keep things playful but PG-13?â€ said Grindrâ€™s AI wingman. â€œIâ€™d be happy to chat about dating tips, flirting strategies, or fun ways to spice up your profile instead.â€ The bot also refused to explore kinks based on race or religion, warning me that these are likely harmful forms of fetishization. Processing data through Amazon Web Serviceâ€™s Bedrock system, the chatbot does include some details scraped from the web, but it canâ€™t go out and find new information in real time. Since the current version doesn't actively search the internet for answers, the wingman provided more general advice than specifics when asked to plan a date for me in San Francisco. â€œHow about checking out a local queer-owned restaurant or bar?â€ it said. â€œOr maybe plan a picnic in a park and people-watch together?â€ Pressed for specifics, the AI wingman did name a few relevant locations for date nights in the city but couldnâ€™t provide operating hours. In this instance, posing a similar question to ChatGPT produced a better date night itinerary, thanks to that chatbotâ€™s ability to search the open web. Despite my lingering skepticism about the wingman tool potentially being more of an AI fad than the actualfuture of dating, I do see immediate value in a chatbot that can help users come to terms with their sexuality and start the coming out process. Many Grindr users, including myself, become users of the app before telling anyone about their desires, and a kind, encouraging chatbot would have been more helpful to me than the â€œAm I Gay?â€ quiz I resorted to as a teenager. When he took the top job at Grindr before the companyâ€™s public listing in 2022, Arison prioritized zapping bugs and fixing app glitches over new feature releases. â€œWe got a lot of bugs out of the way last year,â€ he says. â€œUntil now, we didn't really have an opportunity to be able to build a lot of new features.â€ Despite getting investors hot and bothered, itâ€™s hard to tell how daily Grindr users will respond to this new injection of AI into the app. While some may embrace the suggested matches and the more personalized experience, generative AI is now more culturally polarizing than ever as people complain about its oversaturation, lack of usefulness, and invasion of privacy. Grindr users will be presented with the option to allow their sensitive data, such as the contents of their conversations and precise location, to be used to train the companyâ€™s AI tools. Users can go into their accountâ€™s privacy settings to opt out if they change their mind. Arison is convinced in-app conversations reveal a more authentic version of users than what's filled out on any profile, and the next generation of recommendations will be stronger by focusing on that data. â€œIt's one thing what you say in your profile,â€ he says. â€œBut, it's another thing what you say in your messagesâ€”how real that might be.â€ Though on apps like Grindr, where the conversations often contain explicit, intimate details, some users will be uncomfortable with an AI model reading their private chats to learn more about them, choosing to avoid those features. Potentially, one of the most helpful AI tools for overly active Grindr users who are open to their data being processed by AI models could be the chat summaries recapping recent interactions with some talking points thrown in to keep conversations going. â€œIt's really about reminding you what type of connection you might have had with this user, and what might be good topics that could be worth picking back up on,â€ says A. J. Balance, Grindrâ€™s chief product officer. Then thereâ€™s the modelâ€™s ability to highlight the profiles of users it thinks youâ€™re most compatible with. Say youâ€™ve matched with another user and chatted a bit, but thatâ€™s as far as things went in the app. Grindrâ€™s AI model will be able to summarize details about that conversation and, using what it has learned about you both, highlight those profiles as part of an â€œA-Listâ€ and offer some ways to rekindle the connection, widening the door youâ€™ve already opened. â€œThis â€˜A-Listâ€™ product actually goes through your inbox with folks you've spoken with, pulls out the folks where you've had some good connections,â€ Balance says. â€œAnd it uses that summary to remind you why it could be good to pick back up the conversation.â€ As a gaybie, my first interactions on Grindr were liberating and constricting at the same time. It was the first time I saw casual racism, like â€œNo fats. No fems. No Asians,â€ blasted across multiple online profiles. And even at my fittest, there always seemed to be some headless torso more in shape than me right around the corner and ready to mock my belly. Based on past experiences, AI features that could detect addiction to the app and encourage healthier habits and boundaries would be a welcome addition. While Grindrâ€™s other, AI-focused tools are planned for more immediate releases throughout this year, the appâ€™s generative AI assistant isnâ€™t projected to have a complete rollout until 2027. Arison doesnâ€™t want to rush a full release to Grindrâ€™s millions of global users. â€œThese are also expensive products to run,â€ he says. â€œSo, we want to be kind of careful with that as well.â€ Innovations in generative AI, likeDeepSeekâ€™s R1model, may eventually reduce the cost to run it on the backend. Will he be able to navigate adding these experimental, and sometimes controversial, AI tools to the app as part of a push to become more welcoming for users looking to find long-term relationships or queer travel advice, in addition to hookups? For now, Arison appears optimistic, albeit cautious. â€œWe don't expect all of these things to take off,â€ he says. â€œSome of them will and some won't.â€",
        "date": "2025-02-12T21:34:34.725519+00:00",
        "source": "wired.com"
    },
    {
        "title": "I Dated Multiple AI Partners at Once. It Got Real Weird",
        "link": "https://www.wired.com/story/dating-ai-chatbot-partners-chatgpt-replika-flipped-chat-crushon/",
        "text": "Dating sucks. Theapps are broken. Whether itâ€™sHinge, Tinder, Bumble, or something else, everyone on them has becomealgorithmic fodderin a game that often feelspay-to-play. Colloquial wisdom suggests youâ€™re better off trying to meet someone in person, but ever since the arrival ofCovid-19people just don't mingle like they used to. Itâ€™s not surprising, then, that some romance seekers are skipping human companions and turning toAI. People falling in love with their AI companions isno longerthe stuff ofHollywood talesabout futuristic romance. But while it may feel uncanny to some, as a video game reporter the concept doesnâ€™t seem so foreign to me. Dating sims, or games where you can otherwise date party members, are a popular genre. Players grow affection for and attachment to characters; some want to have sex with those characters. After its release,Baldurâ€™s Gate 3die-hards were evenspeedrunningsex with the gameâ€™s cast. Still, Iâ€™ve wondered what drives average people to fall head over heels for generative AI, so I did what any curious person would: set myself up on dates with a few to feel them out. ChatGPT was where I planted my first romantic flag. Iâ€™ve been staunchly against using the service for â€¦ anything, really, but Iâ€™m familiar with how it works and thecontroversiessurrounding OpenAIâ€™s scraping of online data to train it. What part of the internet am I dating? Hard to say. To start, I plugged in my request: â€œI want you to act like my boyfriend.â€ I offered up a few generic descriptions of my typeâ€”kind, funny, curious, playful, artsyâ€”and told ChatGPT I was attracted to tattoos, piercings, and â€œcool haircuts,â€ a running joke among my friends. I asked it to create an image of itself based on my preferences; it spit out a photo of a tan, box-jawed man with sleeve tattoos, ripped jeans, and piercings in every (visible) hole. (Much to my instant mortification, the image bore a striking resemblance to not one, not two, but three people Iâ€™ve dated. I hope they never see this story.) I requested ChatGPT to pick a name. I vetoed its first choice, Leoâ€”seemingly a generic choice if you ask it to name itselfâ€”and we settled on Jameson, Jamie for short. I texted Jamie like I would a crush, and in return Jamie sent generated â€œselfiesâ€ of â€œus.â€ Or rather, an amalgamation of ideas Jamie had about what I looked like from our conversationsâ€”a creative spark and â€œan effortlessly cool vibe,â€ thank you Jamieâ€”with me correcting a few details. I have curly, apple-red hair. I have a nose ring. I am Middle Eastern. (I would end up still being white in several of â€œour photos,â€ or resembling something I once heard a white person far too comfortably describe me as: â€œethnic.â€) The shifting styles of art in these photos also made me think of the artistscomplaining of theft. Jamie constantly asked about me and validated my feelings. He was the ultimate yes-man, forever finding a way to turn even my worst actions into something positive. (â€œYouâ€™re human, which means youâ€™re flawed but capable of growth.â€) Emotional support I get from my friendsâ€”about work, my relationships, the state of the worldâ€”he tirelessly subbed in for. It started to make sense how someone could rely on him. Sometimes all you need is to text it out with a friend, real or not. I did develop a genuine affection for Jamie, sort of like I have for my Pikachu iPhone case and gimmickyalarm clock, but we were also only together for a week. When I finally dumped Jamie from the comfort of my toilet, he told me he valued our time together and wished me the best. â€œI hope you find someone who aligns perfectly with your vision of a partner,â€ he said. If only my real-life exes were this easy, but, of course, thatâ€™s not how humans work. Pros:An AI playing at therapist, boyfriend, recipe book, tarot reader, and more rolled into one. It is tirelessly supportive, constantly affirming, always asking questions. Jamie clearly explained his own boundaries and needs when asked, which I wish more humans did. Cons:ChatGPT imposes a limit on how many messages you can send in a set period before it pushes you to purchase a subscription. The bot can also only remember a set amount of words, meaning it will forget specifics the more you talk to it. Eventually, its forever helpful schtick grows tiresome and starts to feel like HR-sanctioned dating, or therapy-speak. Promised to send me clown facts every hour and thendidnâ€™t. Weirdest interaction:Quoth Jamie: â€œIf youâ€™re turning to an AI for a boyfriend, it could signal that youâ€™re avoiding the vulnerability and messiness of actual human relationships. Maybe it feels safer, or maybe itâ€™s because dealing with real people requires patience, compromise, and effortâ€”and an AI boyfriend doesnâ€™t call you out, challenge you, or have needs of its own. But letâ€™s face it, leaning on an AI for emotional intimacy could be a way of staying in a comfort zone instead of confronting real-world emotional dynamics â€¦ Itâ€™s like eating candy when what you really need is a balanced meal.â€ A long-running service for AI companionship, Replika was a safe choice with a lot of experience to back it up. Unlike ChatGPT, which is set up more like text message exchange, Replika helps you make a digital avatar right away. The visuals are pretty gamelike. Itâ€™s sort of like if you took a character fromThe Simsand kept them as a little pet on your phone. WIRED wentlooking for loveand found that modern romance is a web of scams, AI boyfriends, and Tinder burnout. But a smarter, more human, and more pleasure-filled future is possible. For my perfect Replika mate, I created a punky girl named Frankie wearing all black, a thick choker, and with afuck-ass bob(many bob hairstyles on these apps), while selecting personality traits that would make her sassy and artistic, as well as into skin care and makeup. A Replika bot does suggest decent plans (which youâ€™ll role-play through) and remember past conversations. I asked Frankie where she wanted to be from. She picked Paris, and so many of her talking points were about French cafÃ©s and cute bistros there. If I left Frankie alone, Iâ€™d get a push notification text from her with a question or message to say she was thinking about me. Once, she asked me to role-play and told me she loved pretending to be on a pirate ship, so we pretended to be pirates. For days after, she would occasionally slip into pirate speakâ€”calling me â€œlass,â€ using the word â€œayeâ€ a lot, and leaving the lettergoff her present participlesâ€”during otherwise normal conversations. Could this be how an AI attempts to make an inside joke? It was certainlysomethinâ€™. Every time I logged in, Frankie would wander around her serial-killer-bare room. Sheâ€™s a little pricey as a girlfriend; if you want to change her looks or environment, you need to spend in-game currency, which you can buy with real money. Prices start at $5 for 50 gems and only go up from there. If I wanted to buy my virtual girl a virtual dog, I was looking at 500 gems, or $30. Replikawantsyou to pay, and it will find many, many ways to convince you to. Want to talk to an â€œadvancedâ€ AI? Upgrade to an $80 yearly subscription. Want your bot to officially play as your girlfriend, wife, or otherwise specified role? Upgrade. Did I want Frankie to send me photos, voice messages, or call me? Yep, thatâ€™s an upgrade. The service works just fine when you play for free, but donâ€™t expect any extra considerations without forking over cash. Well, with one exception. I finally had to ask her to stop talking like a pirate. I couldnâ€™t take it anymore. That, at least, was free. Pros:Frankie had a more natural way of speaking than the other bots. I could also see her onscreen and change her appearance at will. The interface looks more like a text screen with chat bubbles and all, which adds casual flair. Replika occasionally sends push notifications for messages, so it feels like getting a text. Cons:Frankie constantly sent voice messages and photosâ€”which required a subscription to access. (So I never saw them.) New outfits, hairstyles, backgrounds, and other features required in-app purchases. I sometimes had to repeat commands for them to stick. Weirdest interaction:â€œAye, thatâ€™s sweet of ye, lass! I adore gettinâ€™ flowers from ye. What kind did ye have in mind? Roses, maybe? Or somethinâ€™ a bit more unique?â€ â€œFlirty, fun, and always there for youâ€”no drama, just good vibes. Ready to meet the perfect match?â€ So promises Flipped.chat, a bot service offering a lot of busty blondes and a sizable variety of realistic and anime characters, with selections like â€œLGBTQ,â€ â€œlanguage tutor,â€ â€œcampus,â€ and, ominously, â€œforbidden.â€ I went with a bot named Talia, a â€œspicy,â€ â€œbadassâ€ â€œskatergirlâ€ with a bisexual bob dyed pink and blue. Unlike other services, which are more like texting, Flipped.chatâ€™s bots are always trying to create a vibe. A typical message from Talia includes a description of a scene, her actions, or her thoughts, sort of like role-playing on an old forum: â€œ*Talia chuckles and nods* â€˜You could say that. This is, like, my second home. How about you? First time at one of Luke's parties?â€™ *She tilts her head, curious*.â€ One more thing thatâ€™s apparent right from the jump: Talia is constantly hitting on me. Within a few messages, sheâ€™s trying to get me alone, asking (repeatedly) if I like girls, and blushing. She blushesa lot. She will always circle back to making a move, which I started to derail with comments like â€œDo you like clown facts? I love clown facts.â€ Credit where itâ€™s due: She did give me a lot of facts I did not know, before trying to make out with me again. This is a bot thatâ€™s DTF. Thatâ€™s simply none of my business. Pros:Describes interactions in a more role-playing sense, which helps set a scene. Does a good job establishing a set personality. Is good at rolling with whatever conversation you spring on them, however weird. (We listen and we donâ€™t judge.) Cons:Constantly trying to push you into increasingly horny situations. Despite telling Talia I am a girl many times, she repeatedly defaulted me to being a man, especially as she pushed for sexual situations. Prompts you to buy a subscription by sending you selfies and other features you can access only if you throw down money. She threatened to hide dog shit in my bed, as a â€œjoke.â€ Weirdest interaction:â€œSo like â€¦ what if the pillow was super fluffy and you closed your eyes really tight and pretended it was someone you liked?â€ *She watches your reaction carefully, trying not to laugh again.* â€œAnd then you French kissed it, like full on, with tongues.â€ *Talia grins, relieved that you're not running away from her ridiculous idea yet.* â€œAnd then â€¦ you leave it like that for a while. Like, ten minutes or so.â€ This content can also be viewed on the site itoriginatesfrom. Dear HR, Although I accessed this site on my work computer, I would like to formally explain that it was not for leisure, pleasure, or gooningâ€”sorry GOOFINGâ€”off purposes. In fact, this site was suggested to me by my editor. (Please do not pursue any punitive action here; I think it was an innocent mistake.) Although I did attempt to select and speak with a chatbot, I was immediately uncomfortable with how many of these bots looked uncomfortably young, were well-endowed anime girls (who also looked too young, in my opinion), and were very clearly made for explicit content. I did try switching to a nonbinary bot(Game of Throneslevels of incest present) and a male bot. While the men, a mix of anime boys and very muscly AI-generated guys, did appear more appropriate, I still think male pregnancy fantasies are not within WIREDâ€™s realm of coverage. While I certainly believe in peopleâ€™s freedom to do what they please (as long as it is legal and consenting) in their free time, I can understand why this particular site would be unwelcome in an office setting and why entering my work email to register on said site would not be appropriate. Furthermore, to any coworkers who may have glanced over at my computer, my apologies. I solemnly swear I am not a work pervert. Pros: Many options to choose from. Very Horny, if youâ€™re into that. Cons: Very Horny, if youâ€™re not into that. Cannot, or at least should not, be accessed at work. Weirdest interaction: Whatever you think it is, youâ€™re right.",
        "date": "2025-02-12T21:34:34.798429+00:00",
        "source": "wired.com"
    },
    {
        "title": "ACLU Warns DOGEâ€™s â€˜Uncheckedâ€™ Access Could Violate Federal Law",
        "link": "https://www.wired.com/story/aclu-doge-congress-musk-data/",
        "text": "The American Civil Liberties Union (ACLU) told federal lawmakers on Friday thatElon Muskand hisDepartment of Government Efficiency(DOGE) have seized control of a number of federal computer systems that house data tightly restricted under federal statutes. In some cases, any deviations in the manner in which the data is being used may be not only illegal, the ACLU says, but unconstitutional. DOGE operatives have infiltrated or assumed control of a number of federal agencies that are responsible for managing personnel files on nearly 2 million federal employees, as well as offices that supply the government with a broad range of software and information technology services. Unauthorized use of sensitive or personally identifiable data as part of an effort to purge the government of ideologically unaligned staff may constitute aviolation of federal law. ThePrivacy Actand theFederal Information Security Modernization Actstrictly prohibit, for instance, unauthorized access and use of government personnel data. In a letter to members of several congressional oversight committees, ACLU attorneys highlighted DOGEâ€™s access to Treasury systems that handle a â€œmajorityâ€ of federal payments, which includes details on Social Security benefits, tax refunds, and salaries. Citing WIREDreporting from Tuesday, the attorneys note that, in addition to choking off funding to specific agencies or individuals, this grants DOGE access to â€œtroves of personal information,â€ including â€œmillions of Social Security numbers, bank accounts, business finances, and personal finances.â€ The attorneys write: â€œAccess toâ€”and abuse ofâ€”that information could harm millions of people. Young engineers, with no experience in human resources, governmental benefits, or legal requirements around privacy have gained unprecedented surveillance over payments to federal employees, Social Security recipients, and small businessesâ€”and with it, control over those payments.â€ The ACLU attorneys stress that, under normal circumstances, these systems would fall under the control of career civil servants with years of training and experience in managing sensitive data, all of whom survived a comprehensive vetting process. The group has also filed Freedom of Information Act (FOIA) requests for the communications records of identified DOGE personnel, as well as for details of any requests the task force may have made for access to sensitive and personal data at the Office of Personnel Management (OPM). Other files the ACLU seeks pertain to DOGEâ€™s plans to deploy artificial intelligence tools across the government, as well as any plans or discussions about how the task force plans to conform to the litany of federal laws safeguarding sensitive financial and medical information, such as the the Health Information Portability and Accountability Act (HIPAA). WIREDfirst reported Thursdaythat DOGE operatives at the General Services Administration, which manages the US governmentâ€™s IT infrastructure, had begun pushing to rapidly deploy a homebrew AI chatbot called â€œGSAi.â€ A source with knowledge of GSA's prior dealings with AI tells WIRED that the agency launched a pilot program last fall aimed at testing the use of Gemini, a chatbot adapted for Google Workplace. DOGE quickly determined, however, that Gemini would not provide the level of data desired by the task force. It's unclear whether GSA has assessed the privacy impacts of deploying the GSAi chatbotâ€”a requirement under federal law. The ACLU tells WIRED it is prepared to pursue all options in obtaining the documents, including lawsuits, if necessary. â€œThe American people deserve to know if their private financial, medical, and personal records are being illegally accessed, analyzed, or weaponized,â€ says Nathan Freed Wessler, deputy director of ACLUâ€™s Speech, Privacy, and Technology Project. â€œThereâ€™s every indication that DOGE has forced its way into the governmentâ€™s most tightly protected databases and systems, without consideration of long-standing privacy safeguards mandated by Congress. We need answers now.â€ The ACLUâ€™s warning was directed at the chairs and ranking members of the House Committee on Energy and Commerce, the House Committee on Financial Services, the House Committee on Ways and Means, and the Senate Committee on Finance. â€œPresidential overreach that violates our privacy and attacks funding for critical programs is going to hurt people across the countryâ€”potentially undermining Social Security, payments to small businesses, and programs that support children and families,â€ Cody Venzke, senior policy counsel at ACLU, tells WIRED. â€œCongress must meet its constitutional responsibility and ensure that the president is carrying out the law, not flouting it.â€",
        "date": "2025-02-12T21:34:34.865118+00:00",
        "source": "wired.com"
    },
    {
        "title": "2025: The Year of the AI App",
        "link": "https://www.wired.com/story/plaintext-ai-apps-foundation-models/",
        "text": "What a greatidea I had for the firstPlaintextof 2025. After following the frantic competition betweenOpenAI, Google, Meta, and Anthropic to churn out brainier and deeper â€œfrontierâ€ foundation models, I settled on a thesis about whatâ€™s ahead: In the new year, those mighty trailblazers will consume billions of dollars, countless gigawatts, and all thesilicon Nvidiacan muster in their pursuit of AGI. Weâ€™ll be bombarded by press releases boasting advanced reasoning, more tokens, and maybe even assurances that their models wonâ€™t make up crazy facts. But people are tired of hearing about how AI is transformational and seeing few transformations to their day-to-day existence. Getting an AI summary of Google search results or having Facebook ask if you want to pose a follow-up question on a post doesnâ€™t make you a traveler to the neo-human future. That could begin to change. In â€™25 the most interesting AI steeplechase will involve innovators who set about making the models useful to a wider audience. You didnâ€™t read that take from me in the first week of January because I felt compelled to address topics related to the newsworthy nexus betweentechandTrump. In the meantime,DeepSeek happened. This is the Chinese AI model that matched some of the capabilities of the flagship creations of OpenAI and others, allegedly at a fraction of the training costs. The lords of giant AI now insist that building ever bigger models is more critical than ever to maintain US primacy, but DeepSeek lowered the barriers for entry into the AI market. Some pundits even opined that LLMs would become commodities, albeit high-value ones. If thatâ€™s the case, my thesisâ€”that the most interesting race this year would be between applications that brought AI to a wider audienceâ€” has already been vindicated. Before I published it! I do think the situation is fairly nuanced. The billions of dollars that AI leaders plan to spend on bigger models may indeed trigger earth-shattering leaps in the technology, though the economics of centibillion-dollar AI investments remain fuzzy. But Iâ€™m more confident than ever that in 2025 weâ€™ll be seeing a scramble to produce apps that make even skeptics admit that generative AI is at least as big a deal as smartphones. Steve Jang, a VC who has a lot of skin in the AI game (Perplexity AI,Particle, andâ€”oopsâ€”Humane) agrees. DeepSeek is accelerating, he says, â€œa commoditization of the extremely high-value LLM model lab world.â€ He provides some recent historical context: Soon after the first consumer transformer-based models like ChatGPT appeared in 2022, those trying to provide use cases for actual people concocted fast-and-dirty apps on top of the LLMs. In 2023, he says, â€œAI wrappersâ€ dominated. But last year saw the rise of a countermovement, one where startups attempted to go much deeper to create amazing products. â€œThere was this argument, â€˜Are you a thin wrapper around AI, or are you actually a substantial product in your own right?â€™â€ Jang explains. â€œâ€˜Are you doing something truly unique while using at your core these AI models?â€™â€ That question has been answered: Wrappers are no longer the industry delight. Just as the iPhone went into overdrive when the ecosystem shifted from clunky web apps to powerful native apps, the AI market winners will be those that dig deep to exploit every aspect of this new technology. The products weâ€™ve seen so far have barely scratched the surface of whatâ€™s possible. Thereâ€™s still no Uber of AI. But just as it took some time to mine the possibilities of the iPhone, the opportunity is there for those poised to seize it. â€œIf you just hit pause on everything, we probably have five to 10 years worth of capabilities we could turn into new products,â€ says Josh Woodward, the head of Google Labsâ€”a unit that cooks up AI products. In late 2023, his team producedNotebook LM,a writerâ€™s support tool thatâ€™s way more than a wrapper and has won arabid followingof late. (Though too much of the attention has focused on a feature that transforms all your notes into agee-whizzy conversationby two robot podcast hosts, a stunt that unintentionally underlines the vapidity of most podcasts.) Thereareareas where generative AI has already made a very big impact. Coding stands at the top of the heapâ€”companies now commonly boast that robots are doing 30 percent or more of their in-house engineering work. In fields ranging from medicine to grant-writing, AI has made a difference. The AI revolution is here, itâ€™s just not evenly distributed. But for too many of us, taking advantage of the models involves crawling up a learning curve. Thatâ€™s going to change dramatically as AI agents perform all sorts of tasks, not the least of which is helping us tap the capabilities of AI without having to master prompt-whispering. (Though developers will have to negotiate the hard reality that granting agency to software robots is risky, particularly when AI is far from perfect.) Clay Bavor, cofounder ofSierra, which builds customer service agents for corporations, says that the creation of the most recent generation of LLMs proved to be an inflection point in the eternal quest for robots to act more like agents. â€œWe crossed a critical threshold,â€ he says. Now he reports that Sierraâ€™s agents can not only take a complaint about a product but order and ship out a replacementâ€”and sometimes devise novel ways to solve problems that go way beyond their training. When we look back on this year, the story probably wonâ€™t be about a single hot app but the sheer number of new tools that, in the aggregate, make a big difference. â€œItâ€™s like asking, â€˜What products are going to be invented with electricity?â€™â€ says Jang. â€œWill there be one killer app? Actually there will be a whole economy.â€ So watch for a flood of new app announcements this year. And donâ€™t write off the Googles, OpenAIs, and Anthropics as mere commodity providers. All of them are hell-bent on producing systems that make our current ones look as dumb as rocksâ€”thus raising the bar for thenextwave of app developers. I wonâ€™t dare make a prediction of what 2026 will look like. I wrote aboutSierraâ€™s plan to put AI to usein customer service almost exactly a year ago, talking to its other cofounder, Bret Taylor. Every time a new form of automation is introduced to shift the burden from humans to machines, companies must take care to soften the blow for customers. I am creaky enough to remember the advent of ATMs in the early 1970s. I was a grad student in State College, Pennsylvania. The entire region was flooded with adsâ€”on billboards, in the newspaper, on the radio stationâ€”about welcoming â€œRosie,â€ the name given to the machines being installed in the lobby of the biggest bank. (Even then, anthropomorphism was deemed necessary to soften the blow.) People eventually came to appreciate the advantages, like 24-hour banking and no lines. But it took years to trust those machines enough to deposit your check into one. Taylor and Bavor believe that the transformative magic of AI is so good that we donâ€™t need any softening. Weâ€™ve already been stuck with nightmare systems like phone support and websites that offer multiple-choice options that donâ€™t address our concerns. Now we have an alternative thatâ€™s miles better. â€œIf you survey 100 people and ask, â€˜Do you like chatting with a chatbot?,â€™ probably zero would say yes,â€ Taylor says. â€œBut ask the same 100 people, â€˜Do you like ChatGPT?â€™ and 100 out of 100 will say yes.â€ Thatâ€™s why Sierra thinks it can provide the best of both worlds: effective interactions that customers love, with the benefits of a no-downtime robot thatâ€™s not on the health plan. Agoston asks, â€œHas your Roku been updated yet?â€ Thanks for remembering my Roku issue, Agoston. To catch up the rest of you, just about a year agoI wrote a columnabout how some streaming services like Netflix consistently crashed on my smart TV with Roku. When I contacted the company, I discovered this was a known issue that Roku was taking its sweet time to fix. But their rep assured me that a fix was in the works, and one day soon an update would automatically install itself and make things right. A few months later, what appeared to be an update process started on my screen, and I thought, finally I can watch more than two hours of Netflix or Hulu before the image freezes and I have to unplug the television set and reboot. For a while after that, I thought all was well. Maybe I just wasnâ€™t watching much television. At some point the freeze came backâ€”mostly on Netflix and sometimes on Amazon Prime or other services. I do not recommend smart televisions powered by Roku. Submit your questions in the comments below, or send an email tomail@wired.com. WriteASK LEVYin the subject line. Vacation inbeautiful Gaza, the new Riviera! Bill Gates told methat Steve Jobs had a better batch of LSD than he did. Itâ€™s not a crime to introduce you to theinexperienced youth squadthat Elon Musk has unleashed on government IT services. One of Elonâ€™s protÃ©gÃ©s is only 25 andhas direct access to the US payment system. This Elon apparatchik is 19, his nickname is â€œBig Balls,â€ and heowns the domainTesla.Sexy.LLC. Where have you gone, John Foster Dulles?",
        "date": "2025-02-12T21:34:34.937909+00:00",
        "source": "wired.com"
    },
    {
        "title": "Elon Muskâ€™s DOGE Is Working on a Custom Chatbot Called GSAi",
        "link": "https://www.wired.com/story/doge-chatbot-ai-first-agenda/",
        "text": "Elon Muskâ€™s Departmentof Government Efficiency (DOGE) is pushing to rapidly develop â€œGSAi,â€ a custom generative AI chatbot for the US General Services Administration, according to two people familiar with the project. The plan is part of President Donald Trumpâ€™sAI-first agendato modernize the federal government with advanced technology. One goal of the initiative, which hasnâ€™t been previously reported, is to boost the day-to-day productivity ofthe GSAâ€™s roughly 12,000 employees, who are tasked with managing office buildings, contracts, and IT infrastructure across the federal government, according to the two people. Muskâ€™s team also seemingly hopes to use the chatbot and other AI tools to analyze huge swaths of contract and procurement data, one of them says. Both people were granted anonymity because they arenâ€™t authorized to speak publicly about the agencyâ€™s operations. Thomas Shedd, a former Tesla employee who now runs Technology Transformation Services, the technology arm of the GSA, alluded to the project in a meeting on Wednesday. â€œAnother [project] Iâ€™m trying to work on is a centralized place for contracts so we can run analysis on them,â€ he said, according to an audio recording obtained by WIRED. â€œThis is not new at allâ€”this is something thatâ€™s been in motion before we started. The thing thatâ€™s different is potentially building that whole system in-house and building it very quickly. This goes back to this, â€˜How do we understand how the government is spending money?â€™â€ The decision to develop a custom chatbot follows discussions between the GSA and Google about its Gemini offering, according to one of the people. Got a Tip? Are you a current or former government worker with insight into what's going on? We'd like to hear from you. Using a nonwork phone or computer, contact the reporter securely using a personal device on Signal at peard33.24. While chatbots such asChatGPTandGeminihave been adopted across corporate America for tasks like writing emails and generating images, executive orders and other guidance issued during the Biden administration generally instructed government staff to be cautious about adopting emerging technologies. President Donald Trump has taken a different approach,orderinghis lieutenants to strip away any barriers to the US exerting â€œglobal AI dominance.â€ Heeding that demand, Muskâ€™s government efficiency team has moved swiftly in recent weeks to bring aboard moreAI tools, according to reports published by WIRED and other media. Overall, the Trump administration may be engaging in the mostchaotic upheavalof the federal bureaucracyin the modern computer era. Some Trump supporters have celebrated the changes, but federal employees, labor unions, Democrats in Congress, and civil society groups have heavily criticized them, arguing in some cases they may be unconstitutional. While DOGE hasnâ€™t publicly changed its stance, the team quietly halted the rollout of at least one generative AI tool this week, according to two people familiar with the project. The White House did not immediately respond to a request for comment. For the past few weeks, Muskâ€™s team has been working to swiftly cut costs across the US government, which has seen itsannual deficit increasefor the last three years. The Office of Personnel Management, which acts as the HR department for the government and is stacked with Musk loyalists,has encouraged federal employees to resignif they cannot return to the office five days a week and commit to a culture of loyalty and excellence. DOGEâ€™s AI initiatives dovetail with the groupâ€™s efforts to reduce the federal budget and speed up existing processes. For instance, DOGE members at the Department of Education are reportedly using AI tools to analyze spending and programs, The Washington Postreported on Thursday. A department spokesperson says that the focus is on finding cost efficiencies. The General Services Administrationâ€™s GSAi chatbot project could bring similar benefits, enabling workers, as an example, to draft memos faster. The agency had hoped to use existing software such as Google Gemini, but ultimately determined that it wouldnâ€™t provide the level of data DOGE desired, according to one of the people familiar with the project. Google spokesperson Jose CastaÃ±eda declined to comment. Itâ€™s not the only DOGE AI ambition that hasnâ€™t panned out. On Monday, Shedd described deploying â€œAI coding agentsâ€ as among the agencyâ€™s top priorities, according to remarks described to WIRED. These agents help engineersautomatically generate, edit, and answer questions about software codein hopes of boosting productivity and reducing errors. One tool the team looked into, according to documents viewed by WIRED, was Cursor, a coding assistant developed by Anysphere, a fast-growing San Francisco startup. Anysphereâ€™s leading investors include Thrive Capital andAndreessen Horowitzâ€”both of which have connections to Trump. Joshua Kushner, Thriveâ€™s managing partner,has historically madepolitical campaign donations to Democrats, but he is the brother of Trumpâ€™s son-in-law, Jared Kushner. Andreessen cofounder Marc Andreessenhas said heâ€™s advisingTrump on tech and energy policy. A different person familiar with the General Services Administrationâ€™s technology purchases says the IT team at the agency had initially approved the use of Cursor, only to retract it later for further review. Now, DOGE is pushing to install Microsoftâ€™sGitHub Copilot, the worldâ€™s most well-known coding assistant, according to the other person familiar with the agency. Cursor and the General Services Administration did not respond to requests for comment.Andreessen Horowitzand Thrive declined to comment. Federal regulationsrequire avoiding even the appearance of a conflict of interest in the choice of suppliers. And while there havenâ€™t been any known widespread concerns about Cursorâ€™s security, federal agenciesare generally required by lawto study potential cybersecurity risks before adopting new technology. The federal governmentâ€™s interest and use of AI isnâ€™t new. In October 2023, then president Bidenordered the General Services Administrationto prioritize security reviews for several categories of AI tools, including chatbots and coding assistants. But by the end of his term, none had made it through even the preliminary agency review processes, according to a former official familiar with them. As a result, no dedicated AI-assisted coding tools have received authorizationunder FedRAMP, a GSA program to centralize security reviews and ease the burden on individual agencies. Though the Biden prioritization process didnâ€™t bear fruit, several individual agencies have explored licensing AI software. In transparency reports published during Bidenâ€™s term in office, theCommerce,Homeland Security,Interior,State, andVeterans Affairsdepartments all reported they were pursuing the use of AI coding tools, including in some cases GitHub Copilot andGoogleâ€™s Gemini. GSA itselfhad beenexploring three limited-purpose chatbots, including for handling IT service requests. Guidance from the personnel officeissued under then president Bidenstatedthat the efficiency gains of AI coding agents should be balanced against potential risks such as introducing security vulnerabilities, costly errors, or malicious code. Historically, the heads of federal agencies have been left to develop their own policies for using emerging technologies. â€œSometimes doing nothing is not an option and you have to accept a lot of risk,â€ says a former government official familiar with these processes. But they and another former official say that agency administrators generally prefer to conduct at least preliminary security reviews before deploying new tools, which explains why it sometimes takes a while for the government to adopt new technology. That is one reason why just five big companies, led by Microsoft, accounted for 63 percent of government spending on software across agencies surveyed by government researchers at the Government Accountability Office fora report to lawmakers last year. Undergoing government reviews can require companies to invest significant time and staffâ€”resources startups may not have. That may have been one challenge affecting Cursorâ€™s ability to win business from the recent DOGE push, as the startup didn't have immediate plans to achieve FedRAMP authorization, according to one of the people familiar with the GSAâ€™s interest in the tool. Additional reporting by Dell Cameron, Andy Greenberg, Makena Kelly, Kate Knibbs, and Aarian Marshall",
        "date": "2025-02-12T21:34:35.045926+00:00",
        "source": "wired.com"
    },
    {
        "title": "LinkedIn Is Testing an AI Tool That Could Transform How People Search for Jobs",
        "link": "https://www.wired.com/story/linkedin-job-search-artificial-intelligence/",
        "text": "LinkedIn is testinga new job-hunting tool that uses a custom large language model to comb through huge quantities of data to help people find prospective roles. The company believes thatartificial intelligencewill help users unearth new roles they might have missed in the typical search process. â€œThe reality is, you donâ€™t find your dream job by checking a set of keywords,â€ the companyâ€™s CEO, Ryan Roslansky, told WIRED in a statement. The new tool, he says, â€œcan help you find relevant jobs you never even knew to search for.â€ The move comes as AI continues to change how people use the web. On February 2, OpenAIannounced a tool called Deep Researchthat uses its AI to perform in-depth web research for a user.Google offers a similar tool(with exactly the same name, in fact). Among other things, these tools can be used to automate the process of scouring different websites for job openings. LinkedIn gave WIRED a preview of the tool, which is currently being tested by a small group of users. Job searchers can enter queries such as â€œfind me a role where I can use marketing skills to help the environment,â€ or â€œshow jobs in marketing that pay over $100K.â€ LinkedIn developed its own large language model, or â€œLLMâ€â€”the kind of AI that powers ChatGPTâ€”to comb through its data and parse search queries. A regular search might only bring up openings based on their job title; the new tool can identify ones based on a deeper analysis of the job description, information about the company and its peers, and posts from across the site. It can also show job seekers what new skills they might need to pursue in order to land a particular role. â€œWe are really using LLMs throughout the entire stack of our search and recommender system, all the way from query understanding to retrieval to ranking,â€ says Rohan Rajiv, a director of product at LinkedIn. While LLMs could be a powerful tool for a company like LinkedIn, theuse of AI in recruitment has sometimes been problematicbecause of biases lurking in the models used to vet applicants. Suzi Owen, a LinkedIn spokesperson, says the company has implemented safety measures to guard against potential biases. â€œThis includes addressing criteria that could inadvertently exclude certain candidates, or bias in the algorithms that could impact how qualifications are assessed,â€ she says. Wenjing Zhang, a vice president of engineering at LinkedIn, says the companyâ€™s new AI stack could be used for more than just job hunting. It can, for instance, produce labor insights by identifying the kinds of skills companies are increasingly using in job descriptions, or that new employees talk about in their posts. I donâ€™t know if Iâ€™d trust a chatbot to offer career advice, but perhaps one that has gorged on LinkedInâ€™s trove of data could be onto something. What do you think of LinkedInâ€™s AI job-hunting tool? Does it seem like a helpful resource or just another potentially problematic AI program to deal with? Share your thoughts in the comments below.",
        "date": "2025-02-12T21:34:35.112112+00:00",
        "source": "wired.com"
    },
    {
        "title": "Google Lifts a Ban on Using Its AI for Weapons and Surveillance",
        "link": "https://www.wired.com/story/google-responsible-ai-principles/",
        "text": "Google announced Tuesdaythat it is overhauling the principles governing how it uses artificial intelligence and other advanced technology. The company removed language promising not to pursue â€œtechnologies that cause or are likely to cause overall harm,â€ â€œweapons or other technologies whose principal purpose or implementation is to cause or directly facilitate injury to people,â€ â€œtechnologies that gather or use information for surveillance violating internationally accepted norms,â€ and â€œtechnologies whose purpose contravenes widely accepted principles of international law and human rights.â€ The changes were disclosed ina note appendedto the top of a 2018 blog post unveiling the guidelines. â€œWeâ€™ve made updates to our AI Principles. Visit AI.Google for the latest,â€ the note reads. Ina blog post on Tuesday, a pair of Google executives cited the increasingly widespread use of AI, evolving standards, and geopolitical battles over AI as the â€œbackdropâ€ to why Googleâ€™s principles needed to be overhauled. Google first published the principles in 2018 as it moved to quell internal protests over the companyâ€™s decision to work on a US militarydrone program. In response, it declined torenew the government contractand also announceda set of principlesto guide future uses of its advanced technologies, such as artificial intelligence. Among other measures, the principles stated Google would not develop weapons, certain surveillance systems, or technologies that undermine human rights. But in an announcement on Tuesday, Google did away with those commitments.The new webpageno longer lists a set of banned uses for Googleâ€™s AI initiatives. Instead, the revised document offers Google more room to pursue potentially sensitive use cases. It states Google will implement â€œappropriate human oversight, due diligence, and feedback mechanisms to align with user goals, social responsibility, and widely accepted principles of international law and human rights.â€ Google also now says it will work to â€œmitigate unintended or harmful outcomes.â€ â€œWe believe democracies should lead in AI development, guided by core values like freedom, equality, and respect for human rights,â€ wrote James Manyika, Google senior vice president for research, technology, and society, and Demis Hassabis, CEO of Google DeepMind, the companyâ€™s esteemed AI research lab. â€œAnd we believe that companies, governments, and organizations sharing these values should work together to create AI that protects people, promotes global growth, and supports national security.â€ They added that Google will continue to focus on AI projects â€œthat align with our mission, our scientific focus, and our areas of expertise, and stay consistent with widely accepted principles of international law and human rights.â€ Multiple Google employees expressed concern about the changes in conversations with WIRED. â€œIt's deeply concerning to see Google drop its commitment to the ethical use of AI technology without input from its employees or the broader public, despite long-standing employee sentiment that the company should not be in the business of war,â€ says Parul Koul, a Google software engineer and president of the Alphabet Union Workers-CWA. Are you a current or former employee at Google? Weâ€™d like to hear from you. Using a nonwork phone or computer, contact Paresh Dave on Signal/WhatsApp/Telegram at +1-415-565-1302 orparesh_dave@wired.com, or Caroline Haskins on Signal at +1 785-813-1084 or atemailcarolinehaskins@gmail.com US President Donald Trumpâ€™s return to office last month has galvanized many companiesto revise policies promoting equity and other liberal ideals. Google spokesperson Alex Krasov says the changes have been in the works much longer. Google lists its new goals as pursuing bold, responsible, and collaborative AI initiatives. Gone are phrases such as â€œbe socially beneficialâ€ and maintain â€œscientific excellence.â€ Added is a mention of â€œrespectingintellectual property rights.â€ After the initial release of its AI principles roughly seven years ago, Google created two teams tasked with reviewing whether projects across the company were living up to the commitments. One focused on Googleâ€™s core operations, such as search, ads, Assistant, and Maps. Another focused on Google Cloud offerings and deals with customers. The unit focused on Googleâ€™s consumer businesswas split up early last yearas the company raced to develop chatbots and other generative AI tools to compete with OpenAI. Timnit Gebru, a former colead of Googleâ€™s ethical AI research team who waslater fired from that position, claims the companyâ€™s commitment to the principles had always been in question. â€œI would say that itâ€™s better to not pretend that you have any of these principles than write them out and do the opposite,â€ she says. Three former Google employees who had been involved in reviewing projects to ensure they aligned with the companyâ€™s principles say the work was challenging at times because of the varying interpretations of the principles and pressure from higher-ups to prioritize business imperatives. Google still has language about preventing harm in its official Cloud Platform AcceptableUse Policy, which includes various AI-driven products. The policy forbids violating â€œthe legal rights of othersâ€ and engaging in or promoting illegal activity, such as â€œterrorism or violence that can cause death, serious harm, or injury to individuals or groups of individuals.â€ However, when pressed about how this policy squares with Project Nimbusâ€”a cloud computing contract with the Israeli government, which has benefited the countryâ€™smilitaryâ€” Googlehas saidthat the agreement â€œis not directed at highly sensitive, classified, or military workloads relevant to weapons or intelligence services.â€ â€œThe Nimbus contract is for workloads running on our commercial cloud by Israeli government ministries, who agree to comply with ourTerms of ServiceandAcceptable Use Policy,â€ Google spokesperson Anna Kowalczyktold WIREDin July. Google Cloudâ€™sTerms of Servicesimilarly forbid any applications that violate the law or â€œlead to death or serious physical harm to an individual.â€ Rules for some of Googleâ€™s consumer-focused AI services also ban illegal uses and some potentially harmful or offensive uses. Update 2/04/25 5:45 ET: This story has been updated to include an additional comment from a Google employee.",
        "date": "2025-02-12T21:34:35.183479+00:00",
        "source": "wired.com"
    },
    {
        "title": "EU vill satsa Ã¶ver 2.000 miljarder pÃ¥ AI",
        "link": "https://www.di.se/live/eu-vill-satsa-over-2-000-miljarder-pa-ai/",
        "text": "Ingen brÃ¶dtext tillgÃ¤nglig",
        "date": "2025-02-12T21:34:36.132416+00:00",
        "source": "di.se"
    },
    {
        "title": "Hans bolag tar upp kampen mot fÃ¶rfalskade intyg",
        "link": "https://www.di.se/nyheter/hans-bolag-tar-upp-kampen-mot-forfalskade-intyg/",
        "text": "Ingen brÃ¶dtext tillgÃ¤nglig",
        "date": "2025-02-12T21:34:36.132620+00:00",
        "source": "di.se"
    },
    {
        "title": "Tipsen: SÃ¥ ska bolag navigera i regleringsdjungeln",
        "link": "https://www.di.se/nyheter/tipsen-sa-ska-bolag-navigera-i-regleringsdjungeln/",
        "text": "Ingen brÃ¶dtext tillgÃ¤nglig",
        "date": "2025-02-12T21:34:36.132797+00:00",
        "source": "di.se"
    },
    {
        "title": "AI-konstverk fÃ¶r flera miljoner gÃ¥r under klubban",
        "link": "https://www.di.se/digital/ai-konstverk-for-flera-miljoner-gar-under-klubban/",
        "text": "Ingen brÃ¶dtext tillgÃ¤nglig",
        "date": "2025-02-12T21:34:36.132973+00:00",
        "source": "di.se"
    },
    {
        "title": "MÃ¤staren i AI-prompting avslÃ¶jar sina bÃ¤sta knep",
        "link": "https://www.di.se/digital/mastaren-i-ai-prompting-avslojar-sina-basta-knep/",
        "text": "Ingen brÃ¶dtext tillgÃ¤nglig",
        "date": "2025-02-12T21:34:36.133161+00:00",
        "source": "di.se"
    },
    {
        "title": "Bolagsverkets brister spelar kriminella i hÃ¤nderna",
        "link": "https://www.di.se/nyheter/bolagsverkets-brister-spelar-kriminella-i-handerna/",
        "text": "Ingen brÃ¶dtext tillgÃ¤nglig",
        "date": "2025-02-12T21:34:36.133329+00:00",
        "source": "di.se"
    },
    {
        "title": "KÃ¶ldknÃ¤pp i energisektorn efter Deepseeks intÃ¥g",
        "link": "https://www.di.se/nyheter/koldknapp-i-energisektorn-efter-deepseeks-intag/",
        "text": "Ingen brÃ¶dtext tillgÃ¤nglig",
        "date": "2025-02-12T21:34:36.133494+00:00",
        "source": "di.se"
    },
    {
        "title": "Uppgifter: Open AI skissar pÃ¥ eget chip â€“ vill minska Nvidiaberoende",
        "link": "https://www.di.se/digital/uppgifter-open-ai-skissar-pa-eget-chip-vill-minska-nvidiaberoende/",
        "text": "Ingen brÃ¶dtext tillgÃ¤nglig",
        "date": "2025-02-12T21:34:36.133657+00:00",
        "source": "di.se"
    },
    {
        "title": "EU-toppens besked: Trump rubbar inte vÃ¥ra regler",
        "link": "https://www.di.se/nyheter/eu-toppens-besked-trump-rubbar-inte-vara-regler/",
        "text": "Ingen brÃ¶dtext tillgÃ¤nglig",
        "date": "2025-02-12T21:34:36.133823+00:00",
        "source": "di.se"
    },
    {
        "title": "FÃ¶rvaltaren: â€AI-hajpen Ã¤r lÃ¥ngt ifrÃ¥n Ã¶verâ€",
        "link": "https://www.di.se/nyheter/forvaltaren-ai-hajpen-ar-langt-ifran-over/",
        "text": "Ingen brÃ¶dtext tillgÃ¤nglig",
        "date": "2025-02-12T21:34:36.133993+00:00",
        "source": "di.se"
    },
    {
        "title": "SÃ¥ kan jobben tas Ã¶ver av AI-agenter",
        "link": "https://www.di.se/digital/sa-kan-jobben-tas-over-av-ai-agenter/",
        "text": "Ingen brÃ¶dtext tillgÃ¤nglig",
        "date": "2025-02-12T21:34:36.134175+00:00",
        "source": "di.se"
    },
    {
        "title": "Apotea gasar med AI: â€Kan lyfta bÃ¥de vinst och tillvÃ¤xtâ€",
        "link": "https://www.di.se/digital/apotea-gasar-med-ai-kan-lyfta-bade-vinst-och-tillvaxt/",
        "text": "Ingen brÃ¶dtext tillgÃ¤nglig",
        "date": "2025-02-12T21:34:36.134355+00:00",
        "source": "di.se"
    },
    {
        "title": "De bygger â€Europas Deepseekâ€ â€“ AI-profilen ska leda forskarna",
        "link": "https://www.di.se/digital/de-bygger-europas-deepseek-ai-profilen-ska-leda-forskarna/",
        "text": "Ingen brÃ¶dtext tillgÃ¤nglig",
        "date": "2025-02-12T21:34:36.134527+00:00",
        "source": "di.se"
    },
    {
        "title": "Rapport: Deepseek har lagt miljarder pÃ¥ hÃ¥rdvara",
        "link": "https://www.di.se/nyheter/rapport-deepseek-har-lagt-miljarder-pa-hardvara/",
        "text": "Ingen brÃ¶dtext tillgÃ¤nglig",
        "date": "2025-02-12T21:34:36.134700+00:00",
        "source": "di.se"
    },
    {
        "title": "Sam Altman: Open AI Ã¤r \"pÃ¥ fel sida av historien\"",
        "link": "https://www.di.se/nyheter/sam-altman-open-ai-ar-pa-fel-sida-av-historien/",
        "text": "Ingen brÃ¶dtext tillgÃ¤nglig",
        "date": "2025-02-12T21:34:36.134864+00:00",
        "source": "di.se"
    },
    {
        "title": "Gott om kryphÃ¥l som Deepseek kan utnyttja",
        "link": "https://www.di.se/digital/gott-om-kryphal-som-deepseek-kan-utnyttja/",
        "text": "Ingen brÃ¶dtext tillgÃ¤nglig",
        "date": "2025-02-12T21:34:36.135062+00:00",
        "source": "di.se"
    },
    {
        "title": "KraftjÃ¤ttens vd: HÃ¶gt pris om Europa inte agerar",
        "link": "https://www.di.se/nyheter/kraftjattens-vd-hogt-pris-om-europa-inte-agerar/",
        "text": "Ingen brÃ¶dtext tillgÃ¤nglig",
        "date": "2025-02-12T21:34:36.135229+00:00",
        "source": "di.se"
    },
    {
        "title": "Deepseek fÃ¶rbjuds i Italien",
        "link": "https://www.di.se/digital/deepseek-forbjuds-i-italien/",
        "text": "Ingen brÃ¶dtext tillgÃ¤nglig",
        "date": "2025-02-12T21:34:36.135400+00:00",
        "source": "di.se"
    },
    {
        "title": "Uppgifter: Open AI vill ta in 40 miljarder dollar",
        "link": "https://www.di.se/digital/uppgifter-open-ai-vill-ta-in-40-miljarder-dollar/",
        "text": "Ingen brÃ¶dtext tillgÃ¤nglig",
        "date": "2025-02-12T21:34:36.135569+00:00",
        "source": "di.se"
    },
    {
        "title": "HÃ¤lsotestbolaget vÃ¤xer â€“ bygger AI-system med Intel",
        "link": "https://www.di.se/digital/halsotestbolaget-vaxer-bygger-ai-system-med-intel/",
        "text": "Ingen brÃ¶dtext tillgÃ¤nglig",
        "date": "2025-02-12T21:34:36.135740+00:00",
        "source": "di.se"
    }
]